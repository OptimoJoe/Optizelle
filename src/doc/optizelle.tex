\documentclass{report}

% All of the packages required

% AMS math typesetting
\usepackage{amssymb}
\usepackage{amsmath}

% Grabs code examples
\usepackage{listings}

% We use this with listings in order to color our code
\usepackage{xcolor}

% Creates both internal and external links.  At the moment, I like this
% more than the url package
\usepackage[colorlinks=true]{hyperref}

% Creates multiple page tables
\usepackage{longtable}

% Sets both the paper type (letter or A4) as well as the margins
\usepackage[top=0.1\paperheight,bottom=0.1\paperheight,left=0.1\paperwidth,right=0.1\paperwidth,paper=@PAPERTYPE@]{geometry}

% Creates a slightly nicer looking manual.  Make sure this comes after geometry
% or else all of the styles will be messed up.
\usepackage[Bjornstrup]{fncychap}

% Type sets directory trees
\usepackage{dirtree}

% Allows the creation of starred macros
\usepackage{suffix}

% Allows the external creation of files.  We use this in order to get around
% some of the irritating change in formatting that hyperref does.
\usepackage{filecontents}

% Index creation
\usepackage{makeidx}
\makeindex

% In document bibliography.  Note, we include natbib before bibentry because
% we use the hyperref package.  For whatever reason, we fail to build without
% it.
\usepackage{natbib}
\usepackage{bibentry}

% For including license files verbatim
\usepackage{verbatim}

% Define a computer text environment.  This is monospaced and allows
% underscores.  Code found at:
% https://tex.stackexchange.com/questions/20890/define-an-escape-underscore-environment
\makeatletter
\DeclareRobustCommand*{\textct}[1]{%
  \begingroup\@activeus\scantokens{\texttt{#1}\endinput}\endgroup}
\begingroup\lccode`\~=`\_\relax
   \lowercase{\endgroup\def\@activeus{\catcode`\_=\active \let~\_}}
\makeatother

% Enable gobble for lstlisting.  Code found at:
%https://tex.stackexchange.com/questions/48903/how-to-extend-the-lstinputlisting-command
\errorcontextlines=\maxdimen
\newlength{\rawgobble}
\newlength{\gobble}
\newlength{\gobblea}
% The width of a single space. basicstyle from lstset should be used
\sbox0{\normalsize\ttfamily \ }
% Remove a single space
\settowidth{\rawgobble}{\normalsize\ttfamily \ }
\setlength{\rawgobble}{-\rawgobble}
\makeatletter
\def\sepstar#1*#2\relax{%
    \def\sepstarone{#1}%
    \def\sepstartwo{#2}%
}
\lst@Key{firstlineandnumber}\relax{\def\lst@firstline{#1\relax}\def\lst@firstnumber{#1\relax}}
\lst@Key{widthgobble}{0*0}{%
    % Reindent a bit by multiplying with 0.9, then multiply by tabsize and number of indentation levels
    \sepstar #1\relax
    \setlength{\gobble}{0.9\rawgobble}%
    \setlength{\gobble}{\sepstarone\gobble}%
    \setlength{\gobble}{\sepstartwo\gobble}%
    \setlength{\gobblea}{\gobble}%
    \addtolength{\gobblea}{10pt}%
    \def\lst@xleftmargin{\gobble}%
    \def\lst@framexleftmargin{\gobble}%
    \def\lst@numbersep{\gobblea}%
}
\makeatother

% Used for labeling licenses
\newcommand{\licenselabel}[2]{\phantomsection\index{Licenses!#1}\label{lic:#2}}
\newcommand{\licenselabelalt}[2]{\index{Licenses!#2}\href{#1}{#2}}
\newcommand{\licenseref}[2]{\hyperref[lic:#2]{#1}}

% Used for labeling and referring to computer text
\newcommand{\textctalt}[1]{\texttt{\detokenize{#1}}}
\newcommand{\textctlabel}[1]{\phantomsection\label{itm:#1}\textct{#1}}
\newcommand{\textctref}[1]{\hyperref[itm:#1]{\textct{#1}}}
\newcommand{\textctlabelalt}[1]{\phantomsection\label{alt:#1}\textct{#1}}
\newcommand{\textctrefalt}[1]{\hyperref[alt:#1]{\textct{#1}}}

% Setup a bolded list environment.
\newenvironment{boldlist}
    {\begin{list}{}{
        \labelwidth.16\textwidth
        \leftmargin\dimexpr\leftmargin+.16\textwidth
        \renewcommand\makelabel[1]{%
            \textbf{##1}}}}
    {\vspace{-\dimexpr\baselineskip+2\itemsep}\end{list}}

\newenvironment{boldlistwide}
    {\begin{list}{}{
        \labelwidth.20\textwidth
        \leftmargin\dimexpr\leftmargin+.20\textwidth
        \renewcommand\makelabel[1]{%
            \textbf{##1}}}}
    {\vspace{-\dimexpr\baselineskip+2\itemsep}\end{list}}

% Specifies a variety of problem classes following the hierarchy of
% optimization problems.  Basically, an unconstrained parameter is a parameter
% for all classes.  An equality constrained parameter applies to fully
% constrained, etc.
\newcommand{\classUnconstrained}{Unconstrained, Equality Constrained, Inequality Constrained, Constrained}
\newcommand{\classEquality}{Equality Constrained, Constrained}
\newcommand{\classNotEquality}{Unconstrained, Inequality Constrained}
\newcommand{\classInequality}{Inequality Constrained, Constrained}
\newcommand{\classConstrained}{Constrained}

% CMake items
\newcommand{\cmakeitem}[7]{
    \item[Flag] \index{CMake Flags!\textct{#1}}{\textctlabel{#1}}
    \item[Type] \textct{#2}
    \item[Default] #3
    \item[Dependency] #4
    \item[Enables] #5
    \item[Autodetect?] #6
    \item[Description] #7
    \item[]}

% Configuration items for platform specific issues
\newcommand{\configitem}[5]{
    \item[Flag] \textct{#1}
    \item[Platform] #2
    \item[Interface] #3
    \item[Indication] #4
    \item[Description] #5
    \item[]}

%# API items
\newcommand{\apiitem}[4]{
    \item[Language] #1
    \item[Structure]  #2
    \item[Interface] #3
    \item[Code] #4
    \item[]}

\newcommand{\apiitemshort}[3]{
    \item[Language] #1
    \item[Structure]  #2
    \item[Interface] #3
    \item[]}

% Describing the vector space
\newcommand{\vsitem}[3]{
    \item[Language] #1
    \item[Vector]  #2
    \item[Operations]  #3
    \item[]}

% Example items
\newcommand{\exampleitem}[2]{
    \item[Language] #1
    \item[Code] #2
    \item[]}

% Short example items.  Basically, the minipage stops page wrapping, so the example better be short.  We use this in order to gobble up space since a regular example item messes up the indendation.
\newcommand{\shortexampleitem}[2]{
    \item[Language] #1
    \item[Code]\begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}#2\end{minipage}
    \item[]}

% Function bundle items
\newcommand{\functionitem}[5]{
    \item[Element] \index{Functions, User Defined!\textct{#1}}{\textctlabel{#1}}
    \item[Type] \textctref{#2}
    \item[\mbox{Problem Class}] #3
    \item[Required] #4
    \item[Description] #5
    \item[]}

% Type items
\newcommand{\typeitem}[2]{
    \item[Type] \index{Parameter Types!\textct{#1}}{\textctlabel{#1}}
    \item[Description] #2
    \item[]}

% Enumerated items
\newcommand{\enumitem}[1]{
    \item[Type] \index{Enumerated Types!\textct{#1}}{\textctlabel{#1}}
    \item[Values]\begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
        \lstinputlisting[style=C++,linerange=#1 0-#1 1,widthgobble=3*4]{@OPTIZELLECPPPATH@/optizelle.h}
    \end{minipage}
    \item[]}
\newcommand{\enumitemlong}[1]{
    \item[Type] \index{Enumerated Types!\textct{#1}}{\textctlabel{#1}}
    \item[Values]
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=C++,linerange=#1 0-#1 1,widthgobble=3*4]{@OPTIZELLECPPPATH@/optizelle.h}
        \end{minipage}
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=C++,linerange=#1 1-#1 2,widthgobble=3*4]{@OPTIZELLECPPPATH@/optizelle.h}
        \end{minipage}
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=C++,linerange=#1 2-#1 3,widthgobble=3*4]{@OPTIZELLECPPPATH@/optizelle.h}
        \end{minipage}
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=C++,linerange=#1 3-#1 4,widthgobble=3*4]{@OPTIZELLECPPPATH@/optizelle.h}
        \end{minipage}
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=C++,linerange=#1 4-#1 5,widthgobble=3*4]{@OPTIZELLECPPPATH@/optizelle.h}
        \end{minipage}
    \item[]}
\newcommand{\enumitemlinalg}[1]{
    \item[Type] \index{Enumerated Types!\textct{#1}}{\textctlabel{#1}}
    \item[Values]\begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
        \lstinputlisting[style=C++,linerange=#1 0-#1 1,widthgobble=3*4]{@OPTIZELLECPPPATH@/linalg.h}
    \end{minipage}
    \item[]}
\newcommand{\enumitemvspace}[1]{
    \item[Type] \index{Enumerated Types!\textct{#1}}{\textctlabel{#1}}
    \item[Values]\begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
        \lstinputlisting[style=C++,linerange=#1 0-#1 1,widthgobble=3*4]{@OPTIZELLECPPPATH@/vspaces.h}
    \end{minipage}
    \item[]}

% Parameter items
\newcommand{\paramitem}[5]{
    \item[Name] \index{Parameters!\textct{#1}}{\textctlabel{#1}}
    \item[Type] #2
    \item[\mbox{Valid Value}]
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=C++,linerange=#1 _valid0-#1 _valid1,widthgobble=5*4]{@OPTIZELLECPPPATH@/optizelle.h}
        \end{minipage}
    \item[\mbox{Problem Class}] #3
    \item[\mbox{JSON Param}] #4
    \item[Default]
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=C++,linerange=#1 0-#1 1,widthgobble=6*4]{@OPTIZELLECPPPATH@/optizelle.h}
        \end{minipage}
    \item[Description] #5
    \item[]}

\newcommand{\paramitemu}[4]{
    \paramitem
        {#1}
        {\textctref{#2}}
        {\classUnconstrained}
        {#3}
        {#4}}

\newcommand{\paramiteml}[4]{
    \paramitem
        {#1}
        {\textctref{List}(\textctref{#2})}
        {\classUnconstrained}
        {#3}
        {#4}}

\newcommand{\paramitemf}[4]{
    \paramitem
        {#1}
        {\textctref{Function}(\textctref{#2})}
        {\classEquality}
        {#3}
        {#4}}

\newcommand{\paramiteme}[4]{
    \paramitem
        {#1}
        {\textctref{#2}}
        {\classEquality}
        {#3}
        {#4}}

\newcommand{\paramitemi}[4]{
    \paramitem
        {#1}
        {\textctref{#2}}
        {\classInequality}
        {#3}
        {#4}}

\newcommand{\paramitemc}[4]{
    \paramitem
        {#1}
        {\textctref{#2}}
        {\classConstrained}
        {#3}
        {#4}}

% Formulation items
\newcommand{\formitem}[4]{
    \item[Unconstrained] #1
    \item[Equality] #2
    \item[Inequality] #3
    \item[Constrained] #4
    \item[]}

\newcommand{\formiteme}[2]{
    \item[Equality] #1
    \item[Constrained] #2
    \item[]}

\newcommand{\formitemi}[2]{
    \item[Inequality] #1
    \item[Constrained] #2
    \item[]}

% Output items
\newcommand{\outputitemraw}[5]{
    \item[Name] #1
    \item[\mbox{State Param}] #2
    \item[\mbox{Problem Class}] #3
    \item[\mbox{Min \textctref{msg_level}}] #4
    \item[Description] #5
    \item[]}

\newcommand{\outputitem}[5]{
   \outputitemraw
        {\index{Outputs!\textct{#1}}{\textctlabelalt{#1}}}
        {#2}
        {#3}
        {#4}
        {#5}}

\newcommand{\outputitemu}[4]{
    \outputitem
        {#1}
        {#2}
        {\classUnconstrained}
        {#3}
        {#4}}

\newcommand{\outputiteme}[4]{
    \outputitem
        {#1}
        {#2}
        {\classEquality}
        {#3}
        {#4}}

\newcommand{\outputitemi}[4]{
    \outputitem
        {#1}
        {#2}
        {\classInequality}
        {#3}
        {#4}}

\newcommand{\outputitemc}[4]{
    \outputitem
        {#1}
        {#2}
        {\classConstrained}
        {#3}
        {#4}}

% Custom vector-space items
\newcommand{\customvsitem}[8]{
    \item[Name] \index{Vector Space Operations!\textct{#1}}{\textctlabel{#1}}
    \item[Definition]
        \begin{boldlistwide}
            \item[C++] \textct{#2}
            \item[] #3
            \item[Python] \textct{#4}
            \item[] #5
            \item[MATLAB/Octave] \textct{#6}
            \item[] #7
            \item[]
        \end{boldlistwide}
    \item[Description] #8
    \item[]}

% Custom vector-space wrapper items
\newcommand{\vswrapperitem}[3]{
    \item[Language] #1
    \item[Interface] #2
    \item[Description] #3
    \item []}

% Restart type items
\newcommand{\simpletypeitem}[2]{
    \item[Language] #1
    \item[Type] \textct{#2}
    \item[]}

\newcommand{\rtypeitem}[2]{
    \item[Type] \index{Restart Types!\textct{#1}}{\textctlabel{#1}}
    \item[Description] #2
    \item[]}

\newcommand{\restartitem}[5]{
    \item[Language] #1
    \item[Code]
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/unconstrained.#5}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/equality_constrained.#5}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/inequality_constrained.#5}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/constrained.#5}
        \end{minipage}
    \item[]}

\newcommand{\restartitemlong}[5]{
    \item[Language] #1
    \item[Code]
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/unconstrained.#5}
        \end{minipage}

        \bigskip

        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/equality_constrained.#5}
        \end{minipage}

        \bigskip

        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/inequality_constrained.#5}
        \end{minipage}

        \bigskip

        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/constrained.#5}
        \end{minipage}
    \item[]}

\newcommand{\restartitemalt}[5]{
    \item[Language] #1
    \item[Code]
        \begin{minipage}[t]{\textwidth}\vspace{\dimexpr-\medskipamount-2ex}
            \lstinputlisting[style=#2,linerange={#3},widthgobble=#4*4]{@RESTARTPATH@/unconstrained.#5}
        \end{minipage}
    \item[]}

% Items that help describe the installation
\newcommand{\ositem}[3]{
    \item[Windows] #1
    \item[macOS] #2
    \item[Linux/Unix] #3
    \item[]}

\newcommand{\libraryitem}[8]{
    \item[Core] Add #1 to #2
    \item[Python] Add #3 to #4
    \item[MATLAB] Add #5 to #6
    \item[Octave] Add #7 to #8
    \item[]}

% Documentation on the different algorithms
\newcommand{\algorithmitem}[2]{
    \item[Algorithm] \index{Algorithmic discussion!#1}{#1}
    \item[Description] #2
    \item[]}

% How to cache different computations
\newcommand{\cacheref}[3]{\index{Caching!#1}\hyperref[cache:#2]{#3}}
\newcommand{\cachesoftref}[2]{\hyperref[cache:#1]{#2}}
\newcommand{\cacheitem}[7]{
    \item[Computation] #1\index{Caching!#2}{\phantomsection\label{cache:#3}}
    \item[\mbox{Problem Class}] #4
    \item[Priority] #5
    \item[\mbox{Number Stored}] #6
    \item[Description] #7
    \item[]}
\newcommand{\cachecode}[2]{
    \index{Examples!Computation caching}
    \lstinputlisting[style=Matlab,linerange=#2 0-#2 1]{@CACHEPATH@/generate_#1_space.m}
}

% Change the figure numbering to be chap.sec.num
\renewcommand{\thefigure}{\arabic{chapter}.\arabic{section}.\arabic{figure}}

% Create some new environments for displaying code and output

% Use the following for all languages
\lstset{
    tabsize=4,
    columns=flexible,
    boxpos=t,
    showstringspaces=false,
    basicstyle=\normalsize\ttfamily,
    backgroundcolor=\color{white},
    includerangemarker=false,
    keywordstyle=\color{blue}\ttfamily,
    stringstyle=\color{red}\ttfamily,
    commentstyle=\color{green!40!black}\ttfamily,
    morecomment=[l][\color{magenta}]{\#}
}

% C++
\lstdefinestyle{C++}{
    language=C++,
    rangeprefix=//---,
    rangesuffix=---
}

% Python
\lstdefinestyle{Python}{
    language=Python,
    rangeprefix=\#---,
    rangesuffix=---,
}

% MATLAB
\lstdefinestyle{MATLAB}{
    language=MATLAB,
    rangeprefix=\%---,
    rangesuffix=---,
}

% JSON
\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}
\lstdefinestyle{json}{
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    backgroundcolor=\color{white},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {e-}{{{\color{numb}e-}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
    rangeprefix=\"---,
    rangesuffix=---\"\ :\ null
}

% Optizelle output
\lstdefinestyle{OptizelleOutput}{
    morekeywords={iter,f,x,merit,grad,dx,trunc_why,trunc_err,trunc_iter,ared,pred,
        ared/pred,mu,mu_est,g,alpha,alpha0,delta},
    sensitive=false,
    literate=
}

% Simple macros to help math printing
\newcommand{\re}{\mathbb{R}}
\newcommand{\st}{\textnormal{st}}

\newcommand{\uncMerit}[1]{f(#1)}
\newcommand{\uncGradLag}[1]{\nabla f(#1)}
\newcommand{\uncHessVec}[1]{\hyperref[itm:H_type]{H}(#1)\textctref{dx}}

\newcommand{\ineqMerit}[1]{f(#1) - \textctref{mu} \cdot \textctref{barr}(h(#1))}
\newcommand{\ineqGradLag}[2]{\nabla f(#1)-h^\prime(#1)^*#2}
\newcommand{\ineqGradSchur}[1]{\nabla f(#1)-\textctref{mu}\cdot h^\prime(#1)^*L(h(#1))^{-1}e}
\newcommand{\ineqHessVec}[2]{\hyperref[itm:H_type]{H}(#1)\textctref{dx}+h^\prime(#1)^*L(h(#1))^{-1} (h^\prime(#1) \textctref{dx} \circ #2)}

\newcommand{\eqMerit}[2]{f(#1) + \langle #2,g(#1) \rangle + \textctref{rho} || g(#1) ||^2}
\newcommand{\eqGradLag}[2]{\nabla f(#1)+g^\prime(#1)^*#2}
\newcommand{\eqHessVec}[2]{\hyperref[itm:H_type]{H}(#1)\textctref{dx}+(g^{\prime\prime}(#1)\textctref{dx})^*#2}

\newcommand{\conMerit}[2]{f(#1) + \langle #2,g(#1) \rangle + \textctref{rho} || g(#1) ||^2 - \textctref{mu} \cdot \textctref{barr}(h(#1))}
\newcommand{\conGradLag}[3]{\nabla f(#1)+g^\prime(#1)^*#2-h^\prime(#1)^*#3}
\newcommand{\conGradSchur}[2]{\nabla f(#1)+g^\prime(#1)^*#2-\textctref{mu}\cdot h^\prime(#1)^*L(h(#1))^{-1}e}
\newcommand{\conHessVec}[3]{\hyperref[itm:H_type]{H}(#1)\textctref{dx}+(g^{\prime\prime}(#1)\textctref{dx})^*#2+h^\prime(#1)^*L(h(#1))^{-1} (h^\prime(#1) \textctref{dx} \circ #3)}

% Collections of text, tables, etc.
\newsavebox{\boxOptimizationTypes}
\newsavebox{\boxUnconstrained}
\newsavebox{\boxEqualityConstrained}
\newsavebox{\boxInequalityConstrained}
\newsavebox{\boxConstrained}
\newsavebox{\boxImport}
\newsavebox{\boxEnvironmentLinux}
\newsavebox{\boxEnvironmentLinuxAlt}
\newsavebox{\boxEnvironmentmacOS}
\newsavebox{\boxEnvironmentWindows}

% Labels for some sections
\newcommand{\secinstalling}{Installing}
\newcommand{\secimport}{Import Optizelle}
\newcommand{\secimportvs}{Import or define the appropriate vector spaces}
\newcommand{\secobjective}{Define the objective function}
\newcommand{\secconstraints}{(Optional) Define the constraints}
\newcommand{\secpreconditioners}{(Optional) Define the preconditioners}
\newcommand{\secstate}{Create the optimization state}
\newcommand{\secparams}{Set the optimization parameters}
\newcommand{\secfns}{Accumulate the functions}
\newcommand{\secsolve}{Call the optimization solver}
\newcommand{\secextract}{Extract the solution}
\newcommand{\seccompilerun}{Compile/run the program}

\newcommand{\chparams}{Optimization parameters}
\newcommand{\choutput}{Output}
\newcommand{\chadvanced}{Advanced API}
\newcommand{\seccustomvector}{Customized vector spaces}
\newcommand{\secmessaging}{User-defined messaging}
\newcommand{\secerrors}{Handling errors}
\newcommand{\seccone}{Symmetric cone programming}
\newcommand{\secsmanip}{State manipulation}
\newcommand{\secrestart}{Restarts}
\newcommand{\seccaching}{Caching Computations}
\newcommand{\chexamples}{Additional examples}
\newcommand{\secequality}{Simple equality constrained}
\newcommand{\secinequality}{Simple inequality constrained}
\newcommand{\secconstrained}{Simple constrained}
\newcommand{\secsimpleconstrainedadvancedapi}{Simple constrained advanced API}
\newcommand{\secrosenbrockadvancedapi}{Rosenbrock advanced API}
\newcommand{\secrosenbrock}{Rosenbrock}
\newcommand{\secquadratic}{Simple SOCP}
\newcommand{\secsdp}{Simple SDP}

% A couple of macros to help with indexing our examples
\newcommand{\exampleref}[2]{\index{Examples!#1}\hyperref[#2]{#1}}
\newcommand{\examplelabel}[2]{\phantomsection\index{Examples!#1}\label{#2}}

\title{Optizelle v@CPACK_PACKAGE_VERSION_MAJOR@.@CPACK_PACKAGE_VERSION_MINOR@.@CPACK_PACKAGE_VERSION_PATCH@}
\author{OptimoJoe\\Joseph Young}
\date{}
\begin{document}

% Setup the bibliography
\nobibliography{optizelle}
\bibliographystyle{plain}

\maketitle
\tableofcontents

\chapter{Introduction}

        Optizelle [op-t\textit{\!uh}-{\bf zel}] is an open source software library designed to solve general purpose nonlinear optimization problems of the form
    \begin{lrbox}{\boxUnconstrained}
        $\begin{array}[t]{rcl}
            \min\limits_{x\in X} && f(x)
        \end{array}$
    \end{lrbox}
    \begin{lrbox}{\boxEqualityConstrained}
        $\begin{array}[t]{rcl}
            \min\limits_{x\in X} && f(x)\\
            \st && g(x)=0
        \end{array}$
    \end{lrbox}
    \begin{lrbox}{\boxInequalityConstrained}
        $\begin{array}[t]{rcl}
            \min\limits_{x\in X} && f(x)\\
            \st && h(x)\succeq 0
        \end{array}$
    \end{lrbox}
    \begin{lrbox}{\boxConstrained}
        $\begin{array}[t]{rcl}
            \min\limits_{x\in X} && f(x)\\
            \st && g(x)=0\\
                && h(x)\succeq 0
        \end{array}$
    \end{lrbox}
    \begin{lrbox}{\boxOptimizationTypes}
        \begin{tabular}{|l|l|}\hline
            \multicolumn{1}{|c|}{\bf Unconstrained} &
            \multicolumn{1}{c|}{\bf Equality Constrained}\\
            \usebox{\boxUnconstrained} &
            \usebox{\boxEqualityConstrained} \\\hline
            \multicolumn{1}{|c|}{\bf Inequality Constrained} &
            \multicolumn{1}{c|}{\bf Constrained}\\
            \usebox{\boxInequalityConstrained} &
            \usebox{\boxConstrained} \\\hline
        \end{tabular}
    \end{lrbox}
\begin{center}
    \usebox{\boxOptimizationTypes}
\end{center}
\noindent It features
\begin{itemize}
    \item {\bf State of the art algorithms}
        \begin{itemize}
            \item Unconstrained -- steepest descent, preconditioned nonlinear-CG (Fletcher-Reeves, Polak-Ribiere, Hestenes-Stiefel), BFGS, Newton-CG, SR1, trust-region Newton, Barzilai-Borwein two-point approximation
            \item Equality constrained -- inexact composite-step SQP.
            \item Inequality constrained -- primal-dual interior point method for cone constraints (linear, second-order cone, and semidefinite), log-barrier method for cone constraints
            \item Constrained -- any combination of the above
        \end{itemize}
    \item {\bf Open source}
        \begin{itemize}
            \item Released under the 2-Clause BSD License
            \item Free and ready to use with both open and closed sourced commercial codes
        \end{itemize}
    \item {\bf Multilanguage support}
        \begin{itemize}
            \item Interfaces to C++, MATLAB/Octave, and Python
        \end{itemize}
    \item {\bf Robust computations and repeatability}
        \begin{itemize}
            \item Can stop, archive, and restart the computation from any optimization iteration
            \item Combined with the multilanguage support, the optimization can be started in one language and migrated to another.  For example, archived optimization runs that started in Python can be migrated and completed in C++.
        \end{itemize}
    \item {\bf User-defined parallelism}
        \begin{itemize}
            \item Fully compatible with OpenMP, MPI, or GPUs
        \end{itemize}
    \item {\bf Extensible linear algebra}
        \begin{itemize}
            \item Supports user-defined vector algebra and preconditioners
            \item Enables sparse, dense, and matrix-free computations
            \item Ability to define custom inner products and compatibility with preconditioners such as algebraic multigrid make Optizelle well-suited for PDE constrained optimization
        \end{itemize}
    \item {\bf Sophisticated Control of the Optimization Algorithms}
        \begin{itemize}
            \item Allows the user to insert arbitrary code into the optimization algorithm, which enables custom heuristics to be embedded without modifying the source.  For example, in signal processing applications, the optimization iterates could be run through a band-pass filter at the end of each optimization iteration.
        \end{itemize}
\end{itemize}

\section{Licensing}

        Optizelle is copyrighted by OptimoJoe and licensed under the 2-Clause BSD License:
\begin{flushleft}\index{Licenses!Optizelle}
    \texttt{\protect\input{@LICENSEPATH@/optizelle.txt}}
\end{flushleft}
\noindent In short, Optizelle is free to use in both open and closed sourced codes.  If you do so, we ask that you provide a citation or link to \url{http://www.optimojoe.com}.

\section{Support}

        News, updates, and download information for Optizelle can be found at
\begin{center}
    \mbox{\url{http://www.optimojoe.com/products/optizelle}}
\end{center}
Our user forum can be found at
\begin{center}
    \mbox{\url{http://forum.optimojoe.com}}
\end{center}
Finally, if you are interested in paid support and consulting, please contact us at \mbox{\href{mailto:contact@optimojoe.com}{contact@optimojoe.com}}.

\section{Brief example}\examplelabel{\secrosenbrock}{sec:rosenbrock}

        In order to see a short example of Optizelle in action, consider the unconstrained minimization of the Rosenbrock function
$$
    \begin{array}{rcl}
        \min\limits_{x\in\re^2} && (1-x_1)^2+100(x_2-x_1^2)^2.
    \end{array}
$$
In order to optimize this function, we use the following code and parameters, which generates the subsequent output.

\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python]{@ROSENBROCKPATH@/rosenbrock.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=MATLAB]{@ROSENBROCKPATH@/rosenbrock.m}}

    \exampleitem
        {Optizelle Parameters}
        {\lstinputlisting[style=json,linerange=params0-params1]{@ROSENBROCKPATH@/tr_newton.json}}

    \exampleitem
        {Optizelle Output}
        {\lstinputlisting[style=OptizelleOutput]{@DOCPATH@/rosen_output.txt}}
\end{boldlist}

\section{History}

        Optizelle originated in 2010 as a code called PEOpt (Parameter Estimation Using Optimization) written by Joseph Young at Sandia National Laboratories.  There, it was used as the computational driver for a variety of both internal and external customers.  Due to the scale of the problems involved and the nuances of high-performance computing environments, PEOpt was designed specifically to integrate with large, existing code bases as quickly and unobtrusively as possible.  Later, Sandia approved the open source release of PEOpt on two separate occasions in 2012 and 2013 under the 2-Clause BSD License.  It was from this released code that Joseph continued work on Optizelle through a new company called OptimoJoe.

\chapter{Installation}\label{ch:Install}

        In the following chapter, we discuss how to download, build, and incorporate Optizelle into a new project.

\section{Downloading}

        Optizelle can be downloaded from
\begin{center}
    \mbox{\url{http://www.optimojoe.com/products/optizelle}}
\end{center}
in a variety of precompiled packages.  Here, we also provide direct access to our source code repository.

\section{Installing and Uninstalling}

        The installation method depends on the platform, but generally involves opening the installer and following the specified instructions
\begin{lrbox}{\boxEnvironmentLinux}
    \begin{tabular}{l}
    \textctalt{export MATLABPATH=$MATLABPATH:/usr/local/share/optizelle/matlab}\\
    \textctalt{export OCTAVE_PATH=$OCTAVE_PATH:/usr/local/share/optizelle/octave}\\
    \textctalt{export PYTHONPATH=$PYTHONPATH:/usr/local/share/optizelle/python}
    \end{tabular}
\end{lrbox}
\begin{boldlist}
    \ositem
        {Open the installer}
        {\begin{enumerate}
            \item Open the installer
            \item Drag the Optizelle folder to Applications
            \item Copy the file
                \begin{flushleft}
                    \textct{/Applications/Optizelle/share/optizelle/com.optimojoe.optizelle.plist}
                \end{flushleft}
                to
                \begin{flushleft}
                    \textct{/Library/LaunchAgents/}
                \end{flushleft}
            \item Close the Terminal application if open and reboot
        \end{enumerate}
        Note, we summarize these steps and provide additional information in the \textct{ReadMe.txt} file provided after opening the installer.}
        {\begin{enumerate}
            \item Unzip the \textct{tar.gz} file to a local directory or use the appropriate package manager to install the \textct{rpm} or \textct{deb} package directly
            \item Add \textct{/some/path/share/optizelle/matlab} to the \textct{MATLABPATH}
            \item Add \textct{/some/path/share/optizelle/octave} to the \textct{OCTAVE_PATH}
            \item Add \textct{/some/path/share/optizelle/python} to the \textct{PYTHONPATH}
        \end{enumerate}
        where \textct{/some/path} denotes the Optizelle install location.  By default, the \textct{deb} and \textct{rpm} files install Optizelle to \textct{/usr/local/}.  Note, on most Linux distributions, we add a variable to the path by adding
        \begin{flushleft}
            \textctalt{export SOMEVARIABLE=$SOMEVARIABLE:NEWPATH}
        \end{flushleft}
        to the file \textctalt{~/.bashrc}.  In other words, if we install Optizelle to \textct{/usr/local}, we add the following to text \textctalt{~/.bashrc}
        \begin{flushleft}
            \usebox{\boxEnvironmentLinux}
        \end{flushleft}
        Remember to execute \textctalt{source ~/.bashrc} on all active shells, log out and back in, or reboot for the changes to take affect.}
\end{boldlist}

    Similar to installation, how we uninstall Optizelle depends on the platform
\begin{boldlist}
    \ositem
        {Click the menus Start $\rightarrow$ Settings $\rightarrow$ System $\rightarrow$ Apps \& features $\rightarrow$ Optizelle $\rightarrow$ Uninstall}
        {\begin{enumerate}
            \item Drag the folder \textct{/Applications/Optizelle} to the trash
            \item Drag the file \textct{/Library/LaunchAgents/com.optimojoe.optizelle.plist} to the trash
        \end{enumerate}}
        {\begin{enumerate}
            \item When installed locally using the \textct{tar.gz} package, delete the installation folder
            \item When installed using the \textct{rpm} or \textct{deb} packages, use the package manager to remove Optizelle
            \item Delete any modifications to the path made in the file \textctalt{~/.bashrc} or other similar configuration file
        \end{enumerate}}
\end{boldlist}

\section{Dependencies}

        Depending on its configuration, Optizelle uses the following software packages
\begin{center}\begin{tabular}{lll|cccccc}
    Package & Version & License & C++ & Python & MATLAB & Octave & Docs & Windows\\\hline
    \licenselabelalt{http://www.optimojoe.com/products/optizelle/}{Optizelle} & @CPACK_PACKAGE_VERSION_MAJOR@.@CPACK_PACKAGE_VERSION_MINOR@.@CPACK_PACKAGE_VERSION_PATCH@ & \licenseref{BSD}{optizelle} & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$\\
    \licenselabelalt{https://github.com/open-source-parsers/jsoncpp}{JsonCpp} & 1.9.2 & \licenseref{Public}{jsoncpp} & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ &  & $\checkmark$\\
    \licenselabelalt{http://netlib.org/lapack/}{BLAS/LAPACK} & 3.9.0 & \licenseref{BSD}{blaslapack} & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ &  & $\checkmark$\\
    \licenselabelalt{https://cmake.org/}{CMake} & 3.17.1 & \licenseref{BSD}{cmake} & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ &  $\checkmark$ & $\checkmark$\\
    \licenselabelalt{http://wixtoolset.org/}{WiX} & 3.11.2 & \licenseref{MS-RL}{wix} & & & & & & $\checkmark$\\
    \licenselabelalt{https://gcc.gnu.org/}{GCC} & 9.3.0 & \licenseref{GPL}{gcc} & $\checkmark$ & $\checkmark$ & $\checkmark$ & $\checkmark$ &  & $\checkmark$\\
    \licenselabelalt{https://www.tug.org/texlive/}{TeX Live} & 2019 & \licenseref{Various}{texlive} & & & & & $\checkmark$ &\\
    \licenselabelalt{https://www.python.org/}{Python} & 3.8.2 & \licenseref{Python}{python} & & $\checkmark$ & & & &\\
    \licenselabelalt{https://numpy.org/}{NumPy} & 1.18.3 & \licenseref{BSD}{numpy} & & $\checkmark$ & & & &\\
    \licenselabelalt{https://www.mathworks.com/products/matlab/}{MATLAB} & R2020a & \licenseref{Custom}{matlab} & & & $\checkmark$ & & &\\
    \licenselabelalt{https://github.com/fangq/jsonlab}{JSONLab} & 1.9.8 & \licenseref{BSD}{jsonlab} & & & $\checkmark$ & $\checkmark$ & &\\
    \licenselabelalt{https://www.gnu.org/software/octave/}{Octave} & 5.2.0 & \licenseref{GPL}{octave} & & & & $\checkmark$ & &\\
\end{tabular}\end{center}

\noindent Note, we generally depend on GCC for both its C++ and Fortran compiler, but an alternative compiler such as Clang works as well.  Since we do not modify GCC, the GCC Runtime Library Exception applies.  In addition, Optizelle remains compatible with most high-performance varieties of BLAS and LAPACK.

\section{Building}

    Optizelle uses CMake as its build system.  On Linux, Unix, macOS, Cygwin, or MSYS, execute the following commands from the base Optizelle directory:
\begin{enumerate}
    \item \textct{mkdir build}
    \item \textct{cd build}
    \item \textct{ccmake ..}
    \item Configure the build.
    \item \textct{make}
\end{enumerate}
On Windows, if not using Cygwin or MSYS, execute the following commands:
\begin{enumerate}
    \item Using Windows Explorer, create a directory called \textct{build} in the base Optizelle directory.
    \item Run \textct{cmake-gui.exe}
    \item Set the source directory to the base Optizelle directory.
    \item Set the build directory to the \textct{build} folder created above.
    \item Configure the build.
    \item Build the code (\textct{make} with Cygwin or MSYS.)
\end{enumerate}

    Rather than using \textct{ccmake}, we can also run \textct{cmake} directly in order to configure the build.  This allows us to skip the CMake menu system and configure Optizelle directly, which can be advantageous when compiling Optizelle on multiple, but similar systems.  In order to accomplish this, we execute a command such as
\begin{center}\begin{lstlisting}
cmake \
    %-flags
..
\end{lstlisting}\end{center}
where the actual paths, libraries, and archives depend on the individual system.  Generally, we put this command inside a shell script or batch file in order to make it easier to edit.  As far as the available options, we list them in the next section.

    After building Optizelle, installation is as simple as executing
\begin{center}
        \textct{make install}
\end{center}
from the CMake build directory using GNU Make, MSYS, or Cygwin.  If using a different Make utility, call it on the \textct{install} target.  For a complete list of installed files, see
\begin{center}
    \textct{install_manifest.txt}
\end{center}
located in the CMake build directory.\\

    After installation via \textct{make install}, we must also
    \begin{enumerate}
        \item Add \textct{/some/path/share/optizelle/matlab} to the \textct{MATLABPATH}
        \item Add \textct{/some/path/share/optizelle/octave} to the \textct{OCTAVE_PATH}
        \item Add \textct{/some/path/share/optizelle/python} to the \textct{PYTHONPATH}
    \end{enumerate}
where \textct{/some/path} denotes the path found in the \textctref{CMAKE_INSTALL_PREFIX} configuration variable described below.  How we set environment variables depends on the platform
\begin{lrbox}{\boxEnvironmentWindows}
    \begin{minipage}{5in}\begin{enumerate}
        \item Open File Explorer
        \item Right click This PC
        \item Click the menus Advanced System Settings $\rightarrow$ System Properties $\rightarrow$ Environment Variables $\rightarrow$ New (if the variable doesn't exist) or Edit (if the variable does exist)
        \item Modify \textct{PATH} with \verb|C:\some\path\lib| and \verb|C:\some\path\share\optizelle\thirdparty\lib|
        \item Modify \textct{MATLABPATH} with \verb|C:\some\path\share\optizelle\matlab|
        \item Modify \textct{OCTAVE_PATH} with \verb|C:\some\path\share\optizelle\octave|
        \item Modify \textct{PYTHONPATH} with \verb|C:\some\path\share\optizelle\python|
    \end{enumerate}\end{minipage}
\end{lrbox}
\begin{lrbox}{\boxEnvironmentmacOS}
\begin{lstlisting}
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN"
"http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0"><dict>
	<key>Label</key>
	<string>Optizelle.startup</string>
	<key>ProgramArguments</key>
	<array>
		<string>sh</string>
		<string>-c</string>
		<string>
            launchctl setenv MATLABPATH $MATLABPATH:/some/path/share/optizelle/matlab
            launchctl setenv OCTAVE_PATH $OCTAVE_PATH:/some/path/share/optizelle/octave
            launchctl setenv PYTHONPATH $PYTHONPATH:/some/path/share/optizelle/python
		</string>
  </array>
  <key>RunAtLoad</key>
  <true/>
</dict></plist>
\end{lstlisting}
\end{lrbox}
\begin{lrbox}{\boxEnvironmentLinuxAlt}
    \begin{tabular}{l}
    \textctalt{export MATLABPATH=$MATLABPATH:/some/path/share/optizelle/matlab}\\
    \textctalt{export OCTAVE_PATH=$OCTAVE_PATH:/some/path/share/optizelle/octave}\\
    \textctalt{export PYTHONPATH=$PYTHONPATH:/some/path/share/optizelle/python}
    \end{tabular}
\end{lrbox}
\begin{boldlist}
    \ositem
        {Modify each environment variable via the sequence
        \begin{flushleft}
            \usebox{\boxEnvironmentWindows}
        \end{flushleft}
        where \texttt{C:\textbackslash{}some\textbackslash{}path} denotes the installation path found in the CMake variable \textctref{CMAKE_INSTALL_PREFIX}.}
        {Add a plist file to \textct{/Library/LaunchAgents} or \textctalt{~/Library/LaunchAgents}.  For example
        \usebox{\boxEnvironmentmacOS}
        where \textct{/some/path} denotes the installation path found in the CMake variable \textctref{CMAKE_INSTALL_PREFIX}.  Note, we must close the Terminal application and then reboot for the changes to take affect.}
        {When using the Bash shell, we add
        \begin{flushleft}
        \usebox{\boxEnvironmentLinuxAlt}
        \end{flushleft}
        to \textctalt{~/.bashrc} where \textct{/some/path} denotes the installation path found in the CMake variable \textctref{CMAKE_INSTALL_PREFIX}.  Note, we must also execute the command \textctalt{source ~/.bashrc} on all active shells, log out and back in, or reboot for the changes to take affect.}
\end{boldlist}

        As a final note, CMake does not provide a native uninstallation process when installing Optizelle in this manner.  Nevertheless, on Linux, Unix, macOS, MSYS, or Cygwin, the command
\begin{center}
    \textct{xargs rm < install_manifest.txt}
\end{center}
will remove the installation.  Also, don't forget to remove each of the environment variables added in the above installation process.

\section{Configuring}

        Optizelle provides several different options within CMake in order to customize the build.  We describe these flags in the table below:
\begin{boldlist}
    \cmakeitem
        {CMAKE_INSTALL_PREFIX}
        {PATH}
        {Varies}
        {None}
        {None}
        {No}
        {Install location of Optizelle.}

    \cmakeitem
        {ENABLE_DOCUMENTATION}
        {BOOL}
        {\textct{OFF}}
        {None}
        {\textctref{PDFLATEX_COMPILER},
            \textctref{ENABLE_A4_PAPER}}
        {No}
        {Enables the build of the Optizelle manual from the LaTeX source.
        It builds a pdf file of the manual.}

    \cmakeitem
        {PDFLATEX_COMPILER}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_DOCUMENTATION}}
        {None}
        {Yes}
        {Complete path and executable for pdflatex.}

    \cmakeitem
        {ENABLE_A4_PAPER}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_DOCUMENTATION}}
        {None}
        {No}
        {When \textct{ON}, the manual uses A4 paper.  Otherwise, the manual uses
        Letter paper.}

    \cmakeitem
        {ENABLE_CPP}
        {BOOL}
        {\textct{OFF}}
        {None}
        {\textctref{CMAKE_CXX_FLAGS},
            \textctref{CMAKE_BUILD_TYPE},
            \textctref{ENABLE_OPENMP},
            \textctref{ENABLE_BUILD_BLAS_AND_LAPACK},
            \textctref{ENABLE_BUILD_JSONCPP},
            \textctref{BLAS_LIBRARY},
            \textctref{LAPACK_LIBRARY},
            \textctref{JSONCPP_INCLUDE_DIR},
            \textctref{JSONCPP_LIBRARY},
            \textctref{ENABLE_CPP_EXAMPLES},
            \textctref{ENABLE_CPP_UNIT},
            \textctref{ENABLE_PYTHON},
            \textctref{ENABLE_MATLAB},
            \textctref{ENABLE_OCTAVE}}
        {No}
        {Enables the Optizelle C++ library.}

    \cmakeitem
        {CMAKE_CXX_FLAGS}
        {STRING}
        {None}
        {\textctref{ENABLE_CPP}}
        {None}
        {No}
        {C++ compiler specific flags.}

    \cmakeitem
        {CMAKE_BUILD_TYPE}
        {STRING}
        {None}
        {\textctref{ENABLE_CPP}}
        {None}
        {No}
        {Generally set to either \textct{RELEASE} or \textct{DEBUG}.  Set to
        \textct{RELEASE} for production libraries.  Set to \textct{DEBUG} to
        allow profiling through utilities such as
        \href{http://oprofile.sourceforge.net}{OProfile}.}

    \cmakeitem
        {ENABLE_OPENMP}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {None}
        {No}
        {Enable OpenMP/threaded support for the default, dense vector spaces.
        Note, many BLAS and LAPACK libraries such as those from ATLAS benefit
        from OpenMP directives.}

    \cmakeitem
        {ENABLE_BUILD_BLAS_AND_LAPACK}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {\textctref{LAPACK_ARCHIVE}}
        {No}
        {Builds BLAS and LAPACK from source in case an optimized version is not
        available.}

    \cmakeitem
        {LAPACK_ARCHIVE}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_BUILD_BLAS_AND_LAPACK}}
        {None}
        {No}
        {Location of the LAPACK archive downloaded from
        \href{http://www.netlib.org/lapack}{Netlib}.}

    \cmakeitem
        {ENABLE_BUILD_JSONCPP}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {\textctref{JSONCPP_ARCHIVE}}
        {No}
        {Builds JsonCpp from source.}

    \cmakeitem
        {JSONCPP_ARCHIVE}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_BUILD_JSONCPP}}
        {None}
        {No}
        {Location of the JsonCpp archive downloaded from
        \href{https://github.com/open-source-parsers/jsoncpp}{GitHub}.}

    \cmakeitem
        {BLAS_LIBRARY}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_CPP}}
        {None}
        {Yes }
        {A semicolon separated list of the complete path and library used
        to provide BLAS.  This must include all required libraries in
        order to successfully compile a BLAS dependent application.  For
        example, using ATLAS BLAS, one possible entry is:
        \begin{center}
            \textct{/usr/lib/libf77blas.a;/usr/lib/libatlas.a}
        \end{center}}

    \cmakeitem
        {LAPACK_LIBRARY}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_CPP}}
        {None}
        {Yes}
        {A semicolon separated list of the complete path and library used
        to provide LAPACK.  This must include all required libraries,
        except for BLAS libraries specified in \textctref{BLAS_LIBRARY}, in
        order to successfully compile a LAPACK dependent application.
        For example, using ATLAS LAPACK, one possible entry is:
        \begin{center}
            \textct{/usr/lib/liblapack.a;/usr/lib/libgfortran.a}
        \end{center}
        Note, this example assumes that we include \textct{libatlas.a} in our \textctref{BLAS_LIBRARY} filepath.}

    \cmakeitem
        {JSONCPP_INCLUDE_DIR}
        {PATH}
        {None}
        {\textctref{ENABLE_CPP}}
        {None}
        {Yes}
        {A path that indicates where the jsoncpp headers have been
        installed.  The actual headers must be found in
        \textctalt{$JSONCPP_INCLUDE_DIR/json/}}.

    \cmakeitem
        {JSONCPP_LIBRARY}
        {FILEPATH}
        {None }
        {\textctref{ENABLE_CPP}}
        {None}
        {Yes }
        {Complete path and library for JsonCpp. }

    \cmakeitem
        {ENABLE_CPP_EXAMPLES}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {None}
        {No}
        {Enables the build and installation of simple examples that
        demonstrate the use of Optizelle.}

    \cmakeitem
        {ENABLE_CPP_UNIT}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {None}
        {No}
        {Enables the build of unit tests that help validate the
        Optizelle code.  Execute these unit tests by running
        \textct{ctest} in the CMake build directory.}

    \cmakeitem
        {ENABLE_PYTHON}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {\textctref{PYTHON_INCLUDE_DIR},
            \textctref{PYTHON_LIBRARY},
            \textctref{PYTHON_EXECUTABLE},
            \textctref{ENABLE_PYTHON_EXAMPLES},
            \textctref{ENABLE_PYTHON_UNIT}}
        {No}
        {Enables the build of the Python wrappers for Optizelle.}

    \cmakeitem
        {PYTHON_INCLUDE_DIR}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_PYTHON}}
        {None}
        {Yes}
        {A path that indicates where the Python headers have been
        installed.  We do not prefix these headers, so we look directly
        in the directory provided here.}

    \cmakeitem
        {PYTHON_LIBRARY}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_PYTHON}}
        {None}
        {Yes}
        {Complete path and library for Python. }

    \cmakeitem
        {PYTHON_EXECUTABLE}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_PYTHON}}
        {None}
        {Yes}
        {Complete path and executable for Python. }

    \cmakeitem
        {ENABLE_PYTHON_EXAMPLES}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_PYTHON}}
        {None}
        {No}
        {Enables the build and installation of simple examples that
        demonstrate the use of the Python wrappers for Optizelle.}

    \cmakeitem
        {ENABLE_PYTHON_UNIT}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_PYTHON}}
        {None}
        {No}
        {Enables the build of unit tests that help validate the
        Python wrappers for the Optizelle code.  Execute these unit
        tests by running \textct{ctest} in the CMake build directory.}

    \cmakeitem
        {ENABLE_MATLAB}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {\textctref{MATLAB_MEX_EXTENSION},
            \textctref{MATLAB_INCLUDE_DIR},
            \textctref{MATLAB_LIBRARY},
            \textctref{MATLAB_EXECUTABLE},\linebreak
            \textctref{ENABLE_BUILD_JSONLAB},
            \textctref{JSONLAB_DIR},\linebreak
            \textctref{ENABLE_MATLAB_EXAMPLES},
            \textctref{ENABLE_MATLAB_UNIT}}
        {No}
        {Enables the build of the MATLAB wrappers for Optizelle.}

    \cmakeitem
        {MATLAB_MEX_EXTENSION}
        {STRING}
        {None}
        {\textctref{ENABLE_MATLAB}}
        {None}
        {No}
        {Extension of mex files on the system.  This can be found
        by typing in the command 'mexext' inside of MATLAB.}

    \cmakeitem
        {MATLAB_INCLUDE_DIR}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_MATLAB}}
        {None}
        {Yes }
        {Path that indicates where the MATLAB header \textct{mex.h} has
        been installed.  We do not prefix these headers, so we look directly in
        the directory provided here.  Generally, this is generally the
        \textct{extern/include} directory inside the primary MATLAB directory.}

    \cmakeitem
        {MATLAB_LIBRARY}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_MATLAB}}
        {None}
        {Yes}
        {Complete path and library for MATLAB, \textct{mex}.  Sometimes, we
        have to include the \textct{mx} library as well.  If compilation fails
        and there are several undefined symbols with prefixed
        with mx, then add the \textct{mx} library and separate it from
        \textct{mex} with a semicolon.  Generally, these libraries are
        generally found nested within the \textct{bin} directory in the primary
        MATLAB folder.}

    \cmakeitem
        {MATLAB_EXECUTABLE}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_MATLAB}}
        {None}
        {No}
        {Complete path and executable for MATLAB. }

    \cmakeitem
        {ENABLE_MATLAB_EXAMPLES}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_MATLAB}}
        {None}
        {No}
        {Enables the build and installation of simple examples that
        demonstrate the use of the MATLAB wrappers for Optizelle.}

    \cmakeitem
        {ENABLE_MATLAB_UNIT}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_MATLAB}}
        {None}
        {No}
        {Enables the build of unit tests that help validate the
        MATLAB wrappers for the Optizelle code.  Execute these unit
        tests by running \textct{ctest} in the CMake build directory.}

    \cmakeitem
        {ENABLE_OCTAVE}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_CPP}}
        {\textctref{OCTAVE_INCLUDE_DIR},
            \textctref{OCTAVE_LIBRARY},
            \textctref{OCTAVE_EXECUTABLE},\linebreak
            \textctref{ENABLE_BUILD_JSONLAB},
            \textctref{JSONLAB_DIR},\linebreak
            \textctref{ENABLE_OCTAVE_EXAMPLES},
            \textctref{ENABLE_OCTAVE_UNIT}}
        {No}
        {Enables the build of the Octave wrappers for Optizelle.}

    \cmakeitem
        {OCTAVE_INCLUDE_DIR}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_OCTAVE}}
        {None}
        {Yes }
        {Path that indicates where the Octave header \textct{mex.h} has
        been installed.  We do not prefix these headers, so we look directly in
        the directory provided here.  Generally, this is the folder called
        \textct{octave-x.x.x/octave} inside the system \textct{include}
        directory where \textct{x.x.x} denotes the version number.}

    \cmakeitem
        {OCTAVE_LIBRARY}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_OCTAVE}}
        {None}
        {Yes}
        {Complete path and library for Octave, \textct{octinterp}.  Generally,
        this library is found nested within the \textct{octave} directory
        inside the system \textct{lib} directory.}

    \cmakeitem
        {OCTAVE_EXECUTABLE}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_OCTAVE}}
        {None}
        {No}
        {Complete path and executable for Octave. }

    \cmakeitem
        {ENABLE_OCTAVE_EXAMPLES}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_OCTAVE}}
        {None}
        {No}
        {Enables the build and installation of simple examples that
        demonstrate the use of the Octave wrappers for Optizelle.}

    \cmakeitem
        {ENABLE_OCTAVE_UNIT}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_OCTAVE}}
        {None}
        {No}
        {Enables the build of unit tests that help validate the Octave wrappers
        for the Optizelle code.  Execute these unit tests by running
        \textct{ctest} in the CMake build directory.}

    \cmakeitem
        {ENABLE_BUILD_JSONLAB}
        {BOOL}
        {\textct{OFF}}
        {\textctref{ENABLE_MATLAB} or \textctref{ENABLE_OCTAVE}}
        {\textctref{JSONLAB_ARCHIVE}}
        {No}
        {Builds jsonlab from source.}

    \cmakeitem
        {JSONLAB_ARCHIVE}
        {FILEPATH}
        {None}
        {\textctref{ENABLE_BUILD_JSONLAB}}
        {None}
        {No}
        {Location of the json archive downloaded from
        \href{https://github.com/fangq/jsonlab}{GitHub}.}

    \cmakeitem
        {JSONLAB_DIR}
        {PATH}
        {None}
        {\textctref{ENABLE_MATLAB} or \textctref{ENABLE_OCTAVE}}
        {None}
        {Yes}
        {A path that indicates where the jsonlab library has been
        installed.  This is automatically set when \textctref{ENABLE_BUILD_JSONLAB} is enabled.}
\end{boldlist}

\section{Platform Specific Configuration}

    Due to a variety of platform specific quirks, some additional compilation flags may be necessary.  In order to use these flags, place them in the \textct{CMAKE_CXX_FLAGS} variable, separated by spaces, in the CMake configuration.
\begin{boldlist}
    \configitem
        {-include math.h}
        {Windows}
        {Python}
        {During compilation, \textct{error: '::hypot' has not been declared}}
        {Fixes a bug inside of Python where \textct{hypot} has been renamed}

    \configitem
        {-DMS_WIN64}
        {Windows}
        {Python}
        {During compilation, \textct{undefined reference to `__imp_Py_InitModule4'}}
        {Tells Python to use Windows 64-bit specific code}
\end{boldlist}

\noindent In addition, the following flags may need to be added to the \textct{CMAKE_Fortran_FLAGS} variable when the compilation also builds BLAS/LAPACK

\begin{boldlist}
    \configitem
        {-Wl,--allow-multiple-definition}
        {Windows}
        {C++}
        {During compilation, \textct{multiple definition of `_gfortran_st_write_done'}}
        {Fixes a bug that occurs when BLAS/LAPACK is compiled with MinGW}
\end{boldlist}


\chapter{Basic API}\label{ch:Basic}

        We organize Optizelle's algorithms into four different categories:
\begin{center}
    \usebox{\boxOptimizationTypes}
\end{center}
\noindent Since these formulations necessitate different algorithms, we segregate the overall structure of Optizelle and the algorithms themselves into these categories.
        In order to optimize these formulations, we follow the general procedure:
\begin{enumerate}
    \item \hyperref[sec:import]{\secimport}
    \item \hyperref[sec:importvs]{\secimportvs}
    \item \hyperref[sec:objective]{\secobjective}
    \item \hyperref[sec:constraints]{\secconstraints}
    \item \hyperref[sec:preconditioners]{\secpreconditioners}
    \item \hyperref[sec:state]{\secstate}
    \item \hyperref[sec:params]{\secparams}
    \item \hyperref[sec:fns]{\secfns}
    \item \hyperref[sec:solve]{\secsolve}
    \item \hyperref[sec:extract]{\secextract}
    \item \hyperref[sec:compilerun]{\seccompilerun}
\end{enumerate}
We discuss how to implement each of the above steps below.

\section{\secimport}\label{sec:import}

        Each interface uses its own method to import Optizelle:
\begin{boldlist}
    \restartitemalt
        {C++}
        {C++}
        {Import0-Import1}
        {0}
        {cpp}

    \restartitem
        {Python}
        {Python}
        {Import0-Import1}
        {0}
        {py}

    \restartitemalt
        {MATLAB/Octave}
        {Matlab}
        {Import0-Import1}
        {0}
        {m}
\end{boldlist}

\noindent In C++, we always require \textct{optizelle/optizelle.h}, but only require \textct{optizelle/json.h} when working with JSON and \textct{optizelle/vspaces.h} when using our default vector spaces such as \textctref{Optizelle::Rm} and \textctref{Optizelle::SQL}.  In Python, we simply need to include the \textct{Optizelle} module and everything else is automatically imported.  Finally, in MATLAB/Octave, we encapsulate all of the required functions in the global variable \textct{Optizelle}.

\section{\secimportvs}\label{sec:importvs}
        In the optimization problems
\begin{center}
    \usebox{\boxOptimizationTypes}
\end{center}
\noindent we require that
\begin{align*}
    f :& X\rightarrow\re\\
    g :& X\rightarrow Y\\
    h :& X\rightarrow Z.
\end{align*}
Here, the spaces $X$, $Y$, and $Z$ denote {\it vector spaces}, more specifically, Hilbert spaces.  For most problems, these vector spaces just denote $\re^m$, but we also allow these vector spaces to be spaces of functions such as $L^2(\Omega)$ or matrices such as $\re^{m\times n}$ as long as they contain the necessary operations that we describe in the section \hyperref[sec:customvector]{\seccustomvector}.

        A vector space consists of two separate pieces: the actual vector and the operations required to compute on this vector.  In Optizelle, we maintain this separation.  For $\re^m$, we provide a reasonable implementation of the vector space with the following:
\phantomsection\label{itm:Rm}
\phantomsection\label{itm:Optizelle::Rm}
\phantomsection\label{itm:Optizelle.Rm}
\begin{boldlist}
    \vsitem
        {C++}
        {\textct{std::vector}}
        {\textct{Optizelle::Rm}}
    \vsitem
        {C++}
        {\textct{numpy.array}}
        {\textct{Optizelle.Rm}}
    \vsitem
        {MATLAB/Octave}
        {\textct{[]} (column vector)}
        {\textct{Optizelle.Rm}}
\end{boldlist}
\noindent To be precise, each of these vector spaces uses the inner product $\langle x,y\rangle=x^Ty$ and defines inequalities pointwise, $x\succeq y \Longleftrightarrow x_i \geq y_i$ for all $1\leq i\leq m$.  Note, we don't require users to use these vector operations in their code.  Simply, if we're happy using the above vectors, we can use these operations exclusively in Optizelle and forget their details.

\section{\secobjective}\label{sec:objective}

        In the optimization problems
\begin{center}
    \usebox{\boxOptimizationTypes}
\end{center}
\noindent the function $f:X\rightarrow\re$ denotes the \textit{objective function}.  Note, we restrict ourselves to scalar-valued functions and do not consider multi-objective optimization problems.

        In order to optimize with this function, we require information about its evaluation and derivatives.  Specifically, we require its evaluation, $f(x)$, and gradient, $\nabla f(x)$.  In order to use second-order algorithms, we also require the Hessian-vector product, $\nabla^2 f(x)\delta x$.  In the case that $f:\re^m\rightarrow\re$, we can obtain each of these quantities from its partial derivatives.  Specifically, we write
$$
        f(x)=f(x_1,\dots,x_m).
$$
Then, we have that
\begin{align*}
        \nabla f(x) =& \begin{bmatrix}
            \frac{\partial f}{\partial x_1}(x)\\
            \vdots\\
            \frac{\partial f}{\partial x_m}(x)
        \end{bmatrix},\\
        \nabla^2 f(x)\delta x =& \begin{bmatrix}
            \frac{\partial f}{\partial x_{11}}(x) & \dots & \frac{\partial f}{\partial x_{1m}}(x)\\
            \vdots & \ddots & \vdots\\
            \frac{\partial f}{\partial x_{m1}}(x) & \dots & \frac{\partial f}{\partial x_{mm}}(x)
        \end{bmatrix}\delta x.
\end{align*}

        In code, we specify this function as:
\phantomsection\label{itm:ScalarValuedFunction}
\begin{boldlist}
    \apiitem
        {C++}
        {\textct{Optizelle::ScalarValuedFunction}}
        {Inheritance}
        {\lstinputlisting[style=C++,linerange={Optizelle0-Optizelle1,ScalarValuedFunction0-ScalarValuedFunction1,Optizelle2-Optizelle3}]{@OPTIZELLECPPPATH@/optizelle.h}}

    \apiitem
        {Python}
        {\textct{Optizelle.ScalarValuedFunction}}
        {Inheritance}
        {\lstinputlisting[style=Python,linerange=ScalarValuedFunction0-ScalarValuedFunction1]{@OPTIZELLEPYTHONPATH@/Functions.py}}

    \apiitem
        {MATLAB/Octave}
        {\textct{Optizelle.ScalarValuedFunction}}
        {Members present}
        {\lstinputlisting[style=Matlab,linerange=ScalarValuedFunction0-ScalarValuedFunction1]{@OPTIZELLEMATLABPATH@/setupOptizelle.m}}
\end{boldlist}
\noindent Note, we require that the Hessian-vector product always be present.  If one is not available, we simply return zero.

        As an example, in our \exampleref{\secrosenbrock}{sec:rosenbrock} example, we minimize the function $f:\re^2\rightarrow \re$ where
$$
        f(x)=(1-x_1)^2+100(x_2-x_1^2)^2.
$$
This function has a gradient of
$$
        \nabla f(x)=\begin{bmatrix}
            -400x_1(x_2-x_1^2)-2(1-x_1)\\
            200(x_2-x_1^2)
        \end{bmatrix}
$$
and Hessian-vector product of
$$
        \nabla^2 f(x)\delta x=
        \begin{bmatrix}
            1200x_1^2-400x_2+2 & -400x_1\\
            -400x_1 & 200
        \end{bmatrix}\delta x.
$$
Using Optizelle's internal vector spaces, we implement these functions as:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Objective0-Objective1]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Objective0-Objective1]{@ROSENBROCKPATH@/rosenbrock.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Objective0-Objective1]{@ROSENBROCKPATH@/rosenbrock.m}}
\end{boldlist}

        In our \exampleref{\secequality}{sec:equality} example, we have an objective $f:\re^2\rightarrow \re$ where
$$
        f(x)=x_1^2+x_2^2
$$
This function has a gradient of
$$
        \nabla f(x)=\begin{bmatrix}
            2x_1\\
            2x_2
        \end{bmatrix}
$$
and Hessian-vector product of
$$
        \nabla^2 f(x)\delta x=
        \begin{bmatrix}
            2 & 0\\
            0 & 2
        \end{bmatrix}\delta x.
$$
We implement this function with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Objective0-Objective1]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Objective0-Objective1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Objective0-Objective1]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\secconstraints}\label{sec:constraints}
        In the optimization problems
\begin{center}
    \usebox{\boxOptimizationTypes}
\end{center}
\noindent the vector-valued functions $g:X\rightarrow Y$ and $h:X\rightarrow Z$ denote the \textit{equality} and \textit{inequality constraints}, respectfully.  Here, we allow the equality constraints to be nonlinear, but require that the inequality constraints be affine.  Recall, an affine function is one where $h(\alpha x+(1-\alpha)x)=\alpha h(x)+(1-\alpha)h(y)$ for all $\alpha\in\re$ or equivalently where $h^{\prime\prime}(x)=0$.  We require affine inequality constraints in order to simplify the line search that maintains the nonnegativity of the inequality constraints.

        In case we have a nonlinear inequality constraint, we must reformulate the problem in order to make it affine.  The easiest method for doing so is through the reformulations
$$\left.\begin{array}{rcl}
        \min\limits_{x\in X} && f(x)\\
        \st && h(x)\succeq 0
\end{array}\right\}
\leadsto
\left\{\begin{array}{rcl}
        \min\limits_{x\in X,z\in Z} && f(x)\\
        \st && h(x)-z=0\\
            && z\succeq 0
\end{array}\right.$$
and
$$\left.\begin{array}{rcl}
        \min\limits_{x\in X} && f(x)\\
        \st && g(x)=0\\
            && h(x)\succeq 0
\end{array}\right\}
\leadsto
\left\{\begin{array}{rcl}
        \min\limits_{x\in X,z\in Z} && f(x)\\
        \st && \begin{bmatrix}g(x)\\h(x)-z\end{bmatrix}=\begin{bmatrix}0\\0\end{bmatrix}\\
            && z\succeq 0.
\end{array}\right.$$

        Similar to the objective function, we require derivative information in order optimize effectively.  Specifically, we require the evaluation, $g(x)$, Fr\'{e}chet (total) derivative applied to a vector, $g^\prime(x)\delta x$, and the adjoint of the Fr\'{e}chet derivative applied to a vector, $g^\prime(x)^*\delta y$.  In order to use second order algorithms, we also require the second derivative operation $(g^{\prime\prime}(x)\delta x)^*\delta y$.  Note, we require the same operations from $h$, but since $h$ is affine, $(h^{\prime\prime}(x)\delta x)^*\delta z=0$.  In the case that $g:\re^m\rightarrow\re^n$ and we use the inner product $\langle x,y\rangle=x^Ty$ for both $\re^m$ and $\re^n$, the derivation of these derivatives is quite simple.  Here, we write $g$ as
$$
    g(x)=\begin{bmatrix}
        g_1(x)\\
        \vdots\\
        g_n(x)
        \end{bmatrix}.
$$
This means that we have
\begin{align*}
    g^\prime(x)\delta x =& \begin{bmatrix}
        \nabla g_1(x)^T\\
        \vdots\\
        \nabla g_n(x)^T
    \end{bmatrix}\delta x\\
    g^\prime(x)^*\delta y =& \begin{bmatrix}
        \nabla g_1(x) & \dots & \nabla g_n(x)
    \end{bmatrix} \delta y\\
    (g^{\prime\prime}(x)\delta x)^*\delta y =& \sum_{i=1}^n \delta y_i \nabla^2 g_i(x) \delta x.
\end{align*}

        In code, these derivatives become:
\phantomsection\label{itm:VectorValuedFunction}
\begin{boldlist}
    \apiitem
        {C++}
        {\textct{Optizelle::VectorValuedFunction}}
        {Inheritance}
        {\lstinputlisting[style=C++,linerange={Optizelle0-Optizelle1,VectorValuedFunction0-VectorValuedFunction1,Optizelle2-Optizelle3}]{@OPTIZELLECPPPATH@/optizelle.h}}

    \apiitem
        {Python}
        {\textct{Optizelle.VectorValuedFunction}}
        {Inheritance}
        {\lstinputlisting[style=Python,linerange=VectorValuedFunction0-VectorValuedFunction1]{@OPTIZELLEPYTHONPATH@/Functions.py}}

    \apiitem
        {MATLAB/Octave}
        {\textct{Optizelle.VectorValuedFunction}}
        {Members present}
        {\lstinputlisting[style=Matlab,linerange=VectorValuedFunction0-VectorValuedFunction1]{@OPTIZELLEMATLABPATH@/setupOptizelle.m}}
\end{boldlist}
\noindent Note, we require that the second derivative always be present.  If one is not available, we simply return zero.


        For example, in our \exampleref{\secequality}{sec:equality} example, we define a simple equality constraint as
$$
    g(x)=\begin{bmatrix}
        (x_1-2)^2 + (x_2-2)^2 - 1
    \end{bmatrix}.
$$
Then, we have that
\begin{align*}
    g^\prime(x)\delta x=&\begin{bmatrix}
        2(x_1-2) & 2(x_2-2)
    \end{bmatrix}\delta x\\
    g^\prime(x)^*\delta y=&
        \begin{bmatrix}
            2(x_1-2)\\
            2(x_2-2)
        \end{bmatrix} \delta y\\
    (g^{\prime\prime}(x)\delta x)^*\delta y=&
        \delta y \begin{bmatrix}
            2 & 0\\
            0 & 2
        \end{bmatrix}\delta x
\end{align*}
Using Optizelle's internal vector spaces, we implement these functions as:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=EqualityConstraint0-EqualityConstraint1]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=EqualityConstraint0-EqualityConstraint1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=EqualityConstraint0-EqualityConstraint1]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\secpreconditioners}\label{sec:preconditioners}

        Since Optizelle is fully matrix-free, its performance depends highly on the quality of the preconditioners provided to it by the user.  To that end, there are two places where preconditioning matters:  the Hessian of the objective function and a KKT system that relates to the equality constraints.  Specifically, we benefit when we can define $P_H:X\rightarrow X$ such that
$$
        P_H \approx \nabla^2 f(x)^{-1}
$$
and $P_l:Y\rightarrow Y$ along with $P_r:Y\rightarrow Y$ such that
$$
        P_l(g^\prime(x)g^\prime(x)^*)P_r\approx I.
$$

        Before we discuss these operators in detail, let us emphasize two points.  First, as we describe below, we require only the action of this preconditioner on a vector.  This enables Optizelle to continue to be matrix-free.  Second, even though we use matrix-free abstractions, most of the time, we're better off just using matrices.  At this point in time, both dense and sparse linear algebra libraries are extremely fast.  Unless we have a large PDE constrained optimization problem, just form a matrix of the operator, factor it, and move on.

        In the objective function, we use a preconditioner for the Hessian in several different places.  Foremost, we use it to precondition linear systems related to second-order algorithms such as Newton's method.  In addition, we use it within first-order algorithms such as nonlinear-CG and steepest descent.  Certainly, $\nabla^2 f(x)^{-1}$ represents the best such preconditioner, but the Hessian may become singular during the course of optimization, so we must take care in how we generate this preconditioner.  As such, even though $\nabla^2 f(x)$ is self-adjoint, the LU factorization provides a simple, effective manner to factorize the Hessian.  In other words, we find operators $L$ and $U$ such that
$$
        LU=\nabla^2 f(x).
$$
Then, our preconditioner $P_H:X\rightarrow X$ approximates
$$
        P_H\delta x \approx U^{-1}L^{-1} \delta x.
$$
We say approximate because either $U^{-1}$ or $L^{-1}$ may not exist.  In this case, we note that the action of $U^{-1}$ and $L^{-1}$ on a vector denotes a back and forward solve, respectively.  When the inverse does not exist, we can simply modify these solves to ignore any variables that cause problems.

        As a note, we only benefit from a Hessian preconditioner in unconstrained and inequality constrained problems.  For problems with equality constraints, we use a composite-step SQP method.  Here, the tangential subproblem requires a null-space projection that replaces the Hessian preconditioner.  If preconditioning the quantities in the objective is important to the performance of the problem, then we need to reformulate the problem, so that these quantities appear as equality constraints and then use an appropriate Schur preconditioner below.  For example, we can reformulate the problem
$$
        \min\limits_{x\in X}\{f(x) : g(x) = 0\}
$$
as
$$
        \min\limits_{x\in X,x_0\in \re}\{x_0 : x_0 = f(x), g(x) = 0\}.
$$
Note, this transformation may destroy convexity of the problem, so a different transformation may be more appropriate.

        For the equality constraints, our algorithms require the repeated solution of a system whose operator is
$$\begin{bmatrix}
        I & g^\prime(x)^*\\
        g^\prime(x) & 0
\end{bmatrix}.$$
As it happens, if $g^\prime(x)$ is full-rank, the preconditioner
$$\begin{bmatrix}
        I & 0\\
        0 & (g^\prime(x)g^\prime(x)^*)^{-1}
\end{bmatrix}$$
allows a Krylov method to solve the above system in three iterations.  As such, Optizelle focuses on preconditioning the operator
$$
        g^\prime(x)g^\prime(x)^*.
$$
Note, unlike the Hessian, we allow both left and right preconditioners for this operator.  In addition, this operator depends on the inner product used by the vector space because it involves an adjoint.  If we're working in $\re^m$ with the inner product $\langle x,y\rangle = x^Ty$, we can ignore this nuance.  Otherwise, we must modify our factorizations to correctly account for the change in inner product.  Outside of this difficulty, we note the operator is always symmetric and positive-semidefinite.  However, like the Hessian, it can and likely will become singular during the course of optimization.  As such, we propose two ways of dealing with this.  In one case, we use a $QR$ factorization of $g^\prime(x)^*$,
$$
        Q R = g^\prime(x)^*,
$$
then form the preconditioners $P_l: Y\rightarrow Y$ and $P_r: Y\rightarrow Y$ where
\begin{align*}
    P_l \delta x \approx& R^{-1}R^{-*}\delta x,\\
    P_r \delta x =& \delta x .
\end{align*}
Again, we must take care in case $R$ is singular.  Alternatively, we can just form $g^\prime(x)g^\prime(x)^*$ and find its $LU$ factorization like we do with the Hessian,
$$
        LU = g^\prime(x)g^\prime(x)^*.
$$
This gives us the preconditioners
\begin{align*}
        P_l\delta x \approx & U^{-1}L^{-1} \delta x,\\
        P_r\delta x = & \delta x.
\end{align*}
In theory, we can use a Choleski factorization to solve this system.  The problem with this approach is that the Choleski factorization will fail when $g^\prime(x)$ is not full rank.  Generally, we find it easier to fix a failing forward or back solve, as is the case with a QR or LU factorization, than to fix a failing factorization.

        In code, we represent preconditioners as a generic linear operator:
\phantomsection\label{itm:Operator}
\begin{boldlist}
    \apiitem
        {C++}
        {\textct{Optizelle::Operator}}
        {Inheritance}
        {\lstinputlisting[style=C++,linerange={Optizelle0-Optizelle1,Operator0-Operator1,Optizelle2-Optizelle3}]{@OPTIZELLECPPPATH@/linalg.h}}

    \apiitem
        {Python}
        {\textct{Optizelle.Operator}}
        {Inheritance}
        {\lstinputlisting[style=Python,linerange=Operator0-Operator1]{@OPTIZELLEPYTHONPATH@/Functions.py}}

    \apiitem
        {MATLAB/Octave}
        {\textct{Optizelle.Operator}}
        {Members present}
        {\lstinputlisting[style=Matlab,linerange=Operator0-Operator1]{@OPTIZELLEMATLABPATH@/setupOptizelle.m}}
\end{boldlist}
As we can see, there is a slight difference when we compare C++ to Python and MATLAB/Octave.  In Python and MATLAB/Octave, we provide the preconditioner with the variable \textct{state} that we describe in the section \hyperref[sec:state]{\secstate}.  We omit this variable in C++.  If we need access to the state in C++, we can simply pass in a reference to it during the operator's construction.  In Python and MATLAB/Octave, this is not an option, so we must pass the state directly.  To be clear, access to the variable \textct{state} is important for most preconditioners.  Recall, we must either evaluate an approximation to $\nabla^2 f(x)^{-1} \delta x$ or $(g^\prime(x)g^\prime(x)^*)^{-1}\delta y$.  When Optizelle calls the preconditioner, it provides $\delta x$ and $\delta y$ and expects $P_H\delta x$, $P_l\delta y$, and $P_r\delta y$ as its return.  Optizelle does \textbf{not} call the preconditioner on the variables $x$ and $y$.  If we want access to these variables, we must find them in the state.

        As another important note, Optizelle can not optimize user defined factorizations.  Meaning, during the course of an optimization iteration, we call these preconditioners several different times at the same optimization iterate, $x$.  As such, if we factorize $\nabla^2 f(x)$ or $g^\prime(x)g^\prime(x)^*$, it is critical to our performance that we cache these factorizations.  The easiest way to tell when a new factorization is needed is to monitor the variable \textct{x} inside of \textct{state}.  This variable represents the current optimization iterate and it does not change until we take a new step in the optimization algorithms.

        Recall, in our \exampleref{\secrosenbrock}{sec:rosenbrock} example, we have a Hessian-vector product of
$$
        \nabla^2 f(x)\delta x=
        \begin{bmatrix}
            1200x_1^2-400x_2+2 & -400x_1\\
            -400x_1 & 200
        \end{bmatrix}\delta x.
$$
This allows us to find the inverse using Cramer's rule
$$
        \nabla^2 f(x)^{-1}\delta x=
        \frac{1}{80000x_1^2-80000x_2+400}
        \begin{bmatrix}
            200 & 400x_1\\
            400x_1 & 1200x_1^2-400x_2+2
        \end{bmatrix}\delta x.
$$
Generally, we claim using Cramer's rule is a bad idea when compared to an LU factorization, but it works fine on this small example.  Using this formulation, we define our preconditioner to the Hessian with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Preconditioner0-Preconditioner1]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Preconditioner0-Preconditioner1]{@ROSENBROCKPATH@/rosenbrock.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Preconditioner0-Preconditioner1]{@ROSENBROCKPATH@/rosenbrock.m}}
\end{boldlist}

        For our simple equality constraint
$$
    g(x)=\begin{bmatrix}
        (x_1-2)^2 + (x_2-2)^2 - 1
    \end{bmatrix}.
$$
We have that
\begin{align*}
    g^\prime(x)\delta x=&\begin{bmatrix}
        2(x_1-2) & 2(x_2-2)
    \end{bmatrix}\delta x\\
    g^\prime(x)^*\delta y=&
        \begin{bmatrix}
            2(x_1-2)\\
            2(x_2-2)
        \end{bmatrix} \delta y.
\end{align*}
This means that
$$
        g^\prime(x)g^\prime(x)^*\delta y=(4(x_1-2)^2+4(x_2-2)^2)\delta y
$$
and we have a perfect preconditioner
$$
        (g^\prime(x)g^\prime(x)^*)^{-1}\delta y=\frac{1}{4(x_1-2)^2+4(x_2-2)^2}\delta y.
$$
We implement this in our \exampleref{\secequality}{sec:equality} example with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Preconditioner0-Preconditioner1]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Preconditioner0-Preconditioner1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Preconditioner0-Preconditioner1]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\secstate}\label{sec:state}

        In Optizelle, the optimization state contains an entire description of the current state of the optimization algorithm.  This is unique to the particular optimization formulation, but all algorithms in a particular formulations share the same state.  Most algorithms do not require information about all of these pieces, but they are present to make it easier to switch from one algorithm to another.  For example, trust-region and line-search algorithms share several components, but the trust-region radius is unique to trust-region algorithms and the line-search step length is unique to line-search algorithms.  Nevertheless, we may want to switch from one algorithm to another, so they share the same components.

        In order to define an optimization state, we instantiate the state class within the particular class of formulation we require.  The syntax is:
\phantomsection\label{itm:State}
\begin{boldlist}
    \restartitem
        {C++}
        {C++}
        {State0-State1}
        {1}
        {cpp}

    \restartitem
        {Python}
        {Python}
        {State0-State1}
        {0}
        {py}

    \restartitem
        {MATLAB/Octave}
        {Matlab}
        {State0-State1}
        {0}
        {m}
\end{boldlist}

\noindent Here, \textct{XX}, \textct{YY}, and \text{ZZ} correspond to the vector spaces $X$, $Y$, and $Z$ described in the section \hyperref[sec:importvs]{\secimportvs}.  Likely, they are just \textctref{Optizelle::Rm} or \textctref{Optizelle.Rm}.  Next, the variable \textct{x} denotes an initial guess for the optimization problem.  This guess is very important to the performance of the algorithms, so choose wisely.  The variables \textct{y} and \textct{z} represent arbitrary elements in the codomain of $g$ and $h$, respectively.  We do not use the values of these variables, so any properly allocated vector works fine.

    As an example, we create the optimization state in the \exampleref{\secrosenbrock}{sec:rosenbrock} example with the following code:

\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=State0-State1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=State0-State1]{@ROSENBROCKPATH@/rosenbrock.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=State0-State1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.m}}
\end{boldlist}
In our \exampleref{\secequality}{sec:equality} example, we have:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=State0-State1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=State0-State1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=State0-State1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\secparams}\label{sec:params}

        For each optimization problem, the parameters required for an efficient optimization solve can vary wildly.  Nevertheless, the parameters that guide this process reside within the state object.  There are two mechanisms for modifying these entries.  First, the state object created in the section \hyperref[sec:state]{\secstate} is simply an object with a variety of elements that can be modified directly.  Alternatively, and preferably, we can use the JSON reader.  The syntax for reading a parameter file in JSON format from file is:
\begin{boldlist}
    \restartitem
        {C++}
        {C++}
        {ReadJson0-ReadJson1}
        {1}
        {cpp}

    \restartitem
        {Python}
        {Python}
        {ReadJson0-ReadJson1}
        {0}
        {py}

    \restartitem
        {MATLAB/Octave}
        {Matlab}
        {ReadJson0-ReadJson1}
        {0}
        {m}
\end{boldlist}
Here, most of the parameters required are identical to those required in the section \hyperref[sec:state]{\secstate}.  The lone, new parameter is \textct{fname}, which corresponds to a string of the file name where we read the JSON formatted parameters.  As to what these parameters are, we discuss that in the chapter \hyperref[ch:params]{\chparams}.

        In our \exampleref{\secrosenbrock}{sec:rosenbrock} example, we use the following code to read the optimization parameters:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Parameters0-Parameters1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Parameters0-Parameters1]{@ROSENBROCKPATH@/rosenbrock.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Parameters0-Parameters1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.m}}
\end{boldlist}
This becomes the following in our \exampleref{\secequality}{sec:equality} example:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Parameters0-Parameters1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Parameters0-Parameters1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Parameters0-Parameters1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\secfns}\label{sec:fns}

        In order to pass the functions used in the optimization to Optizelle, we accumulate each of them into a bundle of functions.  These bundles are simple structures that contain the appropriate function.  The syntax for creating these objects is:
\begin{boldlist}
    \restartitem
        {C++}
        {C++}
        {Functions0-Functions1}
        {1}
        {cpp}

    \restartitem
        {Python}
        {Python}
        {Functions0-Functions1}
        {0}
        {py}

    \restartitem
        {MATLAB/Octave}
        {Matlab}
        {Functions0-Functions1}
        {0}
        {m}
\end{boldlist}
\noindent As was the case in the section \hyperref[sec:state]{\secstate}, \textct{XX}, \textct{YY}, and \text{ZZ} correspond to the vector spaces $X$, $Y$, and $Z$ described in the section \hyperref[sec:importvs]{\secimportvs}.  Likely, they are just \textctref{Optizelle::Rm} or \textctref{Optizelle.Rm}.

        Now, each of structures contains a number of required and optional elements.  We summarize these elements as follows:
\begin{boldlist}
    \functionitem
        {f}
        {ScalarValuedFunction}
        {\classUnconstrained}
        {Yes}
        {Objective function.}

    \functionitem
        {PH}
        {Operator}
        {\classUnconstrained}
        {No}
        {Preconditioner for the Hessian of the objective function, $\nabla^2 f(x)$.}

    \functionitem
        {g}
        {VectorValuedFunction}
        {\classEquality}
        {Yes}
        {Equality constraint.}

    \functionitem
        {PSchur_left}
        {Operator}
        {\classEquality}
        {No}
        {Left Schur preconditioner for derivative of the equality constraint, $g^\prime(x)g^\prime(x)^*$.}

    \functionitem
        {PSchur_right}
        {Operator}
        {\classEquality}
        {No}
        {Right Schur preconditioner for derivative of the equality constraint, $g^\prime(x)g^\prime(x)^*$.}

    \functionitem
        {h}
        {VectorValuedFunction}
        {\classInequality}
        {Yes}
        {Inequality constraint.}
\end{boldlist}
\noindent In C++, we represent each of the these elements as a \textct{std::unique_ptr} using the type specified above.  In Python, we use simple class elements.  In MATLAB/Octave, we use a structure array.  As a final note, since they are optional, we do \textbf{not} utilize \textctref{PH}, \textctref{PSchur_left}, or \textctref{PSchur_right} by default even when they are defined.  In order to active these functions, we must modify the \textctref{PH_type}, \textctref{PSchur_left_type}, and \textctref{PSchur_right_type} elements in the state, respectively.  We describe these variables in the chapter \hyperref[ch:params]{\chparams}.

        In our \exampleref{\secrosenbrock}{sec:rosenbrock} example, we accumulate our functions with the following code:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Functions0-Functions1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Functions0-Functions1]{@ROSENBROCKPATH@/rosenbrock.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Functions0-Functions1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.m}}
\end{boldlist}
\noindent As another example, we accomplish the same task in our \exampleref{\secequality}{sec:equality} example with the code:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Functions0-Functions1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Functions0-Functions1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Functions0-Functions1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}


\section{\secsolve}\label{sec:solve}

       Once the state, parameters, and functions are set, calling the optimization solver is straightforward.  Simply, we call one of the four commands:
\begin{boldlist}
    \restartitem
        {C++}
        {C++}
        {Solver0-Solver1}
        {1}
        {cpp}

    \restartitem
        {Python}
        {Python}
        {Solver0-Solver1}
        {0}
        {py}

    \restartitem
        {MATLAB/Octave}
        {Matlab}
        {Solver0-Solver1}
        {0}
        {m}
\end{boldlist}
\noindent As was the case in the section \hyperref[sec:state]{\secstate}, \textct{XX}, \textct{YY}, and \text{ZZ} correspond to the vector spaces $X$, $Y$, and $Z$ described in the section \hyperref[sec:importvs]{\secimportvs}.  Likely, they are just \textctref{Optizelle::Rm} or \textctref{Optizelle.Rm}.  Next, we call the function with a \textctref{Messaging} object, \textct{msg}.  In the simple case, we can simply use \textctref{Optizelle::Messaging::stdout} in C++, \textctref{Optizelle.Messaging.stdout} in Python, and \textctref{Optizelle.Messaging.stdout} in MATLAB/Octave.  For more complicated cases, see the section \hyperref[sec:messaging]{\secmessaging}.  Finally, we pass in the state and bundle of functions that we discussed in the sections \hyperref[sec:state]{\secstate} and \hyperref[sec:fns]{\secfns}, respectively.

        In our \exampleref{\secrosenbrock}{sec:rosenbrock} example, we call Optizelle's solver with the code:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Solver0-Solver1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Solver0-Solver1]{@ROSENBROCKPATH@/rosenbrock.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Solver0-Solver1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.m}}
\end{boldlist}
\noindent With the \exampleref{\secequality}{sec:equality} example, this becomes:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Solver0-Solver1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Solver0-Solver1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Solver0-Solver1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\secextract}\label{sec:extract}

        After the optimization routine concludes, the solution resides inside of the optimization state in a variable called \textctref{x} and the reason we stopped the optimization resides in a variable called \textctref{opt_stop}.  At this point, we can examine our solution and run any post optimization diagnostics we require.

        In our \exampleref{\secrosenbrock}{sec:rosenbrock} example, we print out the final solution with the code:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Extract0-Extract1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Extract0-Extract1]{@ROSENBROCKPATH@/rosenbrock.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Extract0-Extract1,widthgobble=1*4]{@ROSENBROCKPATH@/rosenbrock.m}}
\end{boldlist}
\noindent In our \exampleref{\secequality}{sec:equality} example, this becomes:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Extract0-Extract1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Extract0-Extract1]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Extract0-Extract1,widthgobble=1*4]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\seccompilerun}\label{sec:compilerun}

        As a final step, we need to either compile or run the program.  Each language has its own nuances that we describe below.

\subsection{C++}

        By default, we install the C++ relevant headers and libraries to
\begin{center}\begin{minipage}[t]{1\columnwidth}
    \dirtree{%
        .1 /some/path.
        .2 lib.
        .3 liboptizelle.a.
        .3 optizelle.lib.
        .3 liboptizelle.so.
        .3 liboptizelle.dylib.
        .3 optizelle.dll.
        .2 include.
        .3 optizelle.
        .4 optizelle.h.
        .4 json.h.
        .4 vspaces.h.
    }
\end{minipage}\end{center}
where \textct{/some/path} denotes the installation directory.  Therefore, in order to compile an Optizelle program, we must add the directory
\begin{center}
        \textct{/some/path/include}
\end{center}
to the list of include directories and
\begin{center}
        \textct{/some/path/lib}
\end{center}
to the list of library directories.  For the static library, we link either \textct{liboptizelle.a} or \textct{optizelle.lib}.  For the dynamic library, we link either \textct{liboptizelle.so}, \textct{liboptizelle.dylib}, or \textct{optizelle.dll}.

        Note, Optizelle depends on JsonCpp, BLAS, and LAPACK as well.  Therefore, these headers and libraries must be included in any compilation command as well.  For example, in GCC, we may have the following set of build flags
\begin{center}
        \textct{-I/usr/include -L/usr/lib -L/usr/share/optizelle/thirdparty/lib -loptizelle -ljson -lblas -llapack}
\end{center}
where we assume \textctref{CMAKE_INSTALL_PREFIX}=\textct{/usr}.

\subsection{Python/MATLAB/Octave}

        We require no compilation.

\chapter{\chparams}\label{ch:params}

        The parameters that guide the optimization solver have a dramatic effect its performance.  To that end, we find each of these parameters within the optimization state that we initially discussed in the section \hyperref[sec:state]{\secstate}.  These parameters are based on the canonical formulations
\begin{center}
    \usebox{\boxOptimizationTypes}
\end{center}
\noindent and come in one of nine types:
\begin{boldlist}
    \typeitem
        {Real}
        {Floating point numbers.  In C++, this may be a type such as \textct{double} or \textct{float} as long as it matches the template parameters used in items such as \textct{state} and \textct{fns}.  In Python and Matlab/Octave, we use the default floating point representation.}

    \typeitem
        {Natural}
        {Nonnegative integer.  In C++, we use the type \textct{Optizelle::Natural}, which we set to be \textct{size_t}.  In Python, we use the default integer representation.  In MATLAB/Octave, we use the default floating point representation.}

    \typeitem
        {Enumerated}
        {Enumerated type.  In C++, we use an \textct{enum} type called \textct{t} wrapped inside a namespace that we type explicitly to \textct{Natural}.  For example, we refer to the algorithm class as \textctref{AlgorithmClass} and define its type as \textct{AlgorithmClass::t}.  Then, we refer to the enumerated values as:
        \begin{itemize}
            \item \textct{AlgorithmClass::TrustRegion}
            \item \textct{AlgorithmClass::LineSearch}
            \item \textct{AlgorithmClass::UserDefined}
        \end{itemize}
        In Python, we use integers, which we wrap inside of a class.  For example, the class \textct{AlgorithmClass} contains three integer values that we access with:
        \begin{itemize}
            \item \textct{AlgorithmClass.TrustRegion}
            \item \textct{AlgorithmClass.LineSearch}
            \item \textct{AlgorithmClass.UserDefined}
        \end{itemize}
        In MATLAB/Octave, we use floating point numbers, which we wrap inside of a structured array.  For example, the structure array \textct{AlgorithmClass} contains three floating point values that we designate as:
        \begin{itemize}
            \item \textct{AlgorithmClass.TrustRegion}
            \item \textct{AlgorithmClass.LineSearch}
            \item \textct{AlgorithmClass.UserDefined}
        \end{itemize}
        In all cases, we also provide a function called \textct{to_string} in the class or namespace that converts the enumerated type to a string with the name of the enumerated element.  Using our previous example of \textctref{AlgorithmClass}, in C++ we use
        \begin{center}
            \textct{AlgorithmClass::to_string}
            \end{center}
        whereas in Python and MATLAB/Octave we use
        \begin{center}
            \textct{AlgorithmClass.to_string}.
        \end{center}
        As to our specific enumerated types, we elaborate on them \hyperref[lst:enumerated]{below}.}

    \typeitem
        {X_Vector}
        {User defined vector within the vector space $X$, the domain of our objective function, $f:X\rightarrow\re$.}

    \typeitem
        {Y_Vector}
        {User defined vector within the vector space $Y$, the codomain of our equality constraint, $g:X\rightarrow Y$ with $g(x)=0$.}

    \typeitem
        {Z_Vector}
        {User defined vector within the vector space $Z$, the codomain of our inequality constraint, $h:X\rightarrow Z$ with $h(x)\succeq 0$.}

    \typeitem
        {List}
        {List of a specified kind of vectors.  In C++, this denotes a \textct{std::list}.  In Python, this becomes a \textct{list}.  Finally, in MATLAB/Octave, we use a cell array.}

    \typeitem
        {Function}
        {Function of a specified kind of variable.  This type represents a function inside the state structure that we use to set a number of similar parameters.  However, in the JSON parameter files, we set it like it was just another parameter.}
\end{boldlist}

\noindent We further classify our enumerated types into the following:

\phantomsection\label{lst:enumerated}
\begin{boldlist}
    \enumitem {AlgorithmClass}

    \enumitem {OptimizationStop}

    \enumitem {Operators}

    \enumitem {LineSearchDirection}

    \enumitem {LineSearchKind}

    \enumitemlong {OptimizationLocation}

    \enumitem {ProblemClass}

    \enumitem {DiagnosticScheme}

    \enumitem {FunctionDiagnostics}

    \enumitem {VectorSpaceDiagnostics}

    \enumitem {ToleranceKind}

    \enumitem {QuasinormalStop}

    \enumitemlinalg {TruncatedStop}

    \enumitemvspace {Cone}
\end{boldlist}

        Based on these types, we catalog the precise meaning of our parameters below.  As a note, the field \textbf{JSON Param} denotes whether or not we allow the parameter to be set in the JSON file described in the section \hyperref[sec:params]{\secparams}.  Generally, these settable parameters correspond to parameters that tune the behavior the algorithms.  The other parameters correspond to internal quantities that assist in diagnostics or advanced heuristics.
\begin{boldlist}
    \paramitemu
        {eps_grad}
        {Real}
        {Yes}
        {Tolerance for the gradient stopping criteria reported in \textctref{opt_stop}.  We satisfy this stopping criteria when
        \begin{boldlist}
            \formitem
                {$\|\uncGradLag{\textctref{x})}\| \leq \textctref{eps_grad} \cdot \textctref{norm_gradtyp}$,}
                {$\|\eqGradLag{\textctref{x}}{\textctref{y}}\| \leq \textctref{eps_grad} \cdot \textctref{norm_gradtyp}$,}
                {$\|\ineqGradLag{\textctref{x}}{\textctref{z}}\| \leq \textctref{eps_grad} \cdot \textctref{norm_gradtyp}$,}
                {$\|\conGradLag{\textctref{x}}{\textctref{y}}{\textctref{z}}\| \leq \textctref{eps_grad} \cdot \textctref{norm_gradtyp}$.}
        \end{boldlist}
        At each iteration, we output the norm on the left of the inequality under the label \textctrefalt{||grad||}.}

    \paramitemu
        {eps_dx}
        {Real}
        {Yes}
        {Tolerance for the step length stopping criteria reported in \textctref{opt_stop}.  We satisfy this stopping criteria when
        $$
            \|\textctref{dx}\| < \textctref{eps_dx}\cdot\textctref{norm_dxtyp}.
        $$
        At each iteration, we output the norm on the left of the inequality under the label \textctrefalt{||dx||}.}

    \paramitemu
        {stored_history}
        {Natural}
        {Yes}
        {Number of vectors stored for use with quasi-Newton methods such as SR1 and BFGS.}

    \paramitemu
        {iter}
        {Natural}
        {No}
        {Current optimization iteration.  We output \textctref{iter} at each iteration under the label \textctrefalt{iter}.}

    \paramitemu
        {iter_max}
        {Natural}
        {Yes}
        {Maximum number of optimization iterations for the stopping criteria reported in \textctref{opt_stop}.  We satisfy this stopping criteria when
        $$
                \textctref{iter}\geq \textctref{iter_max}
        $$}

    \paramitemu
        {glob_iter}
        {Natural}
        {No}
        {Current globalization iteration.  Here, globalization means the current iteration of the trust-region or line-search method and involves operations such as checking the actual versus predicted reduction or the sufficient decrease condition.}

    \paramitemu
        {glob_iter_max}
        {Natural}
        {Yes}
        {Maximum number of globalization iterations that we take before we exit the optimization.  In other words, we only allow this many failed trust-region or line-search iterations before we exit the algorithm.}

    \paramitemu
        {glob_iter_total}
        {Natural}
        {No}
        {Total number of globalization iterations taken across all iterations.  This information is helpful when determining the overall expense of the algorithm.  When we properly setup an equality constrained problem, we generally do one factorization of $g^\prime(x)g^\prime(x)^*$ every globalization iteration.  In addition, evaluating the globalization routines for trust-region methods requires one Hessian-vector product every globalization iteration.  We output \textctref{glob_iter_total} at each iteration under the label \textctrefalt{glb_itr_tot}.}

    \paramitemu
        {opt_stop}
        {OptimizationStop}
        {No}
        {Why we've stopping the optimization.  We use the following logic when determining when to stop
        \begin{enumerate}
            \item If the optimization iteration exceeds the maximum number of iterations, stop.  We control this with the parameter \textctref{iter_max}.
            \item If size of the optimization step becomes too small, stop.  We control this with the parameter \textctref{eps_dx}.
            \item If we have inequality constraints and the estimated interior point parameter \textctref{mu_est} becomes negative, stop.
            \item If the size of the gradient becomes too small and we satisfy the following additional conditions, stop.  We control this with the parameter \textctref{eps_grad}.
            \begin{enumerate}
                \item For problems with equality constraints, we require that the norm of the equality constraint be small.  We control this with the parameter \textctref{eps_constr}.
                \item For problems with inequality constraints, we require that estimated interior point parameter be small.  We control this with the parameter \textctref{eps_mu}.
            \end{enumerate}
        \end{enumerate}}

    \paramitemu
        {trunc_iter}
        {Natural}
        {No}
        {Current number of iterations taken by truncated CG when solving the optimality conditions.  We output \textctref{trunc_iter} at each iteration under the label \textctrefalt{trunc_iter}.}

    \paramitemu
        {trunc_iter_max}
        {Natural}
        {Yes}
        {Maximum number of iterations taken by truncated CG when solving the optimality conditions.}

    \paramitemu
        {trunc_iter_total}
        {Natural}
        {No}
        {Total number of iterations ever taken by the truncated CG when solving the optimality conditions.  This gives information about the total amount computational effort taken by Optizelle as we evaluate one Hessian-vector product each iteration.  We output \textctref{trunc_iter_total} at each iteration under the label \textctrefalt{trc_itr_tot}.}

    \paramitemu
        {trunc_orthog_storage_max}
        {Natural}
        {Yes}
        {Number of vectors stored and used in the orthogonalization of truncated CG.  In theory, we only need $1$ for unconstrained and inequality constrained problems, but this leads to numerical instabilities.  In practice, if memory is available, it may be worthwhile to over orthogonalize.}

    \paramitemu
        {trunc_orthog_iter_max}
        {Natural}
        {Yes}
        {Maximum number of orthogonalization iterations that we use in truncated-CG.  In theory, $1$ should be enough, which means that we orgthogonalize against all the stored previous directions once.  In practice, we'll eventually lose orthogonality, so using $2$ may help at the cost of additional computation.}

    \paramitemu
        {trunc_stop}
        {TruncatedStop}
        {No}
        {Reason why truncated CG exited when solving the optimality system.  We output \textctref{trunc_stop} at each iteration under the label \textctrefalt{trunc_stop}.}

    \paramitemu
        {trunc_err}
        {Real}
        {No}
        {Relative error in the solution returned by the truncated CG when solving the optimality system.  We output \textctref{trunc_err} at each iteration under the label \textctrefalt{trunc_err}.}

    \paramitemu
        {eps_trunc}
        {Real}
        {Yes}
        {Relative stopping criteria for truncated CG.  In truncated CG, when solving the system $Ax=b$ with preconditioner $B$, we use the stopping criteria  $\|B(Ax_k-b)\|\leq \textctref{eps_trunc}\|B(Ax_0-b)\|$.}

    \paramitemu
        {algorithm_class}
        {AlgorithmClass}
        {Yes}
        {Class of algorithm used in optimization.}

    \paramitemu
        {PH_type}
        {Operators}
        {Yes}
        {Preconditioner used when solving the optimality conditions.  Note, in order to accommodate the null space projection, we currently ignore this quantity if problems with equality constraints.}

    \paramitemu
        {H_type}
        {Operators}
        {Yes}
        {Hessian approximation for the objective function.}

    \paramitemu
        {norm_gradtyp}
        {Real}
        {No}
        {Norm of a typical gradient defined as
        \begin{boldlist}
            \formitem
                {$\|\uncGradLag{\textctref{x}_0}\|$,}
                {$\|\eqGradLag{\textctref{x}_0}{\textctref{y}_0}\|$,}
                {$\|\ineqGradLag{\textctref{x}_0}{\textctref{z}_0}\|$,}
                {$\|\conGradLag{\textctref{x}_0}{\textctref{y}_0}{\textctref{z}_0}\|$,}
        \end{boldlist}
        where $\textctref{x}_0$, $\textctref{y}_0$, and $\textctref{z}_0$ denote our variables at the first iteration.  Sometimes, we use \textctref{norm_gradtyp} with the stopping criteria described in \textctref{eps_grad}.  Specifically, we only refer to this quantity when \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Relative}.  When \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Absolute}, we ignore this value and instead use $1.0$.}

    \paramitemu
        {norm_dxtyp}
        {Real}
        {No}
        {Norm of a typical optimization step.  Similar to \textctref{norm_gradtyp}, we set this to be the gradient found at the initial guess and use it in the stopping criteria described in \textctref{eps_dx}.  Since an optimization algorithm may have numerical issues on the first optimization iteration, we do not use the first optimization step generated.  By using the norm of the gradient, we approximate the norm of a step taken by the steepest descent algorithm.  As a note, we only refer to this quantity when \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Relative}.  When \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Absolute}, we ignore this value and instead use $1.0$.}

    \paramitemu
        {x}
        {X_Vector}
        {No}
        {Optimization variable.}

    \paramitemu
        {grad}
        {X_Vector}
        {No}
        {Gradient of the objective, $\nabla f(\textctref{x})$. }

    \paramitemu
        {dx}
        {X_Vector}
        {No}
        {Step taken during the optimization iteration.  Every iteration we set \textctref{x}=\textctref{x}+\textctref{dx}.  In addition, we output the norm of this vector at each iteration under the label \textctrefalt{||dx||}.}

    \paramitemu
        {x_old}
        {X_Vector}
        {No}
        {Optimization variable from the last iteration.}

    \paramitemu
        {grad_old}
        {X_Vector}
        {No}
        {Gradient of the objective from the last iteration.}

    \paramitemu
        {dx_old}
        {X_Vector}
        {No}
        {Optimization step from the last iteration.}

    \paramiteml
        {oldY}
        {X_Vector}
        {No}
        {Difference in prior gradients,
        $$
            [\nabla f(\textctref{x}_{\textctref{iter}})-\nabla f(\textctref{x}_{\textctref{iter}-1}),\dots,\nabla f(\textctref{x}_{\textctref{iter}-\textctref{stored_history}})-\nabla f(\textctref{x}_{\textctref{iter}-\textctref{stored_history}-1})].
        $$
        We use this list in our quasi-Newton methods.}

    \paramiteml
        {oldS}
        {X_Vector}
        {No}
        {Difference in prior optimization steps,
        $$
            [x_{\textctref{iter}}-x_{\textctref{iter}-1},\dots,x_{\textctref{iter}-\textctref{stored_history}}-x_{\textctref{iter}-\textctref{stored_history}-1}].
        $$
        We use this list in our quasi-Newton methods.}

    \paramitemu
        {f_x}
        {Real}
        {No}
        {Current value of the objective function, $f(\textctref{x})$.  We output \textctref{f_x} at each iteration under the label \textctrefalt{f(x)}.}

    \paramitemu
        {f_xpdx}
        {Real}
        {No}
        {Value of the objective function at the trial step, $f(\textctref{x}+\textctref{dx})$.}

    \paramitemu
        {msg_level}
        {Natural}
        {Yes}
        {Messaging level.  To turn messages off, use $0$.  For normal messaging, set to $1$.  For more detailed information, set to $2$.  For linear solver information, set to $3$.  To see precise information about what information we display, refer to the chapter entitled \hyperref[ch:output]{\choutput}.}

    \paramitemu
        {safeguard_failed_max}
        {Natural}
        {Yes}
        {Number of failed safe-guard steps before exiting truncated CG.  We use this exclusively for our inequality constraints.}

    \paramitemu
        {safeguard_failed}
        {Natural}
        {No}
        {Number of failed safe-guard steps during the last iteration.  We output \textctref{safeguard_failed} at each iteration under the label \textctrefalt{safe_fail}.}

    \paramitemu
        {safeguard_failed_total}
        {Natural}
        {No}
        {Total number of failed safe-guard steps.}

    \paramitemu
        {alpha_x}
        {Real}
        {No}
        {How much we truncate \textctref{dx} in an interior point method in order to maintain strict feasibility.  When $1.0$, we do not truncate and take a full step.  We output \textctref{alpha_x} at each iteration under the label \textctrefalt{alpha_x}.}

    \paramitemu
        {alpha_x_qn}
        {Real}
        {No}
        {How much we truncate \textctref{dx_n} in an interior point method in order to maintain strict feasibility.  When $1.0$, we do not truncate and take a full step.}  We output \textctref{alpha_x_qn} at each iteration under the label \textctrefalt{alpha_x_qn}.

    \paramitemu
        {eps_kind}
        {ToleranceKind}
        {Yes}
        {Kind of stopping tolerance used by the algorithms.}

    \paramitemu
        {delta}
        {Real}
        {Yes}
        {Trust region radius.  We use this as a starting value.  Later, we adjust the radius depending on the behavior of the algorithms.  As a note, we output \textctref{delta} at each iteration under the label \textctrefalt{delta}.}

    \paramitemu
        {eta1}
        {Real}
        {Yes}
        {When the actual versus predicted reduction for a trust-region method is below this threshold, we reject the step.  Otherwise, we accept it.}

    \paramitemu
        {eta2}
        {Real}
        {Yes}
        {When the actual versus predicted reduction for a trust-region method is above this threshold and the size of the trial step equals the trust-region radius, we increase the size of the trust-region radius.}

    \paramitemu
        {ared}
        {Real}
        {No}
        {Actual reduction in the merit function between the current iterate and the iterate after taking the trial step,
        $$
            \textctref{ared}\equiv\textct{merit}(\textctref{x}) - \textct{merit}(\textctref{x}+\textctref{dx}).
        $$
        We use the following merit functions, $\textct{merit}:\textctref{X_Vector}\rightarrow\textctref{Real}$,
        \begin{boldlist}
            \formitem
                {$\uncMerit{\textctref{x}},$}
                {$\eqMerit{\textctref{x}}{\textctref{y}},$}
                {$\ineqMerit{\textctref{x}},$}
                {$\conMerit{\textctref{x}}{\textctref{y}}.$}
        \end{boldlist}
        Here, \textctref{barr} refers to the barrier function, which we describe in the section \hyperref[sec:customvector]{\seccustomvector}.  As a note, we output the value of the merit function at each iteration under the label \textctrefalt{merit(x)} and \textctref{ared} under the label \textctrefalt{ared}.}

    \paramitemu
        {pred}
        {Real}
        {No}
        {Predicted reduction in the merit function between the current iterate and the iterate after taking the trial step,
        $$
            \textctref{pred}\equiv\textct{model}(0) - \textct{model}(\textctref{dx}).
        $$
        We use the following model functions, $\textct{model}:\textctref{X_Vector}\rightarrow\textctref{Real}$,
        \begin{boldlist}
            \formitem
                {$$
                    \uncMerit{\textctref{x}}
                    +\langle \uncGradLag{\textctref{x}},\textctref{dx}\rangle
                    +\frac{1}{2}\langle \uncHessVec{\textctref{x}},\textctref{dx}\rangle,
                $$}
                {$$\begin{array}{l}
                    \eqMerit{\textctref{x}}{\textctref{y}}\\
                    +\langle \eqGradLag{\textctref{x}}{\textctref{y}},\textctref{dx}\rangle\\
                    +\frac{1}{2}\langle \eqHessVec{\textctref{x}}{\textctref{y}},\textctref{dx}\rangle,
                \end{array}$$}
                {$$\begin{array}{l}
                    \ineqMerit{\textctref{x}}\\
                    +\langle \ineqGradSchur{\textctref{x}},\textctref{dx}\rangle\\
                    +\frac{1}{2}\langle \ineqHessVec{\textctref{x}}{\textctref{z}},\textctref{dx}\rangle,
                \end{array}$$}
                {$$\begin{array}{l}
                    \conMerit{\textctref{x}}{\textctref{y}}\\
                    +\langle \conGradSchur{\textctref{x}}{\textctref{y}},\textctref{dx}\rangle\\
                    +\frac{1}{2}\langle \conHessVec{\textctref{x}}{\textctref{y}}{\textctref{z}},\textctref{dx}\rangle.
                \end{array}$$}
        \end{boldlist}
        Here, $\circ$ denotes the Jordan product, \textctref{prod}; $L(h(x))^{-1}$ denotes the inverse of the linear operator induced by the Jordan product, \textctref{linv}; $e$ denotes the identity element in the pseudo-Euclidean-Jordan algebra, \textctref{id}; and \textctref{barr} denotes the barrier function.  We describe each of these operations further in the section \hyperref[sec:customvector]{\seccustomvector}.  As a note, we output \textctref{pred} at each iteration under the label \textctrefalt{pred}.}

    \paramitemu
        {alpha0}
        {Real}
        {Yes}
        {Base line-search step length.  Generally, our line-search methods search for a scaling $\textctref{alpha}\in[0,2\cdot\textctref{alpha0}]$.  Once we find \textctref{alpha}, we increase \textctref{alpha0} when our search always brackets to the right and decrease it when our search always brackets to the left.  As a note, we output \textctref{alpha0} at each iteration under the label \textctrefalt{alpha0}.}

    \paramitemu
        {alpha}
        {Real}
        {No}
        {Actual line-search step length.  After our line-search process completes, we modify our step $\textctref{dx}\leftarrow \textctref{alpha} \cdot \textctref{dx}$.  As a note, we output \textctref{alpha} at each iteration under the label \textctrefalt{alpha}.}

    \paramitemu
        {c1}
        {Real}
        {Yes}
        {Sufficient decrease parameter.  When we set \textctref{algorithm_class} to \hyperref[itm:AlgorithmClass]{LineSearch}, we only take a step when $\hyperref[itm:ared]{\textct{merit}}(\textctref{x}+\textctref{alpha}\cdot\textctref{dx}) < \hyperref[itm:ared]{\textct{merit}}(\textctref{x})+\textctref{c1}\cdot\textctref{alpha}\langle\tilde{x},\textctref{dx}\rangle$ where we define $\tilde{x}$ as
        \begin{boldlist}
            \formitem
                {$\uncGradLag{\textctref{x}},$}
                {$\eqGradLag{\textctref{x}}{\textctref{y}},$}
                {$\ineqGradSchur{\textctref{x}},$}
                {$\conGradSchur{\textctref{x}}{\textctref{y}}.$}
        \end{boldlist}
        Here, $L(h(x))^{-1}$ denotes the inverse of the linear operator induced by the Jordan product, \textctref{linv}; and $e$ denotes the identity element in the pseudo-Euclidean-Jordan algebra, \textctref{id}.  We describe each of these operations further in the section \hyperref[sec:customvector]{\seccustomvector}.}

    \paramitemu
        {ls_iter}
        {Natural}
        {No}
        {Current number of iterations used in the line search.  We use this to determine the amount of computational effort used by Optizelle during the last iteration.   As a note, we output \textctref{ls_iter} at each iteration under the label \textctrefalt{ls_iter}.}

    \paramitemu
        {ls_iter_max}
        {Natural}
        {Yes}
        {Maximum number of iterations used in the line search before checking the sufficient decrease condition.  We use this to tune the amount of work done by the line search.}

    \paramitemu
        {ls_iter_total}
        {Natural}
        {No}
        {Total number of iterations ever taken by the line search.  We use this to determine the amount of computational effort used by Optizelle.}

    \paramitemu
        {eps_ls}
        {Real}
        {Yes}
        {Relative stopping tolerance used by the line search.  At the moment, we do not use this parameter.}

    \paramitemu
        {dir}
        {LineSearchDirection}
        {Yes}
        {Line-search direction taken by the line-search algorithm.}

    \paramitemu
        {kind}
        {LineSearchKind}
        {Yes}
        {Kind of line-search used in the line-search algorithm.}

    \paramitemu
        {f_diag}
        {FunctionDiagnostics}
        {Yes}
        {Function diagnostics on $f$.}

    \paramitemu
        {L_diag}
        {FunctionDiagnostics}
        {Yes}
        {Function diagnostics on the Lagrangian.}

    \paramitemu
        {x_diag}
        {VectorSpaceDiagnostics}
        {Yes}
        {Vector space diagnostics on X.}

    \paramitemu
        {dscheme}
        {DiagnosticScheme}
        {Yes}
        {Which diagnostic scheme, if any, to employ.}

    \paramiteme
        {y}
        {Y_Vector}
        {No}
        {Equality multiplier (dual variable or Lagrange multiplier.)}

    \paramiteme
        {dy}
        {Y_Vector}
        {No}
        {Step in the equality multiplier.  Every iteration we set \textctref{y}=\textctref{y}+\textctref{dy}.}

    \paramiteme
        {zeta}
        {Real}
        {Yes}
        {Fraction of the total trust region used in the quasi-normal step.}

    \paramiteme
        {eta0}
        {Real}
        {Yes}
        {Trust-region parameter that bounds the error in the predicted-reduction.}

    \paramiteme
        {rho}
        {Real}
        {Yes}
        {Penalty parameter for the augmented-Lagrangian.  In problems with equality constraints, this term appears in the merit functions
        \begin{boldlist}
            \formiteme
                {$\eqMerit{\textctref{x}}{\textctref{y}},$}
                {$\conMerit{\textctref{x}}{\textctref{y}}.$}
        \end{boldlist}
        Here, \textctref{barr} refers to the barrier function, which we describe in the section \hyperref[sec:customvector]{\seccustomvector}.}

    \paramiteme
        {rho_old}
        {Real}
        {No}
        {Penalty parameter from the last iteration.}

    \paramiteme
        {rho_bar}
        {Real}
        {Yes}
        {Fixed increase in the penalty parameter in the augmented Lagrangian merit function.}

    \paramiteme
        {eps_constr}
        {Real}
        {Yes}
        {Relative stopping tolerance for feasibility with respect to the equality constraint reported in \textctref{opt_stop}.  We satisfy this stopping criteria when
        $$
            \|g(\textctref{x})\| < \textctref{eps_constr}\cdot\textctref{norm_gxtyp}.
        $$
        At each iteration, we output the norm on the left of the inequality under the label \textctrefalt{||g(x)||}.  Note, since this value tunes a \textit{relative} stopping criteria, if we start with a feasible solution, we need to adjust this value to be something like \textct{1.0}.  This states that we do not seek relative improvement in the infeasibility.}

    \paramiteme
        {xi_qn}
        {Real}
        {Yes}
        {Relative stopping tolerance for the augmented system solve associated with the quasi-Newton step.}

    \paramiteme
        {xi_pg}
        {Real}
        {Yes}
        {Relative stopping tolerance for the augmented system solve associated with the projection of the gradient prior to solving the tangential subproblem.}

    \paramiteme
        {xi_proj}
        {Real}
        {Yes}
        {Relative stopping tolerance for the augmented system solve associated with the null-space projection of the iterate in the tangential subproblem.}

    \paramiteme
        {xi_tang}
        {Real}
        {Yes}
        {Relative stopping tolerance for the augmented system solve associated with the tangential step computation after solving the tangential subproblem.}

    \paramiteme
        {xi_lmh}
        {Real}
        {Yes}
        {Relative stopping tolerance for the augmented system solve associated with the equality multiplier computation.}

    \paramitemf
        {xi_all}
        {Real}
        {Yes}
        {Relative stopping tolerance for all of the augmented system solves, \textctref{xi_qn}, \textctref{xi_pg}, \textctref{xi_proj}, \textctref{xi_proj}, \textctref{xi_tang}, and \textctref{xi_lmh}.}

    \paramiteme
        {xi_lmg}
        {Real}
        {Yes}
        {Absolute tolerance on the residual of the equality multiplier solve.}

    \paramiteme
        {xi_4}
        {Real}
        {Yes}
        {Tolerance for how much error is acceptable after computing the tangential step given the result from the tangential subproblem.}

    \paramiteme
        {rpred}
        {Real}
        {No}
        {Residual term in the predicted reduction.  We use this quantity to determine if we computed a tangential step that is accurate enough.}

    \paramiteme
        {PSchur_left_type}
        {Operators}
        {Yes}
        {Left preconditioner for the augmented system.  For a full discussion of this preconditioner, see the section \hyperref[sec:preconditioners]{\secpreconditioners}.}

    \paramiteme
        {PSchur_right_type}
        {Operators}
        {Yes}
        {Right preconditioner for the augmented system.  For a full discussion of this preconditioner, see the section \hyperref[sec:preconditioners]{\secpreconditioners}.}

    \paramiteme
        {augsys_iter_max}
        {Natural}
        {Yes}
        {Maximum number of GMRES iterations allowed when solving an augmented system.}

    \paramiteme
        {augsys_rst_freq}
        {Natural}
        {Yes}
        {How often we restart the augmented system solve.  We restart GMRES every specified number of iterations in order to save memory.  When 0, we do not restart.}

    \paramiteme
        {augsys_qn_iter}
        {Natural}
        {No}
        {Number of iterations taken during the last iterate by the augmented system solve for the quasi-normal step.}

    \paramiteme
        {augsys_pg_iter}
        {Natural}
        {No}
        {Number of iterations taken during the last iterate by the augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \paramiteme
        {augsys_proj_iter}
        {Natural}
        {No}
        {Number of iterations taken during the last iterate by the augmented system solve during the nullspace projection in the tangential subproblem.  Since there are likely many projections, this is the total number of iterations over all projections.}

    \paramiteme
        {augsys_tang_iter}
        {Natural}
        {No}
        {Number of iterations taken during the last iterate by the augmented system solve during the tangential step.}

    \paramiteme
        {augsys_lmh_iter}
        {Natural}
        {No}
        {Number of iterations taken during the last iterate by the augmented system solve during the equality multiplier solve.}

    \paramiteme
        {augsys_qn_iter_total}
        {Natural}
        {No}
        {Total number of iterations taken by the augmented system solve for the quasi-normal step.}

    \paramiteme
        {augsys_pg_iter_total}
        {Natural}
        {No}
        {Total number of iterations taken by the augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \paramiteme
        {augsys_proj_iter_total}
        {Natural}
        {No}
        {Total number of iterations taken by the augmented system solve during the nullspace projection in the tangential subproblem.}

    \paramiteme
        {augsys_tang_iter_total}
        {Natural}
        {No}
        {Total number of iterations taken by the augmented system solve during the tangential step.}

    \paramiteme
        {augsys_lmh_iter_total}
        {Natural}
        {No}
        {Total number of iterations taken by the augmented system solve during the equality multiplier solve.}

    \paramiteme
        {augsys_iter_total}
        {Natural}
        {No}
        {Total number of iterations taken by all augmented system solves.}

    \paramiteme
        {augsys_qn_err}
        {Real}
        {No}
        {Error in the last augmented system solve for the quasi-normal step.}

    \paramiteme
        {augsys_pg_err}
        {Real}
        {No}
        {Error in the last augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \paramiteme
        {augsys_proj_err}
        {Real}
        {No}
        {Error in the last augmented system solve during the nullspace projection in the tangential subproblem.  Note, since there are likely many projections during a single tangential subproblem, this represents the error from the last such solve.}

    \paramiteme
        {augsys_tang_err}
        {Real}
        {No}
        {Error in the last augmented system solve during the tangential step.}

    \paramiteme
        {augsys_lmh_err}
        {Real}
        {No}
        {Error in the last augmented system solve during the equality multiplier solve.}

    \paramiteme
        {augsys_qn_err_target}
        {Real}
        {No}
        {Target error in the last augmented system solve for the quasi-normal step.}

    \paramiteme
        {augsys_pg_err_target}
        {Real}
        {No}
        {Target error in the last augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \paramiteme
        {augsys_proj_err_target}
        {Real}
        {No}
        {Target error in the last augmented system solve during the nullspace projection in the tangential subproblem.  Note, since there are likely many projections during a single tangential subproblem, this represents the target error from the last such solve.}

    \paramiteme
        {augsys_tang_err_target}
        {Real}
        {No}
        {Target error in the last augmented system solve during the tangential step.}

    \paramiteme
        {augsys_lmh_err_target}
        {Real}
        {No}
        {Target error in the last augmented system solve during the equality multiplier solve.}

    \paramiteme
        {augsys_qn_failed}
        {Real}
        {No}
        {Number of failed quasinormal augmented system solves.}

    \paramiteme
        {augsys_pg_failed}
        {Real}
        {No}
        {Number of failed projected gradient augmented system solves.}

    \paramiteme
        {augsys_proj_failed}
        {Real}
        {No}
        {Number of failed nullspace projection augmented system solves.}

    \paramiteme
        {augsys_tang_failed}
        {Real}
        {No}
        {Number of tangential step augmented system solves.}

    \paramiteme
        {augsys_lmh_failed}
        {Real}
        {No}
        {Number of equality multiplier augmented system solves.}

    \paramiteme
        {augsys_failed_total}
        {Real}
        {No}
        {Total number of failed augmented system solves.  In short, the theory for convergence to a local minima requires that augmented system solves meet their specified tolerance.  Sometimes, a lower tolerance can be used and these tolerances are controlled by \textctref{xi_all}, \textctref{xi_qn}, \textctref{xi_pg}, \textctref{xi_proj}, \textctref{xi_tang}, and \textctref{xi_lmh}.  However, even with a lower specified tolerance, the inexact composite step SQP method can still require a tighter tolerance in order to guarantee convergence.  Generally, the algorithms are tolerant to a few failed solves.  However, if there are failed solves at every iteration, then there's a problem with the given preconditioner or no preconditioner was specified.  See the section \hyperref[sec:preconditioners]{\secpreconditioners} for more information on how to implement an appropriate preconditioner.}

    \paramiteme
        {g_x}
        {Y_Vector}
        {No}
        {Equality constraint evaluated a \textctref{x}, $g(\textctref{x})$.  We use this in the quasi-normal step as well as in the computation of the linear Taylor series at \textctref{x} in the direction \textctref{dx_n}.  As a note, we output the norm of this vector each iteration under the label \textctrefalt{||g(x)||}.}

    \paramiteme
        {norm_gxtyp}
        {Real}
        {No}
        {Norm of a typical equality constraint, which we define to be the norm of the equality constraint at the first iteration.  Sometimes, we use \textctref{norm_gxtyp} with the stopping criteria described in \textctref{eps_constr}. Specifically, we only refer to this quantity when \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Relative}.  When \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Absolute}, we ignore this value and instead use $1.0$.}

    \paramiteme
        {norm_gpsgxtyp}
        {Real}
        {No}
        {Norm of a typical value of $g'(\textctref{x})^*g(\textctref{x})$, which we define to be the value of this quantity at the first iteration.  When we compute the quasinormal step, we compute the Cauchy point by finding the least-squares solution to the linearized equality constraint, $\min_{\partial x} \frac{1}{2} \|g'(x)\partial x + g(x)\|^2$.  Here, the gradient is $g^\prime(x)^*g^\prime(x)\partial x + g^\prime(x)^*g(x)$.  Now, for the Cauchy point, we start with $\partial x=0$, so the steepest descent direction becomes $\partial x = -g^\prime(x)^*g(x)$.  We find the Cauchy point, by doing an exact line-search along this direction in the objective for the least-squares problem above.  Now, when $g^\prime(x)^*g(x) = 0$, we sit at a local minima to the least-squares problem above.  Generally, this is bad since we're not feasible and we don't have good information as to where to move to improve our infeasibility.  Nevertheless, the tangential step will likely move us off that point unless we've already achieved optimality with respect to the Lagrangian.  In any case, we require \textctref{norm_gpsgxtyp} to determine when the relative norm of $g^\prime(x)^*g(x)$ is small and hence fall into this local minima.}

    \paramiteme
        {gpxdxn_p_gx}
        {Y_Vector}
        {No}
        {Linear Taylor series at \textctref{x} in the direction \textctref{dx_n}.  We use this both in the predicted reduction as well as the residual predicted reduction.}

    \paramiteme
        {gpxdxt}
        {Y_Vector}
        {No}
        {Derivative of the constraint applied to the tangential step this is used in the residual predicted reduction.}

    \paramiteme
        {norm_gpxdxnpgx}
        {Real}
        {No}
        {Norm of \textctref{gpxdxn_p_gx}.  We use this in the penalty parameter computation and predicted reduction.}

    \paramiteme
        {dx_n}
        {X_Vector}
        {No}
        {Normal step.  We output the norm of this vector at each iteration under the label \textctrefalt{||dx_n||}.}

    \paramiteme
        {dx_ncp}
        {X_Vector}
        {No}
        {Cauchy point for normal step.}

    \paramiteme
        {dx_t}
        {X_Vector}
        {No}
        {(Corrected) tangential step.  We output the norm of this vector at each iteration under the label \textctrefalt{||dx_t||}.}

    \paramiteme
        {dx_t_uncorrected}
        {X_Vector}
        {No}
        {Tangential step prior to correction.}

    \paramiteme
        {dx_tcp_uncorrected}
        {X_Vector}
        {No}
        {Cauchy point for tangential step prior to correction.}

    \paramiteme
        {H_dxn}
        {X_Vector}
        {No}
        {Hessian applied to the normal step.  We require this in \textctref{W_gradpHdxn} as well as the predicted reduction.}

    \paramiteme
        {W_gradpHdxn}
        {X_Vector}
        {No}
        {Quantity grad $f(\textctref{x}) + g^\prime(\textctref{x})*\textctref{y} + \hyperref[itm:H_type]{H} \textctref{dx_n}$ projected into the null-space of the constraints.  We require this in the tangential subproblem and the predicted reduction.}

    \paramiteme
        {H_dxtuncorrected}
        {X_Vector}
        {No}
        {Hessian applied to the uncorrected tangential step.  We require this in the predicted reduction.}

    \paramiteme
        {g_diag}
        {FunctionDiagnostics}
        {Yes}
        {Function diagnostics on $g$.}

    \paramiteme
        {y_diag}
        {VectorSpaceDiagnostics}
        {Yes}
        {Vector space diagnostics on Y.}

    \paramiteme
        {qn_stop}
        {QuasinormalStop}
        {No}
        {Reason why the quasinormal problem exited.}

    \paramitemi
        {z}
        {Z_Vector}
        {No}
        {Inequality multiplier (dual variable or Lagrange multiplier.)}

    \paramitemi
        {dz}
        {Z_Vector}
        {No}
        {Step in the inequality multiplier.  Every iteration we set \textctref{z}=\textctref{z}+\textctref{dz}.}

    \paramitemi
        {h_x}
        {Z_Vector}
        {No}
        {The inequality constraint evaluated at x.  In theory, we can always just evaluate this when we need it.  However, we require its computation both in the gradient as well as Hessian calculations.  More specifically, when computing with SDP constraints, we require a factorization of this quantity.  By caching it, we have the ability to cache the factorization.}

    \paramitemi
        {mu}
        {Real}
        {Yes}
        {Interior point parameter.  We use this as the target for the interior-point parameter estimate \textctref{mu_est}.  As the interior point method progresses, we drive this value toward zero.  As a note, we output \textctref{mu} at each iteration under the label \textctrefalt{mu}.}

    \paramitemi
        {mu_est}
        {Real}
        {No}
        {Current interior-point estimate.  We define this as
        $$
                \textctref{mu_est}\equiv\frac{\langle \textctref{z},\textctref{h_x} \rangle}{\langle e,e\rangle}.
        $$
        As a note, we output \textctref{mu_est} at each iteration under the label \textctrefalt{mu_est}.  Also note, we require this value to be small relative to \textctref{mu_typ} for convergence and control the relative decrease required with the parameter \textctref{eps_mu}.}

    \paramitemi
        {mu_typ}
        {Real}
        {No}
        {Typical value for \textctref{mu}, which we define as the value of \textctref{mu_est} at the first iteration.  Sometimes, we use \textctref{mu_typ} with the stopping criteria described in \textctref{eps_mu}.  Specifically, we only refer to this quantity when \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Relative}.  When \textctref{eps_kind} is set to \hyperref[itm:ToleranceKind]{Absolute}, we ignore this value and instead use $1.0$.}

    \paramitemi
        {eps_mu}
        {Real}
        {Yes}
        {Relative stopping tolerance for satisfying the complementary slackness condition for the inequality constraint.  We satisfy this stopping criteria when
        \begin{enumerate}
            \item $|\textctref{mu} - \textctref{mu_typ} \cdot \textctref{eps_mu}| \leq \textctref{mu_typ} \cdot \textctref{eps_mu}$
            \item $|\textctref{mu} - \textctref{mu_est}| \leq \textctref{mu}$
        \end{enumerate}}

    \paramitemi
        {sigma}
        {Real}
        {Yes}
        {Rate that we decrease the interior point parameter.}

    \paramitemi
        {gamma}
        {Real}
        {Yes}
        {How close we move to the boundary during a single step.  A step of $1.0$ allows a step to touch the boundary of the inequality constraint in a single step, which is disallowed by the interior point algorithm.}

    \paramitemi
        {alpha_z}
        {Real}
        {No}
        {How much we truncate \textctref{dz} in an interior point method in order to maintain strict feasibility.  When $1.0$, we do not truncate and take a full step.  We output \textctref{alpha_z} at each iteration under the label \textctrefalt{alpha_z}.}

    \paramitemi
        {h_diag}
        {FunctionDiagnostics}
        {Yes}
        {Function diagnostics on $h$.}

    \paramitemi
        {z_diag}
        {VectorSpaceDiagnostics}
        {Yes}
        {Vector space diagnostics on Z.}
\end{boldlist}

\chapter{\choutput}\label{ch:output}

        Optizelle generates a series of diagnostics while running that give information about the behavior and performance of the underlying algorithm.  This information is organized into columns that are exactly 12 characters wide.  When no information is available, we print a single dot, \textct{.}.  In this way, each column always has some sort of information, which makes the output easy to parse using standard Unix utilities such as \texttt{cut} or \texttt{awk}.  For example, to only print the iteration, objective value, and norm of the step on the Rosenbrock example, we use the following commands on POSIX compliant systems:
\begin{center}\begin{verbatim}
./rosenbrock tr_newton.json | awk '{printf "%-12s%-12s%-12s\n", $1,$2,$4}'
\end{verbatim}
\end{center}
\noindent and
\begin{center}\begin{verbatim}
./rosenbrock tr_newton.json | cut -c1-12,13-24,37-48
\end{verbatim}
\end{center}

        As far as the information in the columns themselves, we detail their meaning below.  In terms of convergence, we require the values \textctrefalt{||grad||}, \textctrefalt{||g(x)||}, and \textctrefalt{mu_est} be small relative to their starting value and control the relative decrease required with the parameters \textctref{eps_grad}, \textctref{eps_constr}, and \textctref{eps_mu}, respectively.  In addition, if the value \textctrefalt{||dx||} becomes too small relative to its starting value, we terminate the optimization.  We control the amount of relative decrease allowed in \textctrefalt{||dx||} with the parameter \textctref{eps_dx}.
\begin{boldlist}
    \outputitemu
        {iter}
        {\textctref{iter}}
        {1}
        {Current optimization iteration.  If the value of this entry is \textct{*}, then either a trust-region algorithm has rejected a step due to an unfavorable actual versus predicted reduction or a line-search algorithm has rejected a step due to a lack of sufficient decrease.  In a trust-region method, we tune the rejection of steps with the parameter \textctref{eta1}.  In a line-search method, we tune the rejection of steps with the parameter \textctref{c1}.}

    \outputitemu
        {f(x)}
        {\textctref{f_x}}
        {1}
        {Value of the objective function at the start of the specified iteration.}

    \outputitemraw
        {\index{Outputs!\textct{"|"|grad"|"|}}{\textctlabelalt{||grad||}}}
        {None}
        {\classUnconstrained}
        {1}
        {Norm of the gradient of either the objective function or the Lagrangian, which we describe in the description of \textctref{eps_grad}.  We use this value within our gradient stopping condition described by the parameter \textctref{eps_grad}.  In general, we need this value to be small relative to the starting value for convergence.}

    \outputitemraw
        {\index{Outputs!\textct{"|"|dx"|"|}}{\textctlabelalt{||dx||}}}
        {None}
        {\classUnconstrained}
        {1}
        {Norm of the step taken during the last iteration.  We calculate this value by taking the norm of the value found in \textctref{dx} and use this within our stopping condition controlled by \textctref{eps_dx}.  As a safeguard, we exit the optimization if this value becomes too small relative to the starting value.}

    \outputitemraw
        {\index{Outputs!\textct{"|"|g(x)"|"|}}{\textctlabelalt{||g(x)||}}}
        {None}
        {\classEquality}
        {1}
        {Norm of the equality constraint at the start of the optimization iteration, which we calculate in \textctref{g_x}.  We use this value within our equality constraint feasibility stopping condition described by the parameter \textctref{eps_constr}.  In short, we need this value to be small relative to the starting value for convergence.  If the starting value is already acceptably small, then we have started with a feasible solution.  In this case, we may need to adjust \textctref{eps_constr} to something like \textct{1.0}, which states that we do not seek relative improvement in the infeasibility.}

    \outputitemi
        {mu_est}
        {\textctref{mu_est}}
        {1}
        {Current interior-point estimate.  We use this value within our complementary slackness stopping condition described by the parameter \textctref{eps_mu}.  In short, we need this value to be small relative to its starting value for convergence.  We control the relative decrease required with the parameter \textctref{eps_mu}.}

    \outputitemu
        {merit(x)}
        {None}
        {2}
        {Value of the merit function at the start of the specified iteration.  We specify the various merit functions in the description of the parameter \textctref{ared}.}

    \outputitemu
        {trunc_iter}
        {\textctref{trunc_iter}}
        {2}
        {Number of iterations used by truncated CG when solving the optimality system.   We tune the maximum number of truncated CG iterations with the parameter \textctref{trunc_iter_max}.}

    \outputitemu
        {trunc_err}
        {\textctref{trunc_err}}
        {2}
        {Error in truncated CG when solving the optimality system.  We control this error with the parameter \textctref{eps_trunc} and indirectly affect it with the parameters \textctref{trunc_orthog_storage_max} and \textctref{trunc_orthog_iter_max}.}

    \outputitemu
        {trunc_stop}
        {\textctref{trunc_stop}}
        {2}
        {Why truncated CG terminated.  Although we shorten the strings, we describe each possible outcome in the enumerated type \textctref{TruncatedStop}.}

    \outputitemu
        {ared}
        {\textctref{ared}}
        {2}
        {Actual reduction in the merit function between the current iterate and the iterate after taking the trial step.}

    \outputitemu
        {pred}
        {\textctref{pred}}
        {2}
        {Predicted reduction in the merit function between the current iterate and the iterate after taking the trial step.}

    \outputitemu
        {ared/pred}
        {None}
        {2}
        {Actual versus predicted reduction.  Simply, we divide the outputs \textctrefalt{ared} and \textctrefalt{pred}.  For a perfect model, this ratio is $1.0$.}

    \outputitemu
        {delta}
        {\textctref{delta}}
        {2}
        {Trust-region radius.}

    \outputitemu
        {ls_iter}
        {\textctref{ls_iter}}
        {2}
        {Number of iterations taken by the line search.  We tune the maximum number of line-search iterations with the parameter \textctref{ls_iter_max} and indirectly control the number of iterations with the parameter \textctref{eps_ls}.}

    \outputitemu
        {alpha}
        {\textctref{alpha}}
        {2}
        {Actual line-search step length.}

    \outputitemu
        {alpha0}
        {\textctref{alpha0}}
        {2}
        {Base line-search step length.}

    \outputiteme
        {qn_stop}
        {\textctref{qn_stop}}
        {2}
        {Reason why the quasinormal problem exited.}

    \outputiteme
        {aug_fail}
        {\textctref{augsys_failed_total}}
        {2}
        {Total number of failed augmented system solves.}

    \outputitemi
        {mu}
        {\textctref{mu}}
        {2}
        {Interior point parameter.}

    \outputitemi
        {alpha_x}
        {\textctref{alpha_x}}
        {2}
        {Amount we truncate \textctref{dx} in order to maintain feasibility with respect to the inequality constraint.}

    \outputitemi
        {alpha_z}
        {\textctref{alpha_z}}
        {2}
        {Amount we truncate \textctref{dz} in order to maintain feasibility with respect to the inequality multiplier.  Note, we only reference this when we are using a primal-dual interior point method.}

    \outputitemi
        {safe_fail}
        {\textctref{safeguard_failed}}
        {2}
        {Number of failed safe-guard steps during the last iteration.  Note, we only reference this when using a trust-region method.}

    \outputitemc
        {alpha_x_qn}
        {\textctref{alpha_x_qn}}
        {2}
        {Amount we truncate \textctref{dx_n} in order to maintain feasibility with respect to the inequality constraint.}

    \outputitemu
        {glb_itr_tot}
        {\textctref{glob_iter_total}}
        {3}
        {Total number of globalization iterations taken across all iterations.}

    \outputitemu
        {trc_itr_tot}
        {\textctref{trunc_iter_total}}
        {3}
        {Total number of iterations used by truncated CG when solving the optimality system.  We typically use this to determine how many Hessian-vector products we've computed over the entire optimization run.}

    \outputitemraw
        {\index{Outputs!\textct{"|"| dx_n "|"|}}{\textctlabelalt{||dx_n||}}}
        {\classEquality}
        {None}
        {3}
        {Norm of the quasinormal step, \textctref{dx_n}, taken during the last iteration.}

    \outputitemraw
        {\index{Outputs!\textct{"|"| dx_t "|"|}}{\textctlabelalt{||dx_t||}}}
        {\classEquality}
        {None}
        {3}
        {Norm of the tangential step, \textctref{dx_t}, taken during the last iteration.}

    \outputiteme
        {qn_iter}
        {\textctref{augsys_qn_iter}}
        {3}
        {Number of iterations taken during the last iterate by the augmented system solve for the quasi-normal step.}

    \outputiteme
        {qn_iter_tot}
        {\textctref{augsys_qn_iter_total}}
        {3}
        {Total number of iterations taken by the augmented system solve for the quasi-normal step.}

    \outputiteme
        {qn_err}
        {\textctref{augsys_qn_err}}
        {3}
        {Error in the last augmented system solve for the quasi-normal step.}

    \outputiteme
        {qn_err_trg}
        {\textctref{augsys_qn_err_target}}
        {3}
        {Target error in the last augmented system solve for the quasi-normal step.}

    \outputiteme
        {qn_fail}
        {\textctref{augsys_qn_failed}}
        {3}
        {Number of failed quasinormal augmented system solves.}

    \outputiteme
        {pg_iter}
        {\textctref{augsys_pg_iter}}
        {3}
        {Number of iterations taken during the last iterate by the augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \outputiteme
        {pg_iter_tot}
        {\textctref{augsys_pg_iter_total}}
        {3}
        {Total number of iterations taken by the augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \outputiteme
        {pg_err}
        {\textctref{augsys_pg_err}}
        {3}
        {Error in the last augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \outputiteme
        {pg_err_trg}
        {\textctref{augsys_pg_err_target}}
        {3}
        {Target error in the last augmented system solve when projecting the gradient prior to the tangential subproblem.}

    \outputiteme
        {pg_fail}
        {\textctref{augsys_pg_failed}}
        {3}
        {Number of failed projected gradient augmented system solves.}

    \outputiteme
        {pr_iter}
        {\textctref{augsys_proj_iter}}
        {3}
        {Number of iterations taken during the last iterate by the augmented system solve during the nullspace projection in the tangential subproblem.  Since there are likely many projections, this is the total number of iterations over all projections.}

    \outputiteme
        {pr_iter_tot}
        {\textctref{augsys_proj_iter_total}}
        {3}
        {Total number of iterations taken by the augmented system solve during the nullspace projection in the tangential subproblem.}

    \outputiteme
        {pr_err}
        {\textctref{augsys_proj_err}}
        {3}
        {Error in the last augmented system solve during the nullspace projection in the tangential subproblem.  Note, since there are likely many projections during a single tangential subproblem, this represents the error from the last such solve.}

    \outputiteme
        {pr_err_trg}
        {\textctref{augsys_proj_err_target}}
        {3}
        {Target error in the last augmented system solve during the tangential step.}

    \outputiteme
        {pr_fail}
        {\textctref{augsys_proj_failed}}
        {3}
        {Number of failed nullspace projection augmented system solves.}

    \outputiteme
        {tg_iter}
        {\textctref{augsys_tang_iter}}
        {3}
        {Number of iterations taken during the last iterate by the augmented system solve during the tangential step.}

    \outputiteme
        {tg_iter_tot}
        {\textctref{augsys_tang_iter_total}}
        {3}
        {Total number of iterations taken by the augmented system solve during the tangential step.}

    \outputiteme
        {tg_err}
        {\textctref{augsys_tang_err}}
        {3}
        {Error in the last augmented system solve during the tangential step.}

    \outputiteme
        {tg_err_trg}
        {\textctref{augsys_tang_err_target}}
        {3}
        {Target error in the last augmented system solve during the tangential step.}

    \outputiteme
        {tg_fail}
        {\textctref{augsys_tang_failed}}
        {3}
        {Number of failed tangential step augmented system solves.}

    \outputiteme
        {lm_iter}
        {\textctref{augsys_lmh_iter}}
        {3}
        {Number of iterations taken during the last iterate by the augmented system solve during the equality multiplier solve.}

    \outputiteme
        {lm_iter_tot}
        {\textctref{augsys_lmh_iter_total}}
        {3}
        {Total number of iterations taken by the augmented system solve during the equality multiplier solve.}

    \outputiteme
        {lm_err}
        {\textctref{augsys_lmh_err}}
        {3}
        {Error in the last augmented system solve during the equality multiplier solve.}

    \outputiteme
        {lm_err_trg}
        {\textctref{augsys_lmh_err_target}}
        {3}
        {Target error in the last augmented system solve during the equality multiplier solve.}

    \outputiteme
        {lm_fail}
        {\textctref{augsys_lmh_failed}}
        {3}
        {Number of failed equality multiplier augmented system solves.}

    \outputiteme
        {aug_itr_tot}
        {\textctref{augsys_iter_total}}
        {3}
        {Total number of iterations taken by all augmented system solves.  We use this to help determine the overall expense of the augmented system solver and its precondition.}
\end{boldlist}

\chapter{\chadvanced}\label{ch:advanced}

        Optizelle contains many additional features such as customizing the output and defining custom vector spaces.  We detail these features below.

\section{\secmessaging}\label{sec:messaging}

        By default, we output messages from Optizelle to \textct{stdout}.  However, in some environments, we require different behavior.  For example,
\begin{itemize}
    \item When we use Optizelle in a program with a GUI, we may not to display the output to a separate window.
    \item When using MPI in a distributed, parallel environment we likely want to restrict our output to only the rank 0 processor.
\end{itemize}
\noindent In these cases, we want to define a new messaging object.

        Messaging objects are simply functions that accept a string and print it accordingly.  In code, we specify this object as:
\phantomsection\label{itm:Messaging}
\phantomsection\label{itm:Optizelle::Messaging::stdout}
\phantomsection\label{itm:Optizelle.Messaging.stdout}
\begin{boldlist}
    \apiitem
        {C++}
        {\textct{Optizelle::Messaging::t}}
        {Function matches type}
        {\lstinputlisting[style=C++,linerange={Optizelle0-Optizelle1,Messaging0-Messaging1,Messaging2-Messaging3,Optizelle2-Optizelle3}]{@OPTIZELLECPPPATH@/optizelle.h}}

    \apiitem
        {Python}
        {\textct{Optizelle.Messaging.t}}
        {Function matches type}
        {\lstinputlisting[style=Python,linerange=Messaging0-Messaging1]{@OPTIZELLEPYTHONPATH@/Messaging.py}}

    \apiitem
        {MATLAB/Octave}
        {\textct{Optizelle.Messaging.t}}
        {Function matches type}
        {\lstinputlisting[style=Matlab,linerange=Messaging0-Messaging1]{@OPTIZELLEMATLABPATH@/setupOptizelle.m}}
\end{boldlist}

        Once we define a custom messaging object, we are free to pass it to Optizelle, which occurs when we call the function \textct{getMin}.  We describe this process in the section \hyperref[sec:solve]{\secsolve}.

        As an example, we modify the messaging object in our \exampleref{\secrosenbrockadvancedapi}{sec:rosenbrockadvancedapi} example:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Messaging0-Messaging1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Messaging0-Messaging1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Messaging0-Messaging1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.m}}
\end{boldlist}

\section{\secerrors}\label{sec:errors}

        In general, Optizelle handles algorithmic errors gracefully and will exit the optimization with the current best solution.  However, errors in the problem setup or functions provided by the user cause Optizelle to exit its routines immediately.

        The mechanism for handling errors depends on the type and interface.  For errors that originate with Optizelle, we use the following scheme
\begin{boldlist}
    \apiitem
        {C++}
        {\textct{Optizelle::Exception::t}}
        {Exception handling}
        {\lstinputlisting[style=C++,linerange={Optizelle0-Optizelle1,Exception0-Exception1,Optizelle2-Optizelle3}]{@OPTIZELLECPPPATH@/exception.h}}

    \apiitem
        {Python}
        {\textct{Optizelle.Exception.t}}
        {Exception handling}
        {\lstinputlisting[style=Python,linerange=Exception0-Exception1]{@OPTIZELLEPYTHONPATH@/Exception.py}}

    \apiitemshort
        {MATLAB/Octave}
        {\textct{error}}
        {Native error function}
\end{boldlist}
\noindent For errors that originate within the user code, we exit Optizelle and propagate the original error back to parent code.  Typically, the best way to throw an error in the user code is by exceptions in C++ and Python and the \textct{error} function in MATLAB/Octave.


    As an example, reading an invalid parameter from file raises an Optizelle error.  We catch this error with the following code
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Exception0-Exception1]{@ERRORPATH@/read_params.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Exception0-Exception1]{@ERRORPATH@/read_params.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Exception0-Exception1]{@ERRORPATH@/read_params.m}}
\end{boldlist}

\section{\seccustomvector}\label{sec:customvector}

        In continuous optimization, we most often optimize over a simple vector of numbers in $\re^m$.  If that's the case, we provide a reasonable implementation of this vector space and describe it in section \hyperref[sec:importvs]{\secimportvs}.  However, in some situations we want to use a different space.  For example:
\begin{itemize}
    \item In PDE constrained optimization, we may want to optimize over a space of functions such as $L^2(\Omega)$.
    \item In certain relaxations to discrete optimization problems, we must optimize over the space of symmetric, positive definite matrices.
    \item When the variables in $\re^m$ have radically different scalings, we may need to alter the inner product to normalize our variables.
    \item On large-scale problems with billions of variables, we must store the vectors in parallel and compute operations using a messaging system such as MPI.
\end{itemize}
\noindent In each of these cases, we need to define a custom vector space for our problem.

        Each custom vector space requires us to define the following operations:
\begin{boldlist}
    \customvsitem
        {init}
        {init(x)}
        {$\textit{init}\leftarrow \xi(W)$ where $x\in W$}
        {init(x)}
        {$\textit{init}\leftarrow \xi(W)$ where $x\in W$}
        {init(x)}
        {$\textit{init}\leftarrow \xi(W)$ where $x\in W$}
        {Initializes memory for a new vector.  Here, the function $\xi:\{X,Y,Z\}\rightarrow X\cup Y\cup Z$ denotes a choice function that selects an arbitrary element from the appropriate set.  Essentially, this states that we want a valid element in the vector space, but we don't care what the element is.}

    \customvsitem
        {copy}
        {copy(x,y)}
        {$y\leftarrow x$}
        {copy(x,y)}
        {$y\leftarrow x$}
        {copy(x)}
        {$\textit{copy}\leftarrow x$}
        {In C++ and Python, a shallow copy of the vector $x$ into the vector $y$.  In MATLAB/Octave, return the vector $x$}.

    \customvsitem
        {scal}
        {scal(alpha,x)}
        {$x\leftarrow \alpha x$}
        {scal(alpha,x)}
        {$x\leftarrow \alpha x$}
        {scal(alpha,x)}
        {$\textit{scal}\leftarrow \alpha x$}
        {In C++ and Python, overwrite $x$ with $\alpha x$.  In MATLAB/Octave, return $\alpha x$.}

    \customvsitem
        {axpy}
        {axpy(alpha,x,y)}
        {$y\leftarrow \alpha x + y$}
        {axpy(alpha,x,y)}
        {$y\leftarrow \alpha x + y$}
        {axpy(alpha,x,y)}
        {$\textit{axpy}\leftarrow \alpha x + y$}
        {In C++ and Python, overwrite $y$ with $\alpha x+y$.  In MATLAB/Octave, return $\alpha x+y$.}

    \customvsitem
        {innr}
        {innr(x,y)}
        {$innr\leftarrow \langle x,y\rangle$}
        {innr(x,y)}
        {$innr\leftarrow \langle x,y\rangle$}
        {innr(x,y)}
        {$innr\leftarrow \langle x,y\rangle$}
        {Return the inner product between $x$ and $y$.}

    \customvsitem
        {zero}
        {zero(x)}
        {$x\leftarrow 0$}
        {zero(x)}
        {$x\leftarrow 0$}
        {zero(x)}
        {$\textit{zero}\leftarrow 0$}
        {In C++ and Python, overwrite $x$ with $0$.  In MATLAB/Octave, return $0$.  Note, this is not necessarily the same as \textct{scal(0.,x)} since, in practice, $x$ may contain NaNs and Infs.  As such, we consider \textctref{zero} to be a safe operation that returns $0.$ whereas \textctref{scal} may be an unsafe operation.}

    \customvsitem
        {rand}
        {rand(x)}
        {$x\leftarrow \psi(W)$ where $x\in W$}
        {rand(x)}
        {$x\leftarrow \psi(W)$ where $x\in W$}
        {rand(x)}
        {$\textit{rand}\leftarrow \psi(W)$ where $x\in W$}
        {In C++ and Python, overwrite $x$ with a random vector.  In MATLAB/Octave, return a random vector.  Here, the function $\psi:\{X,Y,Z\}\rightarrow X\cup Y\cup Z$ denotes a stochastic choice function that randomly selects an element from the appropriate set.  Essentially, this states that we want a valid, random element in the vector space.  Primarily, we use these vectors for our diagnostic tests controlled by the parameters \textctref{f_diag}, \textctref{g_diag}, and \textctref{h_diag}.}
\end{boldlist}
\noindent In addition, the vector space associated with the codomain of the inequality constraints, $Z$, requires the following operations:
\begin{boldlist}
    \customvsitem
        {prod}
        {prod(x,y,z)}
        {$z\leftarrow x\circ y$}
        {prod(x,y,z)}
        {$z\leftarrow x\circ y$}
        {prod(x,y)}
        {$\textit{prod}\leftarrow x\circ y$}
        {In C++ and Python, overwrite $z$ with $x\circ y$.  In MATLAB/Octave, return $x\circ y$.  Here, $\circ$ denotes a pseudo-Jordan product between two elements.  We say pseudo-Jordan in the sense that we do not require a full Euclidean-Jordan algebra.  Instead, we drop the requirement for commutativity.  Hence, for linear bound constraints, we define that
$$
        [x\circ y]_i = x_iy_i.
$$
Hence, the product denotes the pointwise or Hadamard product.  For second-order cone constraints, we define that
$$
        \begin{bmatrix}x_0\\\bar{x}\end{bmatrix} \circ \begin{bmatrix}y_0\\\bar{y}\end{bmatrix}=\begin{bmatrix} x_0y_0 + \bar{x}^T\bar{y}\\x_0 \bar{y} + y_0 \bar{x}\end{bmatrix}.
$$
For semidefinite programming, we have that
$$
        X\circ Y = XY.
$$
Alternatively, we can define that
$$
        X\circ Y = \frac{XY + YX}{2},
$$
but the inverse operation \textctref{linv} below becomes far less efficient.}

    \customvsitem
        {id}
        {id(x)}
        {$x\leftarrow e$}
        {id(x)}
        {$x\leftarrow e$}
        {id(x)}
        {$\textit{id}\leftarrow e$}
        {In C++ and Python, overwrite $x$ with $e$.  In MATLAB/Octave, return $e$.  In this function, $e$ denotes the identity element for the Jordan algebra.  Hence, this function creates element $e$ so that $x\circ e=x$.   For linear bound constraints, $e$ denotes the vector of all ones.  For second-order cone constraints, $e=\begin{bmatrix} 1 & 0 & \dots & 0\end{bmatrix}^T$.  For semidefinite constraints, $e=I$}

    \customvsitem
        {linv}
        {linv(x,y,z)}
        {$z\leftarrow L(x)^{-1} y$}
        {linv(x,y,z)}
        {$z\leftarrow L(x)^{-1} y$}
        {linv(x,y)}
        {$\textit{linv}\leftarrow L(x)^{-1} y$}
        {In C++ and Python, overwrite $z$ with $L(x)^{-1} y$.  In MATLAB/Octave, return $L(x)^{-1} y$.  Here, the function \textctref{linv} denotes the inverse operation to \textctref{prod}.  Note, $\textctref{prod}$ defines a bilinear operation so that there exists a linear operator $L(x)$ such that $x\circ y=L(x)y$.  The function \textctref{linv} computes the action of the {\it inverse} of $L(x)$ on a vector.  For linear bound constraints, $L(x)=\textnormal{Diag}(x)$, where $\textnormal{Diag}(x)$ denotes the diagonal matrix with $x$ on the diagonal.  For second-order cone constraints, $L(x)=\textnormal{Arw}(x)$ where we define $\textnormal{Arw}(x)$ as
$$
        \textnormal{Arw}\left(\begin{bmatrix}x_0\\\bar{x}\end{bmatrix}\right) =
\begin{bmatrix}
        x_0 & \bar{x}^T\\\bar{x} & x_0 I
\end{bmatrix}.
$$
For semidefinite constraints, we can either define that $L(X)=X$ or that $L(X)=\frac{X\cdot + \cdot X}{2}$.  Generally, it is preferable to use the first definition since $L(X)^{-1}=X^{-1}$.  In the second case, we require the solution of the Sylvester equations.}

    \customvsitem
        {barr}
        {barr(x)}
        {$\textit{barr}\leftarrow \phi(x)$ where $x\circ\nabla \phi(x)=e$}
        {barr(x)}
        {$\textit{barr}\leftarrow \phi(x)$ where $x\circ\nabla \phi(x)=e$}
        {barr(x)}
        {$\textit{barr}\leftarrow \phi(x)$ where $x\circ\nabla \phi(x)=e$}
        {Return the result of the barrier function applied to a vector.  Here, the function $\phi:Z\rightarrow \re$ denotes the barrier function, which we require to satisfy
$$
    x\circ \nabla \phi(x) = e.
$$
For linear bound constraints, this is simply the log-barrier function
$$
    \phi(x) = \sum\limits_{i=1}^m \log(x_i).
$$
For second-order cone constraints, we define this as
$$
    \phi\left(\begin{bmatrix}x_0\\\bar{x}\end{bmatrix}\right) = \frac{1}{2} \log(x_0^2-\langle \bar{x},\bar{x}\rangle).
$$
For semidefinite constraints, we define this as
$$
    \phi(X)=\log(\textnormal{det}(X))
$$
where $\textnormal{det}(X)$ denotes the determinant of $X$.}

    \customvsitem
        {srch}
        {srch(x,y)}
        {$\textit{srch}\leftarrow \arg\max\{\alpha\in\re : \alpha x + y \succeq 0, \alpha\geq 0\}$}
        {srch(x,y)}
        {$\textit{srch}\leftarrow \arg\max\{\alpha\in\re : \alpha x + y \succeq 0, \alpha\geq 0\}$}
        {srch(x,y)}
        {$\textit{srch}\leftarrow \arg\max\{\alpha\in\re : \alpha x + y \succeq 0, \alpha\geq 0\}$}
        {Return how far we can move in the direction $x$ from the point $y$ before violating nonnegativity.  In other words, the function \textctref{srch} denotes the search function used to maintain strict feasibility with respect to the inequality constraint.  We define this as
$$
    \arg\max\{\alpha\in\re : \alpha x + y \succeq 0, \alpha\geq 0\}
$$
where we assume $y\succ 0$.  Hence, $\alpha$ denotes the maximum distance we can move in the direction $x$ from $y$ so that $\alpha x + y$ remains feasible.  Note, sometimes this number is infinite.  If this is the case, we must return \textct{Inf}.}

    \customvsitem
        {symm}
        {symm(x)}
        {$x\leftarrow \pi(x)$ where $\pi(x\circ y)=\pi(y\circ x)$}
        {symm(x)}
        {$x\leftarrow \pi(x)$ where $\pi(x\circ y)=\pi(y\circ x)$}
        {symm(x)}
        {$symm \leftarrow \pi(x)$ where $\pi(x\circ y)=\pi(y\circ x)$}
        {In C++ and Python, overwrite $x$ with its symmetrization.  In MATLAB/Octave, return the symmetrization of $x$.  Here, the function $\pi:Z\rightarrow Z$ denotes the symmetrization operator.  We require this operator since we relax the commutativity requirement from the Euclidean-Jordan algebra.  For linear bound constraints and second-order cone constraints, this operation does nothing.  In addition, for semidefinite constraints where $X\circ Y=\frac{XY+YX}{2}$, this operation does nothing.  However, for semidefinite constraints where $X\circ Y=XY$, we may use symmetrization,
$$
    \pi(X)=\frac{X+X^T}{2},
$$
or more generally the \textit{similar symmetrization} operator,
$$
    \pi_P(X)=\frac{(PXP^{-1}+(PXP^{-1})^T}{2},
$$
where we require $P$ to be nonsingular.}
\end{boldlist}

        Next, we require these vector-space functions be encapsulated in the following structures:
\begin{boldlist}
    \vswrapperitem
        {C++}
        {Templated struct with static members and a single typedef called \textct{Vector}}
        {A vector space in C++ must be declared as a templated struct with static members.  As far as the template parameter, we template on our real scalar type and require that each of the functions that accept or return a scalar use this type.  This template parameter allows us to insure that each of the vector spaces uses the same real type, which is important for consistency.  Next, each of the above functions must be included and declared static.  This allows us to access the functions without instantiating the struct.  We also require a single typedef called \textct{Vector}.  This defines the vector type used by each of the vector-space functions.  In addition to the typedef, we require that this vector type implement move semantics, which includes both the move constructor as well as move semantics for the assignment operator.  Note, items in the standard library all properly implement move semantics.  As such, as long as we use \textct{std::vector}, \textct{std::unique_ptr}, or \textct{std::shared_ptr}, we satisfy this requirement.}

    \vswrapperitem
        {Python}
        {Class with static methods}
        {A vector space in Python must be declared as a class consisting entirely of static methods.  In other words, we require a class that implements all of the above vector-space functions where we decorate each function definition with the decorator \textct{@staticmethod}.}

    \vswrapperitem
        {MATLAB/Octave}
        {Structure array}
        {A vector space in MATLAB/Octave must be declared as a structure array with all of the above methods present.}
\end{boldlist}

        As an example, we define and use a custom vector space for $\re^m$ in our \exampleref{\secrosenbrockadvancedapi}{sec:rosenbrockadvancedapi} example:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=VectorSpace0-VectorSpace1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=VectorSpace0-VectorSpace1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=VectorSpace0-VectorSpace1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.m}}
\end{boldlist}

\section{\seccone}
\phantomsection\label{itm:SQL}
\phantomsection\label{itm:Optizelle::SQL}

        In the case of C++ and MATLAB/Octave, we provide a built-in vector space for semidefinite, second-order cone, and linear (SQL) programs:
\begin{boldlist}
    \vsitem
        {C++}
        {\textct{Optizelle::SQL::Vector}}
        {\textct{Optizelle::SQL}}
    \vsitem
        {MATLAB/Octave}
        {\textct{Optizelle.SQL.create} (produces a structure array)}
        {\textct{Optizelle.SQL}}
\end{boldlist}

        In order to create a C++ \textct{SQL::Vector}, we use the following constructor
\begin{flushleft}
    \lstinputlisting[style=C++,linerange={Optizelle0-Optizelle1,SQL0-SQL1,SQLVector0-SQLVector1,SQLVector2-SQLVector3,SQLVector4-SQLVector5,SQL2-SQL3,Optizelle2-Optizelle3}]{@OPTIZELLECPPPATH@/vspaces.h}
\end{flushleft}
Here, \textct{Cone::t} corresponds to the enumerated type \textctref{Cone} and \textct{Natural} refers to the architecture specific unsigned integer defined in \textct{Optizelle::Natural}.  The constructor creates an SQL variable with the specified types and sizes of cones.  Specifically, a linear cone of size $m$ denotes a vector in $\re^m$ that lies in the nonnegative orthant.  A quadratic cone of size $m$ denotes a vector in $\re^m$ that lies in the quadratic cone.  Finally, a semidefinite cone of size $m$ denotes a matrix in $\re^{m\times m}$ that lies in the cone of positive semidefinite matrices.  Note, even though we ultimately find a symmetric matrix, we compute with a full $m\times m$ matrix and not just the upper or lower half.  Using a full matrix affects how we define the derivatives of our inequality constraint $h$, so take care.  Specifically, $h^\prime(x)$ and $h^\prime(x)^*$ need to assume that their arguments are not symmetric, so consider both upper and lower triangular parts of the matrices.

        In order to create a MATLAB/Octave \textct{SQL} vector, we use the function
\begin{flushleft}
    \lstinputlisting[style=Matlab,linerange={SQLVector0-SQLVector1}]{@SQLRESTARTPATH@/sql_restart.m}
\end{flushleft}
where \textct{types} is a vector containing elements from the enumerated type \textctref{Cone} and \textct{sizes} is a vector denoting the size of the cones.  For example, in order to define a \textct{SQL} vector with a semidefinite, quadratic, and linear cone with sizes 2, 2, and 1, we use the syntax
\begin{flushleft}
    \lstinputlisting[style=Matlab,linerange={SQLSpec0-SQLSpec1}]{@SQLRESTARTPATH@/sql_restart.m}
\end{flushleft}
Otherwise, we define the meaning of each of these cones to be the same as the C++ case above.

        In order to access the elements of a C++ SQL vector, \textct{x}, we use the following indexing functions
\begin{center}\begin{tabular}{llll}
Number of cones & Type of cone & Type of Indexing & Use\\\hline
Single & Quadratic/Linear & Specific element & \textct{x(i)}\\
Multiple & Quadratic/Linear & Specific element & \textct{x(k,i)}\\
Multiple & Semidefinite & Specific element & \textct{x(k,i,j)}\\
Multiple & Semidefinite/Quadratic/Linear & First element & \textct{x.front(k)}\\
Multiple & Quadratic & First element & \textct{x.naught(k)}\\
Multiple & Quadratic & Second element & \textct{x.bar(k)}
\end{tabular}\end{center}
\noindent Finally, we have a couple of query functions
\begin{center}\begin{tabular}{lll}
Purpose & Use\\\hline
Size of block & \textct{x.blkSize(k)}\\
Type of block & \textct{x.blkType(k)}\\
Number of blocks & \textct{x.numblocks()}
\end{tabular}\end{center}

        In order to access the elements of a MATLAB/Octave SQL vector, \textct{x}, we note that the cones are stored in the cell array \textct{x.data} where each element in the cell array denotes a different cone.  We store quadratic and linear elements as column vectors and semidefinite elements as matrices.  For example, to access the $i$th element of the $k$th block when this block is quadratic or linear, we use the syntax \textct{x.data\{k\}(i)}.  To access the $(i,j)$th element of the $k$th block when the block is semidefinite, we use the syntax \textct{x.data\{k\}(i,j)}.

        As an example, we setup and solve a simple second-order cone program in our simple quadratic cone example:
\examplelabel{\secquadratic}{sec:quadratic}
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@SIMPLEQUADRATICCONEPATH@/simple_quadratic_cone.cpp}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab]{@SIMPLEQUADRATICCONEPATH@/simple_quadratic_cone.m}}
\end{boldlist}
\noindent Similarly, we setup and solve a simple semidefinite program in our simple SDP cone example:
\examplelabel{\secsdp}{sec:sdp}
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@SIMPLESDPCONEPATH@/simple_sdp_cone.cpp}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab]{@SIMPLESDPCONEPATH@/simple_sdp_cone.m}}
\end{boldlist}

\section{\secsmanip}\label{sec:smanip}

        State manipulation is a process that allows us to insert arbitrary code into the optimization algorithms.  We use this to add new features such as the following:
\begin{itemize}
    \item Real-time optimal control systems require hard computational time limit.  After this time, we must exit the optimization cleanly and return our most current solution.
    \item For a particular application, we may want to use a custom line-search, but not recode the rest of the optimization algorithms.
    \item In signal processing, we may know our optimal solution does not have any frequencies above a certain threshold.  When this is difficult to formulate as a constraint, we can simply run a high-pass filter on the optimization variable at the end of each iteration.
    \item When our algorithms perform poorly, we may want to run some custom diagnostics at the end of each optimization iteration.
    \item In order to replicate our optimization runs, we need to write a restart file at the end of each optimization iteration.  We describe this process in the section \hyperref[sec:restart]{\secrestart}.
    \item Internally, we use state manipulation to add algorithms such as the interior point method to the composite-step SQP method.
\end{itemize}
\noindent In each of these situations, we make use of the \textctref{StateManipulator}.

        In order to manipulate the state, we use an object called the \textctref{StateManipulator}.  During the optimization computation, we repeatedly call this object with the \hyperref[sec:fns]{bundle of functions}, \hyperref[sec:state]{optimization state}, and the \hyperref[itm:OptimizationLocation]{location}.  At this point, we may do any computation and modify the state as desired.  In C++ and Python, we implicitly return these changes to the state.  In MATLAB/Octave, we must return the state explicitly.

        In code, we specify the \textctref{StateManipulator} as:
\phantomsection\label{itm:StateManipulator}
\begin{boldlist}
    \apiitem
        {C++}
        {\textct{Optizelle::StateManipulator}}
        {Inheritance}
        {\lstinputlisting[style=C++,linerange={Optizelle0-Optizelle1,StateManipulator0-StateManipulator1,Optizelle2-Optizelle3}]{@OPTIZELLECPPPATH@/optizelle.h}}

    \apiitem
        {Python}
        {\textct{Optizelle.StateManipulator}}
        {Inheritance}
        {\lstinputlisting[style=Python,linerange=StateManipulator0-StateManipulator1]{@OPTIZELLEPYTHONPATH@/Functions.py}}

    \apiitem
        {MATLAB/Octave}
        {\textct{Optizelle.StateManipulator}}
        {Members present}
        {\lstinputlisting[style=Matlab,linerange=StateManipulator0-StateManipulator1]{@OPTIZELLEMATLABPATH@/setupOptizelle.m}}
\end{boldlist}
\noindent Once we define the \textctref{StateManipulator}, we call the optimization solver with one of the following four commands, which differs slightly from those defined in the section \hyperref[sec:solve]{\secsolve}.  In essence, we add the \textctref{StateManipulator} as the last argument to \textct{getMin}:
\begin{boldlist}
    \restartitem
        {C++}
        {C++}
        {SmanipSolver0-SmanipSolver1}
        {1}
        {cpp}

    \restartitem
        {Python}
        {Python}
        {SmanipSolver0-SmanipSolver1}
        {0}
        {py}

    \restartitem
        {MATLAB/Octave}
        {Matlab}
        {SmanipSolver0-SmanipSolver1}
        {0}
        {m}
\end{boldlist}

        As an example, we use the \textctref{StateManipulator} to add restarts to our \exampleref{\secrosenbrockadvancedapi}{sec:rosenbrockadvancedapi} example.  We discuss restarts in the section entitled \hyperref[sec:restart]{\secrestart}.
\phantomsection\label{itm:StateManipulatorExample}
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=RestartManipulator0-RestartManipulator1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=RestartManipulator0-RestartManipulator1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=RestartManipulator0-RestartManipulator1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.m}}
\end{boldlist}
\noindent In order to use this \textctref{StateManipulator}, we call Optizelle's solver with the code:
\begin{boldlist}
    \shortexampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Solver0-Solver1,widthgobble=1*4]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.cpp}}

    \shortexampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Solver0-Solver1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.py}}

    \shortexampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Solver0-Solver1,widthgobble=1*4]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.m}}
\end{boldlist}

\section{\secrestart}\label{sec:restart}

        Restarts are a mechanism to read, write, and archive the progress and solution of an optimization algorithm.  In other words, restarts allow us to save the state of an optimization algorithm before it finishes computing.  We do this for several reasons:
\begin{itemize}
    \item In scientific or engineering tasks, we may need to replicate or reproduce our work.

    \item Large, computationally expensive problems typically require parallel computing clusters.  With thousands of computers working in concert, the chance that a hardware failure occurs increases.  One way to recover from these failures it to restart the computation after a crash.

    \item Parallel computing clusters generally share their computing resources between several users.  In order to fairly divide use, batch jobs require us to specify the amount of time required to run a job.  If we guess this number poorly, restarts allow us to complete the computation later.

    \item For many problems, it's unclear what algorithm we should use.  Second-order methods such as Newton's method are only guaranteed to converge quadratically near the solution.  As such, we may be well served to start the computation with a first-order method and then switch to a second-order method as we approach optimality.  We can accomplish this by writing a restart file, modifying the specified algorithm, and then resuming the computation.

    \item Often an algorithm makes progress toward a solution, but then stagnates.  In order to diagnose why the algorithm stagnated, we may examine the restart file at the iteration of stagnation.  Furthermore, if we have insight into the underlying problem structure, we could modify the solution by hand or with an outside tool and then restart the computation.
\end{itemize}
\noindent Each of these situations requires restarts.

        As long as we use our built-in vector spaces such as \textctref{Rm} and \textctref{SQL}, we can easily read and write the state to a JSON formatted file with the commands:
\phantomsection\label{itm:write_restart}
\phantomsection\label{itm:read_restart}
\begin{boldlist}
    \restartitem
        {C++}
        {C++}
        {WriteReadRestart0-WriteReadRestart1}
        {1}
        {cpp}

    \restartitem
        {Python}
        {Python}
        {WriteReadRestart0-WriteReadRestart1}
        {0}
        {py}

    \restartitem
        {MATLAB/Octave}
        {Matlab}
        {WriteReadRestart0-WriteReadRestart1}
        {0}
        {m}
\end{boldlist}
\noindent As was the case before, \textct{XX}, \textct{YY}, and \text{ZZ} correspond to the vector spaces $X$, $Y$, and $Z$ described in the section \hyperref[sec:importvs]{\secimportvs}.  Likely, they are just \textctref{Rm} or \textctref{SQL}.  Next, we call the function with a \textctref{Messaging} object, \textct{msg}.  Third, the string \textct{fname} denotes the file name that we read or write the restart.  Next, the variable \textct{state} denotes a \textctref{State} object.  During a write, we write the provided state to file.  During a read, we read the restart file into the specified state.  Finally, the variables \textct{x}, \textct{y}, and \textct{z} denote variables in the spaces \textct{XX}, \textct{YY}, and \textct{ZZ}, respectively.  We only use them to initialize memory, so any valid vector works.

        As an example, we return to our \exampleref{\secrosenbrockadvancedapi}{sec:rosenbrockadvancedapi} example.  We already showed how to write a restart file at the end of each optimization iteration in our discussion of \textctref{StateManipulator}s.  Specifically, we used the \textctref{write_restart} command in our \textctref{StateManipulator} \hyperref[itm:StateManipulatorExample]{example}.  To compliment that code, we read an optional restart file prior to optimization with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=ReadRestart0-ReadRestart1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=ReadRestart0-ReadRestart1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=ReadRestart0-ReadRestart1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.m}}
\end{boldlist}
\noindent As a note, we call the \hyperref[sec:params]{JSON reader} after we read the restart file.  If we do this in the reverse order, the restart read process overwrites all of our parameters.

        For \textctref{Rm} and \textctref{SQL}, the above process works seamlessly.  In fact, C++, Python, and MATLAB/Octave all use the same format for \textct{Rm}, which means we can write a restart file in one language and then read the same restart file in a different language.  However, for \hyperref[sec:customvector]{customized vector spaces}, we must provide Optizelle information on how to translate a vector to a JSON formatted file using the following commands:
\phantomsection\label{itm:serialize}
\phantomsection\label{itm:deserialize}
\begin{boldlist}
    \restartitemalt
        {C++}
        {C++}
        {Serialization0-Serialization1}
        {0}
        {cpp}

    \restartitemalt
        {Python}
        {Python}
        {Serialization0-Serialization1}
        {0}
        {py}

    \restartitemalt
        {MATLAB/Octave}
        {Matlab}
        {Serialization0-Serialization1}
        {0}
        {m}
\end{boldlist}
\noindent In each command, the \textctref{serialize} and \textctref{deserialize} functions work in a similar manner.  The \textctref{serialize} function accepts a vector, the vector's name, and the current iteration. Then, \textctref{serialize} returns a valid JSON structure corresponding to this vector.  For \textctref{Rm}, we use simple JSON vector notation such as \textct{[1.2, 2.3, 3.4]}, but this can be significantly more complicated.  In fact, for large-scale optimization problems, we suggest storing the vector in a separate binary file and returning a JSON structure that denotes the name of the file.  In order to make process of defining these file names easier, we provide access to the variable name and iteration number as the second and third arguments, respectively.  Next, the \textctref{deserialize} function accepts two arguments and returns a vector.  The first argument denotes a vector in the same vector space as the vector we need translated.  The second argument denotes a JSON formatted string of the vector we need to translate.  Generally, we use the first argument to initialize memory for the vector we eventually return.  Then, we use the JSON formatted string to fill in the appropriate information.  In C++, we accomplish this process through template specialization.  In Python, we call the \textct{serialize} and \textctref{deserialize} functions in the \hyperref[sec:import]{\textct{Optizelle.json.Serialization}} module with the \textct{"registration"} string.  Then, we provide our custom \textctref{serialize} and \textctref{deserialize} routines along with the type of the vector that we want to serialize in the variable \textct{vector_type}.  We obtain this information with the \textct{type} command and require it in order to disambiguate multiple serialization routines.  In MATLAB/Octave, we call the \textctref{serialize} and \textctref{deserialize} functions in the \hyperref[sec:import]{\textct{Optizelle.json.Serialization}} structure with the \textct{'registration'} string.  Then, similar to Python, we provide our custom \textctref{serialize} and \textctref{deserialize} routines along with a function \textct{check}.  The function \textct{check} accepts a single argument and returns \textct{1} when called with the kind of vector we want to serialize and \textct{0} otherwise.  We require the \textct{check} function to disambiguate the different serialization functions, so we try to make it as specific as possible.

        As an example, we return to our \exampleref{\secrosenbrockadvancedapi}{sec:rosenbrockadvancedapi} example.  There, we define custom serialization routines with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Serialization0-Serialization1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Serialization0-Serialization1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Serialization0-Serialization1]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.m}}
\end{boldlist}

        As another example, we refer to our \exampleref{\secsimpleconstrainedadvancedapi}{sec:simpleconstrainedadvancedapi} example.  This differs from the previous example since we write our vectors to a separate file.  In order to accomplish this, we define custom serialization routines with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++,linerange=Serialization0-Serialization1]{@SIMPLECONSTRAINEDADVANCEDAPIPATH@/simple_constrained_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python,linerange=Serialization0-Serialization1]{@SIMPLECONSTRAINEDADVANCEDAPIPATH@/simple_constrained_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=Matlab,linerange=Serialization0-Serialization1]{@SIMPLECONSTRAINEDADVANCEDAPIPATH@/simple_constrained_advanced_api.m}}
\end{boldlist}

        In some situations, we want to avoid using JSON all together.  Generally, this occurs when integrating Optizelle into an existing application with rigid I/O requirements.  In this case, we provide an alternative mechanism to generate restarts.

        At its core, restarts consist of two mechanisms: release and capture.  Release transforms the state into a collection of lists that contain all of the optimization information.  Capture reverses this process.  Generally, we do a release, write these lists containing the state information to file, and then capture the state.  The idea behind this process is that we don't expect ourselves to remember all of the optimization variables.  Certainly, this collection of variables changes whenever we update the code or add new algorithms.  However, if we know how to write a list of variables to file, we can simply iterate over the list and take the appropriate action.

       More specifically, the capture and release functions operate on lists of tuples.  As far as the type used for the lists, we have:
\begin{boldlist}
    \simpletypeitem
        {C++}
        {std::list}

    \simpletypeitem
        {Python}
        {list}

    \simpletypeitem
        {MATLAB/Octave}
        {cell}
\end{boldlist}
\noindent For the type used by the tuples, we have
\begin{boldlist}
    \simpletypeitem
        {C++}
        {std::pair}

    \simpletypeitem
        {Python}
        {tuple}

    \simpletypeitem
        {MATLAB/Octave}
        {cell}
\end{boldlist}
\noindent In these tuples, we always use a string for the first element.  This represents the unique label for the item.  The second items depends on the type involved and we enumerate these possibilities below:
\begin{boldlist}
    \rtypeitem
        {Reals}
        {List of \textctref{Real} numbers and labels.}

    \rtypeitem
        {Naturals}
        {List of \textctref{Natural} numbers and labels.}

    \rtypeitem
        {Params}
        {List of strings and labels.  These strings correspond to the various \textctref{Enumerated} types that have been converted to strings using the \textct{to_string} function, which we also describe in the \textctref{Enumerated} type documentation.}

    \rtypeitem
        {X_Vectors}
        {List of \textctref{X_Vector} vectors and labels.}

    \rtypeitem
        {Y_Vectors}
        {List of \textctref{Y_Vector} vectors and labels.}

    \rtypeitem
        {Z_Vectors}
        {List of \textctref{Z_Vector} vectors and labels.}
\end{boldlist}
\noindent Based on the above types, we release and capture the state with the following code:
\begin{boldlist}
    \restartitemlong
        {C++}
        {C++}
        {Release0-Release1,Capture0-Capture1}
        {1}
        {cpp}

    \restartitemlong
        {Python}
        {Python}
        {Release0-Release1,Capture0-Capture1}
        {0}
        {py}

    \restartitemlong
        {MATLAB/Octave}
        {Matlab}
        {Release0-Release1,Capture0-Capture1}
        {0}
        {m}
\end{boldlist}
\noindent As with \textctref{read_restart} and \textctref{write_restart}, we most likely use this functions within a \textctref{StateManipulator}.  However, when possible, we are likely better off just using the JSON formatted restart mechanisms within \textctref{read_restart} and \textctref{write_restart}.

\section{\seccaching}\label{sec:caching}

    Internally, Optizelle caches many operations in order to reduce unnecessary computation.  This includes computations such as the objective or gradient evaluations.  Nevertheless, there are operations that should be cached that Optizelle does not control due to its matrix-free nature.  These operations must be cached by the user's code.  In the following section, we detail what these operations are and how they should be cached.

    The following table summarizes the different pieces of the code that can be cached, the number of items that should be stored, and the priority of caching this particular element.
\begin{boldlist}
    \cacheitem
        {Objective evaluation during the first gradient solve}
        {Objective evaluation}
        {objective}
        {\classUnconstrained}
        {Low}
        {1}
        {During initialization, Optizelle evaluates the gradient before the objective function.  Depending on the problem, it may be possible to evaluate and cache the objective function at the same time as this computation.  Specifically, when the objective function has the form $J(x)=f(g(x))$, we calculate the gradient as
        $$
            \nabla J(x) = g^\prime(x)^*\nabla f(g(x)).
        $$
        When the evaluation of $g(x)$ is expensive, such as solving a PDE or computing an inverse, we can use this calculation for both the gradient and the objective function by simultaneously computing both $f(g(x))$ and $\nabla f(g(x))$.

        Despite this utility, we do not typically prioritize this optimization.  We only benefit from saving this computation on the first iteration since Optizelle automatically caches the appropriate objective evaluations from the globalization, be that from line-search or trust-region algorithms, for the rest of the algorithm.  Therefore, subsequent gradient evaluations don't need to cache information about the objective since it's already been cached.  Nevertheless, when we repeatedly run the first iteration of an optimization problem in order to check the problem setup, this caching can save in the overall computation.}

    \cacheitem
        {Nested computations and state solves}
        {Nested computations and state solves}
        {state}
        {\classUnconstrained}
        {High}
        {1}
        {During the discussion of \cachesoftref{objective}{caching the objective}, we spoke of objective functions of the form $J(x)=f(g(x))$.  As we noted before, we have that
        $$
            \nabla J(x) = g^\prime(x)^*\nabla f(g(x)),
        $$
        but we also note that
        $$
            \nabla^2 J(x)\partial x = (g^{\prime\prime}(x)\partial x)^*\nabla f(g(x)) + g^\prime(x)^*\nabla^2 f(g(x))g^\prime(x)\partial x.
        $$
        Here, we see that we repeatedly use the quantity $g(x)$.  When the evaluation of $g(x)$ is expensive, such as solving a PDE or computing an inverse, then caching this element allows us to save significantly on the computational cost.  When the evaluation of $g(x)$ corresponds to a PDE solve, we refer to its evaluation as a state solve.}

    \cacheitem
        {Hessian}
        {Hessian}
        {hessian}
        {\classUnconstrained}
        {Low}
        {1}
        {Although Optizelle implements matrix-free algorithms, we can still use a precomputed Hessian when one is available.  Since calculating a Hessian can be expensive, we should only calculate it once per iteration and use it both in computing in the Hessian-vector product as well as the Hessian preconditioner.

        Overall, we do not prioritize computing the Hessian explicitly as it tends to require a lot of memory.  In addition, we rely on Newton's method in order to obtain quadratic convergence, but this fast convergence only occurs when close to the optimal solution.  When far away from the optimal solution, we waste computational effort when fully computing second-order information.  Generally, truncated-CG does a good job at determining how many Hessian-vector products are required and this does not require a fully computed Hessian.}

    \cacheitem
        {Factorization, inverse, or approximate inverse of the Hessian}
        {Hessian factorization}
        {invhessian}
        {\classNotEquality}
        {Low}
        {1}
        {For problems without equality constraints, Optizelle allows the user to define a preconditioner for the Hessian.  Recall, the null space projection inherent to the composite-step SQP method precludes a Hessian preconditioner from being used on problems with equality constraints.  For more details see the section \hyperref[sec:preconditioners]{\secpreconditioners}.  In any case, barring some kind of problem specific preconditioner, we can always compute and then factorize the Hessian to be used as a preconditioner.  If we do this, we should also \cachesoftref{hessian}{cache the Hessian computation} itself.

        Overall, we do not prioritize caching this information.  Similar to the discussion of \cachesoftref{hessian}{caching the Hessian}, far from the optimal solution, Newton's method does not guarantee quadratic convergence.  Therefore, we waste computational effort when computing the Hessian and factorizing it every iteration in order to force a pure Newton step.}

    \cacheitem
        {Total derivative (Jacobian) of the equality constraints}
        {Derivative of equality constraints}
        {gderiv}
        {\classEquality}
        {High}
        {2}
        {Although Optizelle only requires the action of the derivative of the equality constraints on a vector, $g^\prime(x)\partial x$, we benefit greatly from computing the total derivative $g^\prime(x)$ and caching the result.  First, depending on the inner product, when $g^\prime(x)$ or $g^\prime(x)^*$ is explicitly available, we can quickly compute its adjoint.  For example, when using the inner product $\langle x,y\rangle=x^Ty$, we simply have to transpose the matrix.  Second, each augmented system solve requires the repeated application of $g^\prime(x)\partial x$ and $g^\prime(x)^*\partial y$.  Combined with the first point, we can compute these operations by simply multiplying the cached result by a vector.  Third, when solving a problem with more than tens of variables, we require a preconditioner for the augmented system, which can be accomplished by finding a preconditioner for the operator $g^\prime(x) g^\prime(x)^*$.  When these derivatives are explicitly available, we can easily form and factorize this matrix.  As we discuss \cachesoftref{invschur}{below}, we should also cache this factorization.

        Note, unlike most of the other caching, we require two cached elements for an efficient code.  During globalization, we compute a new equality multiplier, which requires an augmented system solve at the trial point.  If we accept the point, we can reuse the new cached derivative.  However, if we reject the point, we will continue to require the current cached derivative.

        As a final note, it's often easier to cache and store $g^\prime(x)^*$ as opposed to $g^\prime(x)$.  For example, given the inner product $\langle x,y\rangle = x^Ty$ and a function of the form
        $$
        g(x) = \begin{bmatrix}
                g_1(x)\\
                \vdots\\
                g_m(x)
            \end{bmatrix},
        $$
        we can compute $g^\prime(x)^*$ as
        $$
                g^\prime(x)^* = \begin{bmatrix}
                        \nabla g_1(x) & \dots & \nabla g_m(x)
                    \end{bmatrix}.
        $$
        Especially with tools like automatic differentiation, this form becomes somewhat more natural to compute since we don't have to compute an extra transpose, which we undo later.  Further, if we decide to compute the Schur preconditioner using a QR factorization, we actually factorize $g^\prime(x)^*$ and not $g^\prime(x)$.  Though, as we stated above, we can quickly compute one form from the other, so we always use what's easiest to compute and calculate.  For more information on preconditioning, see the section \hyperref[sec:preconditioners]{\secpreconditioners}.}

    \cacheitem
        {Factorization, inverse, or approximate inverse for the Schur preconditioner}
        {Schur factorization}
        {invschur}
        {\classEquality}
        {High}
        {2}
        {As we discuss in the section \hyperref[sec:preconditioners]{\secpreconditioners}, we require a Schur preconditioner for equality constrained problems that contain more than tens of variables.  To accomplish this, we generally factorize $g^\prime(x)g^\prime(x)^*$, but we can use a problem specific preconditioner as well.  In either case, it's important that we cache this computation since we repeatedly require it and it's likely expensive to compute.  Similar to our discussion of \cachesoftref{gderiv}{caching the total derivative of the equality constraints}, we require two cached factorizations for an efficient code.}

    \cacheitem
        {Adjoint of the second derivative of the equality constraints applied to a vector}
        {Second derivative of equality constraints}
        {gderiv2}
        {\classEquality}
        {Low}
        {1}
        {During the tangential subproblem, which solves the optimality conditions, we require the repeated computation of $(g^{\prime\prime}(x)\partial x)^*y$.  Sometimes, we can precompute part of this computation, which can accelerate this application.  For example, when we use the inner product $\langle x,y\rangle=x^Ty$ and have a function of the form
        $$
        g(x) = \begin{bmatrix}
                g_1(x)\\
                \vdots\\
                g_m(x)
            \end{bmatrix},
        $$
        we have that
        $$
        (g^{\prime\prime}(x)\partial x)^*y = \left(\sum\limits_{i=1}^m y_i \nabla^2 g_i(x)\right)\partial x.
        $$
        In this case, we can cache the quantity
        $$
            \sum\limits_{i=1}^m y_i \nabla^2 g_i(x)
        $$
        to accelerate the computation.

        Most of the time, we do not prioritize caching this operator.  This operator has the same size as the Hessian, which tends to require a lot of memory.  Further, when far from the optimal solution, we may only require the action of this operator on a vector a few times each iteration.  Therefore, computing the entire operator can be wasteful.}

\end{boldlist}

    \examplelabel{Computation caching}{sec:cache}
    In order to illustrate these caching techniques, let us setup and solve a simple parameter estimation problem.  In parameter estimation, we seek an unknown parameter, $k$, that characterizes a model, which is often a PDE describing some kind of physical system.  In order to find these parameters, we run a series of experiments on the physical system and collect the measurable data, $d$.  Then, we match this data to the output of the model, $u$.  For example, we can model a parameter estimation problem governed by the steady-state convection-diffusion equations in 1-D as
$$\begin{array}{rcl}
        \min\limits_{k\in\re^2,u\in C^2([0,1])}  && \frac{1}{2} \| u - d \|^2 \\
        \st && k_1 \nabla\cdot(\nabla u) + k_2 \nabla \cdot u = f\\
        && u(0)=a\\
        && u(1)=b.
\end{array}$$
To be sure, we give the simplest possible case here.  Really, there should be a time component and $k$ should represent material properties that vary spatially like $u$.  Nevertheless, this problem will demonstrate that even a problem with only two variables can be very expensive to solve and that intermediate quantities should be cached appropriately.  To that end, our strategy for this example will be to
\begin{enumerate}
    \item Discretize the differential equation using a finite-difference method
    \item Implement caching on the reduced-space (unconstrained) formulation
    \item Implement caching on the full-space (equality constrained) formulation
\end{enumerate}
This includes code written in MATLAB/Octave demonstrating the caching called \textct{computation_caching} in the examples directory.  We explain the terms \textit{reduced-space} and \textit{full-space} below.

\subparagraph{Discretization}\mbox{}\\

        In order to discretize the diffusion operator, $\nabla\cdot\nabla$, we use the second-order accurate finite-difference operator
$$
        A = \frac{1}{\partial x^2} \begin{bmatrix}
            -2 & -1\\
            -1 & 2 & -1\\
            & \ddots & \ddots & \ddots\\
            & & -1 & 2 & -1\\
            & & & -1 & 2
        \end{bmatrix}.
$$
In order to accommodate the Dirichlet boundary conditions, we also define a vector that we use to modify the right hand side with information about the boundary conditions,
$$
        \hat{A} = \frac{1}{\partial x^2} \begin{bmatrix}
            -a\\
            0\\
            \vdots\\
            0\\
            -b
        \end{bmatrix}.
$$
Normally, we just subtract this quantity from the discretized $f$, but since we have unknown material properties $k$, we represent it explicitly.  Next, we discretize the convection operator, $\nabla\cdot$, using the first-order accurate finite difference operator
$$
        B = \frac{1}{\partial x} \begin{bmatrix}
            1 \\
            -1 & 1 \\
            & \ddots & \ddots \\
            & & -1 & 1
        \end{bmatrix}
$$
As before, we accommodate the Dirichlet boundary condition with a vector to modify the right hand side with information about the boundary conditions,
\begin{align*}
        \hat{B} = \frac{1}{\partial x} \begin{bmatrix}
            -a\\
            0\\
            \vdots\\
            0
        \end{bmatrix}.
\end{align*}
This allows us to specify the discretized parameter estimation problem as
$$\begin{array}{rcl}
        \min\limits_{k\in\re^2,u\in\re^m}  && \frac{1}{2} \| u - d \|^2 \\
        \st && (k_1 A + k_2 B)u = f - k_1 \hat{A} - k_2 \hat{B}.
\end{array}$$
For brevity, we specify that
\begin{align*}
    C(k) =& k_1 A + k_2 B\\
    g(k) =& f-k_1\hat{A}-k_2\hat{B},
\end{align*}
which allows us to reformulate the discretized parameter estimation problem as
$$\begin{array}{rcl}
        \min\limits_{k\in\re^2,u\in\re^m}  && \frac{1}{2} \| u - d \|^2 \\
        \st && C(k)u = g(k).
\end{array}$$
We call the above formulation the \textit{full-space formulation}.  Alternatively, we can solve for $u$ in the constraints and instead solve
$$\begin{array}{rcl}
        \min\limits_{k\in\re^2}  && \frac{1}{2} \| C(k)^{-1}g(k) - d \|^2
\end{array}$$
which we call the \textit{reduced-space formulation}.

\subparagraph{Caching the reduced-space (unconstrained) formulation}\mbox{}\\

        In the reduced-space formulation, let us set
$$
    J(k) = \frac{1}{2} \| C(k)^{-1}g(k) - d \|^2.
$$
In order to optimize with this function, we require the gradient and the Hessian-vector product.  In order to derive the gradient, we calculate the partial derivative with respect to $k_i$ as
\begin{align*}
    J^\prime_i(k)
    =& \langle C(k)^{-1}g(k) - d, -C(k)^{-1} C^\prime_i(k) C(k)^{-1}g(k) + C(k)^{-1}g^\prime_i(k)\rangle\\
    =& \langle C(k)^{-1}g(k) - d, -C(k)^{-1} (C^\prime_i(k) C(k)^{-1}g(k) - g^\prime_i(k))\rangle
\end{align*}
where
$$\begin{array}{r@{\,=\,}lr@{\,=\,}l}
        C^\prime_1(k) & A,&
        C^\prime_2(k) & B,\\
        g^\prime_1(k) & -\hat{A},&
        g^\prime_2(k) & -\hat{B}.
\end{array}$$
Then,
$$
        \nabla J(k) = \begin{bmatrix}
                J^\prime_1(k)\\
                J^\prime_2(k)
            \end{bmatrix}.
$$
In order to calculate the Hessian-vector product, we continue this process and compute the full Hessian.  We see that the second partial derivative of $J$ with respect to $k_i$ and $k_j$ is
\begin{align*}
    J^{\prime\prime}_{ij}(k)
        =& \langle -C(k)^{-1} (C^\prime_j(k) C(k)^{-1}g(k) - g^\prime_j(k)), -C(k)^{-1} (C^\prime_i(k) C(k)^{-1}g(k) - g^\prime_i(k))\rangle\\
        &+ \langle C(k)^{-1}g(k) - d, C(k)^{-1} C^\prime_j(k) C(k)^{-1}(C^\prime_i(k) C(k)^{-1}g(k) - g^\prime_i(k))\rangle\\
        &+ \langle C(k)^{-1}g(k) - d, C(k)^{-1}(C^\prime_i(k) C(k)^{-1}C^\prime_j(k)C(k)^{-1}g(k))\rangle\\
        &+ \langle C(k)^{-1}g(k) - d, -C(k)^{-1}(C^\prime_i(k) C(k)^{-1}g^\prime_j(k)\rangle.
\end{align*}
Certainly, we could group terms more optimally, but this formulation is good enough for our purposes.  Then, we have that
$$
        \nabla^2 J(k) = \begin{bmatrix}
                J^{\prime\prime}_{11}(k) & J^{\prime\prime}_{12}(k)\\
                J^{\prime\prime}_{21}(k) & J^{\prime\prime}_{22}(k)
            \end{bmatrix}.
$$

        At this point, we can implement the necessary optimization functions and cache effectively.  We begin with \cacheref{Objective evaluation}{objective}{caching the initial objective function solve} in the code

\cachecode{reduced}{ObjectiveGradient}

\noindent In the function \textct{obj_grad}, we compute the objective during the gradient solve and store it in the global variable \textct{ocache}.  Then, the function \textct{obj_eval} uses this cached value when possible.  Note, it's possible to accomplish the same effect without global variables by using an intermediate function with persistent variables, but this method works well enough.

        Next, we \cacheref{Nested computations and state solves}{state}{cache the state solves} with the code

\cachecode{reduced}{StateSolve}

\noindent We greatly improve the code's performance with this routine because it insures that we only factorize the linear system associated with the discretized convection-diffusion equations once per iteration.  It accomplishes this by storing the cached results in the persistent variable \textct{cache}.

        As far as the second-order information, we see how to \cacheref{Hessian}{hessian}{compute and cache the Hessian-vector product} with the code

\cachecode{reduced}{Hessian}

\noindent Notice that we compute and cache the dense Hessian in the routine \textct{hessian}, which makes the Hessian-vector product a simple multiplication.  As before, we accomplish this caching with the persistent variable \textct{cache}.  Also note, this code relies on the cached state solves we describe above for fast performance.

        Finally, we \cacheref{Hessian factorization}{invhessian}{implement and cache a Hessian preconditioner} using the inverse of the Hessian computed with the code

\cachecode{reduced}{HessianInv}

\noindent Similar to the other functions, we cache the intermediate results in the persistent variable \textct{cache}.  Also note that we rely on the cached Hessian in the code listed above.

\subparagraph{Caching the full-space (equality constrained) formulation}\mbox{}\\

        If the full-space formulation, we focus on the constraint
$$
    G(k,u) = C(k)u - g(k)
$$
In order to derive the total derivative, we note that
\begin{align*}
        G^\prime_{k_i}(k,u) =& C^{\prime}_i u - g^\prime_i(k)\\
        G^\prime_u(k,u) =& C(k).
\end{align*}
This implies that the total derivative and its adjoint are
\begin{align*}
        G^\prime(k,u) =& \begin{bmatrix}
                C^{\prime}_1 u - g^\prime_1(k) & C^{\prime}_2 u - g^\prime_2(k) & C(k)
            \end{bmatrix}\\
        G^\prime(k,u)^* =& \begin{bmatrix}
                (C^{\prime}_1 u - g^\prime_1(k))^T \\
                (C^{\prime}_2 u - g^\prime_2(k))^T \\
                C(k)^T
            \end{bmatrix}.
\end{align*}
We wrote out the adjoint explicitly because it makes it easier to derive the adjoint of the second-derivative in a more cacheable form
$$
    (G^{\prime\prime}(k,u)(\partial k,\partial u))^*\partial y = \begin{bmatrix}
        0 & 0 & \partial y^TC^\prime_1(k)\\
        0 & 0 & \partial y^TC^\prime_2(k)\\
        C^\prime_1(k)^T\partial y & C^\prime_2(k)^T \partial y & 0\\
    \end{bmatrix}
    \begin{bmatrix}
        \partial k_1\\
        \partial k_2\\
        \partial u
    \end{bmatrix}
$$

        Now, let us look at the code that caches these operations effectively.  First, we start with the code that \cacheref{Derivative of equality constraints}{gderiv}{caches the total derivative of $G$}

\cachecode{full}{Derivative}

\noindent Here, we see that our reliance on computing an explicit representation for the total derivative of $G$ simplifies the functions \textct{eq_p} and \textct{eq_ps} to simple multiplications.  Next, as before, we store the cached information in a persistent variable called \textct{cache}.  However, unlike before, we store two separate cached items and manage them with the function \textct{cache_search}.  In this function, we keep the most recently used cached item as the first element in the cache.  When we evaluate the derivative at a new point, we discard the the second item.  Recall, we require two cached items due to an additional augmented system solve for the equality multiplier during globalization.

        In a similar manner, we define the code that \cacheref{Schur factorization}{invschur}{implements and caches the Schur preconditioner} as

\cachecode{full}{Schur}

\noindent Like the code that cached the total derivative of $G$, we cache two elements in the persistent variable \textct{cache}.  However, here, we store the factorization of the system $G^\prime(k,u)G^\prime(k,u)^*$.  Note, caching the total derivative above helps accelerate this code as well.  As a side note, we actually define two different preconditioners in this code.  The true Schur preconditioner factorizes the system $G^\prime(k,u)G^\prime(k,u)^*$, which typically yields a dense factorization due to the derivatives with respect to $k$.  Alternatively, we can define an approximate Schur preconditioner from the factorization of $G^\prime_u(k,u)G_u^\prime(k,u)^*$.  Although we can no longer solve the augmented system in exactly three iterations, this preconditioner allows us to factorize $G^\prime_u(k,u)$ directly, which yields a sparse decomposition.

        Finally, we \cacheref{Second derivative of equality constraints}{gderiv2}{cache the adjoint of the second derivative applied to the equality multiplier} with the code

\cachecode{full}{Derivative2}

\noindent As before, we store the cached information in a persistent variable called \textct{cache}.  The nuance in this case is that we should check both \textct{x} and \textct{dy} when determining whether we've moved to a new point and need to recompute the second derivative.

\chapter{\chexamples}\label{ch:examples}

        During the configure process, we compile and install a variety of examples whenever the \textctref{ENABLE_CPP_EXAMPLES}, \textctref{ENABLE_PYTHON_EXAMPLES}, or \textctref{ENABLE_MATLAB_EXAMPLES} are turned to \textct{ON}.  For reference, we include some of these examples here.

\section{\secequality}\examplelabel{\secequality}{sec:equality}

        In our \exampleref{\secequality}{sec:equality} example, we optimize the formulation
$$
    \begin{array}{rcl}
        \min\limits_{x\in\re^2} && x^2+y^2\\
        \st && (x-2)^2 + (y-2)^2 = 1
    \end{array}
$$
with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@SIMPLEEQUALITYPATH@/simple_equality.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python]{@SIMPLEEQUALITYPATH@/simple_equality.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=MATLAB]{@SIMPLEEQUALITYPATH@/simple_equality.m}}
\end{boldlist}

\section{\secinequality}\examplelabel{\secinequality}{sec:inequality}

        In our \exampleref{\secinequality}{sec:inequality} example, we optimize the formulation
$$
    \begin{array}{rcl}
        \min\limits_{x\in\re^2} && (x+1)^2+(y+1)^2\\
        \st && x + 2y \geq 1\\
            && 2x + y \geq 1
    \end{array}
$$
with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@SIMPLEINEQUALITYPATH@/simple_inequality.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python]{@SIMPLEINEQUALITYPATH@/simple_inequality.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=MATLAB]{@SIMPLEINEQUALITYPATH@/simple_inequality.m}}
\end{boldlist}

\section{\secconstrained}\examplelabel{\secconstrained}{sec:constrained}

        In our \exampleref{\secconstrained}{sec:constrained} example, we optimize the formulation
$$
    \begin{array}{rcl}
        \min\limits_{x\in\re^2} && (x+1)^2+(y+1)^2\\
        \st && x + 2y = 1\\
            && 2x + y \geq 1
    \end{array}
$$
with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@SIMPLECONSTRAINEDPATH@/simple_constrained.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python]{@SIMPLECONSTRAINEDPATH@/simple_constrained.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=MATLAB]{@SIMPLECONSTRAINEDPATH@/simple_constrained.m}}
\end{boldlist}

\section{\secrosenbrockadvancedapi}\examplelabel{\secrosenbrockadvancedapi}{sec:rosenbrockadvancedapi}

        In our \exampleref{\secrosenbrockadvancedapi}{sec:rosenbrockadvancedapi} example, we optimize the formulation
$$
    \begin{array}{rcl}
        \min\limits_{x\in\re^2} && (1-x_1)^2+100(x_2-x_1^2)^2.
    \end{array}
$$
using the features described in our chapter \hyperref[ch:advanced]{\chadvanced}.  We accomplish this with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=MATLAB]{@ROSENBROCKADVANCEDAPIPATH@/rosenbrock_advanced_api.m}}
\end{boldlist}

\section{\secsimpleconstrainedadvancedapi}\examplelabel{\secsimpleconstrainedadvancedapi}{sec:simpleconstrainedadvancedapi}

        In our \exampleref{\secsimpleconstrainedadvancedapi}{sec:simpleconstrainedadvancedapi} example, we optimize the formulation
$$
    \begin{array}{rcl}
        \min\limits_{x\in\re^2} && (x+1)^2+(y+1)^2\\
        \st && x + 2y = 1\\
            && 2x + y \geq 1
    \end{array}
$$
which uses the same formulation as our example \exampleref{\secconstrained}{sec:constrained}.  It differs in that we implement a restart mechanism that writes our variables to an external file.  By using the features described in our chapter \hyperref[ch:advanced]{\chadvanced}, we accomplish this with the code:
\begin{boldlist}
    \exampleitem
        {C++}
        {\lstinputlisting[style=C++]{@SIMPLECONSTRAINEDADVANCEDAPIPATH@/simple_constrained_advanced_api.cpp}}

    \exampleitem
        {Python}
        {\lstinputlisting[style=Python]{@SIMPLECONSTRAINEDADVANCEDAPIPATH@/simple_constrained_advanced_api.py}}

    \exampleitem
        {MATLAB/Octave}
        {\lstinputlisting[style=MATLAB]{@SIMPLECONSTRAINEDADVANCEDAPIPATH@/simple_constrained_advanced_api.m}}
\end{boldlist}

\chapter{Algorithmic discussion}

        In the following chapter, we give a brief discussion of the algorithms we include within Optizelle and references to more detailed descriptions.

\begin{boldlist}
    \algorithmitem
        {Barzilai-Borwein}
        {We implement the Barzilai-Borwein algorithm by setting \textctref{dir} to \hyperref[itm:LineSearchDirection]{\textct{SteepestDescent}} and \textctref{kind} to either \hyperref[itm:LineSearchKind]{\textct{TwoPointA}} or \hyperref[itm:LineSearchKind]{\textct{TwoPointB}}.  Specifically, \hyperref[itm:LineSearchKind]{\textct{TwoPointA}} and \hyperref[itm:LineSearchKind]{\textct{TwoPointB}} refer to the algorithms generated by equation (5) and (6) in Barzilai and Borwein's paper, respectively.  Since this algorithm requires two points before it may commence, we use a \hyperref[itm:LineSearchKind]{\textct{GoldenSection}} search on the first iteration.
    \begin{itemize}
        \item \bibentry{barzilai1988two_point}.
    \end{itemize}}

    \algorithmitem{Golden-section search}
        {We implement a straightforward golden-section search.  For historical significance, we refer to Kiefer's paper, but a much more complete description can be found in Bazaraa, Sherali, and Shetty's book.
    \begin{itemize}
        \item \bibentry{kiefer1953fibonacci_golden_section_search}.
        \item \bibentry{bazaraa2006nonlinear_programming}.
    \end{itemize}}

    \algorithmitem
        {BFGS}
        {Our BFGS implementation uses a limited-memory, iterative reformulation of the algorithm based on a generic inner product.  Our limited-memory implementation differs from that of Byrd, Nocedal, and Schnabel's because we do not form a compact representation, but instead use a scratch space whose size is equal to \textctref{stored_history}.  In addition, since we do not check the Wolfe conditions, we do a hard check to insure that BFGS operator remains positive definite.  We refer to the collection of 1970s papers for historical significance, but note that a much better presentation of the algorithm can be found in Nocedal and Wright's book.
    \begin{itemize}
        \item \bibentry{broyden1970bfgs}.
        \item \bibentry{fletcher1970bfgs}.
        \item \bibentry{goldfarb1970variable_metric_methods}.
        \item \bibentry{shanno1970bfgs}.
        \item \bibentry{byrd1994limited_memory_quasi_newton}.
        \item \bibentry{nocedal2006numerical_optimization}.
    \end{itemize}}

    \algorithmitem
        {SR1}
        {Similar to BFGS, our SR1 implementation uses a limited-memory, iterative reformulation of the algorithm based on a generic inner product.  As before, our limited-memory implementation differs from that of Byrd, Nocedal, and Schnabel's because we do not form a compact representation, but instead use a scratch space whose size is equal to \textctref{stored_history}.  We refer to Broyden's paper for historical significance, but note that a much better presentation of the algorithm can be found in Nocedal and Wright's book.
    \begin{itemize}
        \item \bibentry{broyden1967quasi_newton}.
        \item \bibentry{byrd1994limited_memory_quasi_newton}.
        \item \bibentry{nocedal2006numerical_optimization}.
    \end{itemize}}

    \algorithmitem
        {Nonlinear-CG}
        {We use a standard implementation of nonlinear-CG.  On the first iteration, we move in the steepest descent direction, but use the specified nonlinear-CG direction on subsequent iterations.  Since we do not check the strong-Wolfe condition, we do a hard check to insure a descent direction.  If we do not, we negate the search direction.  Although we reference the original papers from Hestenes and Stiefel, Fletcher and Reeves, and Polak and Ribiere, Nocedal and Wright give a nicer presentation.  In addition, Hager and Zhang present a nice overview of the different nonlinear-CG variations in their survey paper.
    \begin{itemize}
        \item \bibentry{hestenes1952conjugate_gradient}.
        \item \bibentry{fletcher1963nonlinear_conjugate_gradient}.
        \item \bibentry{polak1969nonlinear_conjugate_gradient}.
        \item \bibentry{nocedal2006numerical_optimization}.
        \item \bibentry{hager2006nonlinear_cg}.
    \end{itemize}}

    \algorithmitem
        {Trust-region Newton}
        {Our trust-region Newton implementation uses truncated-CG to solve the trust-region subproblem.  Both Conn, Gould, and Toint's as well as Nocedal and Wright's book give good descriptions of the algorithm.
    \begin{itemize}
        \item \bibentry{conn2000trust_region_methods}.
        \item \bibentry{nocedal2006numerical_optimization}.
    \end{itemize}}

    \algorithmitem
        {Newton-CG}
        {We base our Newton-CG algorithm on truncated CG and not a Hessian modification.  Nocedal and Wright's book describes this algorithm.
    \begin{itemize}
        \item \bibentry{nocedal2006numerical_optimization}.
    \end{itemize}}

    \algorithmitem
        {Truncated CG}
        {Our version of truncated CG actually possesses the ability to over orthogonalize against previous Krylov vectors, which is controlled by the parameters \textctref{trunc_orthog_storage_max} and \textctref{trunc_orthog_iter_max}.  In addition, we have added a safeguard procedure for the interior point method that insures truncated CG always produces a solution feasible with respect to the inequality constraint.  This safeguard process is similar to the one used by Byrd, Hribar, and Nocedal in their NITRO algorithm.  Finally, for the inexact composite-step SQP method, we use the heuristic described in appendix B by Heinkenschloss and Ridzal to detect instability in the algorithm.  Historically, Toint and Steihaug give a description of truncated-CG in their respective papers.  For a modern treatment of truncated-CG see Conn, Gould, and Toint's book.
    \begin{itemize}
        \item \bibentry{toint1981truncated_cg}.
        \item \bibentry{steihaug1983truncated_cg}.
        \item \bibentry{conn2000trust_region_methods}.
        \item \bibentry{byrd1999interior_point_trust_region}.
        \item \bibentry{heinkenschloss2014inexact_sqp}.
    \end{itemize}}

    \algorithmitem
        {Interior-point method}
        {Our interior point method is based on a new derivation of the primal-dual interior point equations based on pseudo-Euclidean-Jordan algebras.  We say {\it pseudo} because we do not require commutativity in the Jordan product.  Specifically, our derivation begins from the optimality conditions
    \begin{align*}
        \nabla f(x) - h^\prime(x)^*z =& 0,\\
        h(x)\succeq & 0,\\
        z \succeq & 0,\\
        h(x) \circ z = & 0
    \end{align*}
    in the case of inequality constrained problems and
    \begin{align*}
        \nabla f(x) + g^\prime(x)^*y - h^\prime(x)^*z =& 0,\\
        g(x) = & 0,\\
        h(x)\succeq & 0,\\
        z \succeq & 0,\\
        h(x) \circ z = & 0
    \end{align*}
    in the case of constrained problems.  Here, $\circ$ denotes the Jordan product that we refer to as \textctref{prod}.  Since we use a composite-step SQP method for constrained problems, we ignore the feasibility condition, $g(x)=0$, in the constrained problem.  Simply, we handle feasibility with respect to this constraint with the quasi-normal step.  This allows us to reduce both sets of optimality conditions to
    \begin{align*}
        \textnormal{grad}(x,y) - h^\prime(x)^*z =& 0,\\
        h(x)\succeq & 0,\\
        z \succeq & 0,\\
        h(x) \circ z = & 0
    \end{align*}
    where
    $$
        \textnormal{grad}(x,y) = \left\{
            \begin{array}{ll}
                \nabla f(x) & \textnormal{Inequality constrained problems,}\\
                \nabla f(x) + g^\prime(x)^*y & \textnormal{Constrained problems.}
            \end{array}\right.
    $$
    Then, using a standard interior-point formulation, we perturb the optimality conditions into
    \begin{align*}
        \textnormal{grad}(x,y) - h^\prime(x)^*z =& 0\\
        h(x)\succ & 0\\
        z \succ & 0\\
        h(x) \circ z = & \mu e.
    \end{align*}
    where $e$ denotes the identity element in the pseudo-Euclidean-Jordan algebra, which we refer to as \textctref{id}.  Next, we apply Newton's method to the nonlinear system of equations
    \begin{align*}
        \textnormal{grad}(x,y) - h^\prime(x)^*z =& 0,\\
        h(x) \circ z = & \mu e,
    \end{align*}
    which yields the system
    $$
        \begin{bmatrix}
            \textnormal{hess}(x,y) & - h^\prime(x)^*\\
            h^\prime(x) \cdot \circ z  & h(x)\circ \cdot
        \end{bmatrix}
        \begin{bmatrix}
            \delta x\\
            \delta z
        \end{bmatrix}
        =
        \begin{bmatrix}
            -\textnormal{grad}(x,y) + h^\prime(x)^*z\\
            -h(x) \circ z + \mu e
        \end{bmatrix}
    $$
    where
    $$
        \textnormal{hess}(x,y) = \left\{
            \begin{array}{ll}
                \nabla^2 f(x) & \textnormal{Inequality constrained problems,}\\
                \nabla^2 f(x) + (g^{\prime\prime}(x)\cdot)^*y & \textnormal{Constrained problems.}
            \end{array}\right.
    $$
    Using the second equation in the Newton system, we solve for $\delta z$ and find that
    $$
        \delta z =  -z + L(h(x))^{-1} (-h^\prime(x) \delta x \circ z + \mu e)
    $$
where $L(h(x))^{-1}$ denotes the inverse of the linear operator induced by the Jordan product, $\circ$, which we refer to as \textctref{linv}.  In other words, $h(x)\circ z=L(h(x))z$.  Then, we plug this equation into the first equation and reduce our Newton system to
    $$
        [\textnormal{hess}(x,y) + h^\prime(x)^* (L(h(x))^{-1} (h^\prime(x) \cdot \circ z)) ] \delta x =  -\textnormal{grad}(x,y) + \mu h^\prime(x)^* (L(h(x))^{-1} e).
    $$
    At this point, we solve the Newton system using truncated CG.  As a note, when using a line-search method that is not Newton-CG, we using a different scheme and instead set
    $$
        \textctref{z} =  \textctref{mu} \cdot L(h(\textctref{x}))^{-1} e.
    $$
This gives us a log-barrier algorithm for these methods.  In short, without solving a Newton system, the equations for \textctref{dz} don't make sense, so we instead fallback on a log-barrier method, which does not require them.

        In order to maintain strict feasibility of $h(x)$ and $z$ we safeguard our steps \textctref{dx} and \textctref{dz} using the fraction to the boundary rule
\begin{align*}
        h(\textctref{x} + \textctref{alpha_x}\cdot\textctref{dx}) \geq& (1-\textctref{gamma}) h(x)\\
        \textctref{z} + \textctref{alpha_z}\cdot\textctref{dz} \geq& (1-\textctref{gamma}) z)\\
        h(\textctref{x} + \textctref{alpha_x_qn}\cdot\textctref{dx_n}) \geq& (1-\textctref{gamma}\cdot\textctref{zeta}) h(x)
\end{align*}
Note, the last inequality only occurs in constrained problems.  When we enforce these rules depends on the algorithm.  Specifically, trust-region methods enforce these bounds during the truncated-CG solve of the optimality conditions.  Since truncated CG may violate the inequality bounds periodically throughout the optimality solve, we save the last feasible iterate during the computation.  When we exit, we take the last feasible iterate and step and compute the safeguard search, which satisfies the fraction to the boundary rule above.  In order to prevent too many discarded steps due to the safeguard, we limit the maximum number of infeasible steps that we allow to be \textctref{safeguard_failed_max}.  Although our process is slightly different than their paper, how we embed the safeguard into truncated CG is similar to what Byrd, Hribar, and Nocedal do in their implementation of NITRO.  In a line-search method, we safeguard the step prior to the line search.  Specifically, we shorten \textctref{alpha0} so that the maximum step length taken by the line search does not exceed our fraction to the boundary rule.  Finally, in the inexact composite step SQP method, we also safeguard our quasi-normal step by enforcing the fraction to the boundary rule during the dogleg computation.  In each case, we calculate the distance to the boundary with the user-defined function \textctref{srch}.  In our \textctref{Rm} and \textctref{SQL} vector spaces, we use a closed form formula for linear and second-order cones and the Arnoldi algorithm for semidefinite cones.

        We reduce \textctref{mu} prior to the truncated-CG solve for the optimality system and set $\textctref{mu} = \textctref{sigma}\cdot \textctref{mu}$ when one of the following global or local convergence criteria is satisfied
        \begin{enumerate}
            \item $\log(\textctref{norm_gradtyp}) - \log(\|\textnormal{gradstep}(x,y,z)\|) < \log(\textctref{mu_typ}) - \log(\textctref{mu_est})$

            \item $\|\textnormal{gradstep}(x,y,z)\| < \textctref{eps_grad}\cdot \textctref{norm_gradtyp}$

            \item $\log(\textctref{norm_gradtyp}) - \log(\|\textnormal{gradstop}(x,y,z)\|) < \log(\textctref{mu_typ}) - \log(\textctref{mu_est})$

            \item $\|\textnormal{gradstop}(x,y,z)\| < \textctref{eps_grad}\cdot \textctref{norm_gradtyp}$
        \end{enumerate}
        where
        \begin{align*}
            \textnormal{gradstop}(x,y,z) =& \left\{
                \begin{array}{ll}
                    \nabla f(x) - h^\prime(x)^*z& \textnormal{Inequality constrained,}\\
                    \nabla f(x) + g^\prime(x)^*y -h^\prime(x)^* z & \textnormal{Constrained.}
                \end{array}\right.\\
            \textnormal{gradstep}(x,y,z) =& \left\{
                \begin{array}{ll}
                    \nabla f(x) - \mu h^\prime(x)^* L(h(x))^{-1} e& \textnormal{Inequality constrained,}\\
                    \nabla f(x) + W(\nabla^2 f(x)\textctref{dx_n}) + g^\prime(x)^*y - \mu h^\prime(x)^* L(h(x))^{-1} e & \textnormal{Constrained.}
                \end{array}\right.
        \end{align*}
        and $W$ denotes the projection onto nullspace of $g^\prime(x)$.  Next, we must satisfy one of the following global or local convergence criteria
        \begin{enumerate}
            \item $\log(\textctref{norm_gxtyp}) - \log(\|g(\textctref{x})\|) < \log(\textctref{mu_typ}) - \log(\textctref{mu_est})$

            \item $\|g(\textctref{x})\| < \textctref{eps_constr}\cdot \textctref{norm_gxtyp}$
        \end{enumerate}
        In addition, we must converge \textctref{mu_est} locally
        $$
                | \textctref{mu} - \textctref{mu_est} | < \textctref{mu}
        $$
        and not have converged \textctref{mu} globally
        $$
                | \textctref{mu} - \textctref{eps_mu}\cdot \textctref{mu_typ}| \geq \textctref{eps_mu} \cdot \textctref{mu_typ}.
        $$
        Finally, we also require that $\textctref{iter} > 1$, so that we don't reduce \textctref{mu} on the first iteration.

        For globalization, in both trust-region and line-search methods, we modify our merit function with the addition of a barrier function, which we refer to as \textctref{barr}.  Specifically, we allow any barrier function such that $x\circ\nabla\textctref{barr}(x)=e$.  In our \textctref{Rm} and \textctref{SQL} vector spaces, we use the log-barrier functions:
        $$\begin{array}{ll}
            \textnormal{Linear} & \langle \log(x),e\rangle,\\
            \textnormal{Quadratic} & \frac{1}{2} \log(x_0^2-\langle\bar{x},\bar{x}\rangle),\\
            \textnormal{Semidefinite} & \log(\det(x)).
        \end{array}$$
where $\langle\cdot,\cdot\rangle$ refers to the $\ell^2$ inner product.  In order to compute the semidefinite barrier function, we Choleski factor $x$ into $u^Tu$ since
$$
\log(\det(x)) = \log(\det(u^Tu)) = \log(\det(u^T)\det(u)) = \log(\det(u)^2) = 2 \log(\det(u))
$$
and the determinant of an upper triangular matrix can be calculated quickly.

        As our final step, since we don't require our Jordan product to be commutative, we forcibly symmetrize both $\delta x$ and $\delta z$ using the \textctref{symm} operator in our vector space.

        As far as the initial inequality multiplier, we set
$$
        \textctref{z} =  \textctref{mu} \cdot L(h(\textctref{x}))^{-1} e.
$$
This guarantees that
\begin{enumerate}
    \item $h(\textctref{x}) \circ \textctref{z} = \textctref{mu} \cdot e$
    \item $\textctref{mu_est} = \textctref{mu}$
\end{enumerate}
In other words, our initial inequality multiplier puts us on the central path specified by the parameter \textctref{mu}.

        Historically, we are not the first to use Euclidean-Jordan algebras in an interior point algorithm.  Alizadeh and Schmieta describe their use for semidefinite programming and Alizadeh and Goldfarb describe their use in second-order cone programming.  Nevertheless, we drop the commutativity requirement in our algorithm.  Part of the reason we drop the commutativity requirement is that in the SDP case we essentially generate the same optimality conditions as equation (4.10) in Helmberg, Rendl, Vanderbei, and Wolkowicz's SDP paper.  In fact, our symmetrization in the SQL vector space is identical to equation (4.30) in the same paper, which later became known as the HKM search direction.  Beyond the HKM symmetrization, we allow any similar symmetrization operator, which Zhang describes in his paper.
    \begin{itemize}
        \item \bibentry{alizadeh2000sdp_euclidean_jordan}.
        \item \bibentry{alizadeh2003socp}.
        \item \bibentry{helmberg1996interior_point_sdp}.
        \item \bibentry{zhang1998sdp_symmetrization}.
        \item \bibentry{byrd1999interior_point_trust_region}.
    \end{itemize}}

    \algorithmitem
        {Inexact composite-step SQP}
        {We implement a modified version of inexact composite-step SQP method that Ridzal devised in his Ph.D. thesis and later refined in a technical report by Ridzal, Aguil\'{o}, and Heinkenschloss.  Our implementation adds several safe-guards in order to more directly account for round-off error within the algorithm, which generally affects the augmented system solves.  As one example, when solving the augmented system for the quasi-normal step, if the Cauchy point brings us to optimality, GMRES may not be able to practically satisfy the tolerances the algorithm specifies.  Therefore, we detect this case directly and terminate the augmented system solve.
    \begin{itemize}
        \item \bibentry{ridzal2006trust_region_sqp}.
        \item \bibentry{ridzal2011inexact_sqp}.
        \item \bibentry{heinkenschloss2014inexact_sqp}.
    \end{itemize}}
\end{boldlist}

\chapter{Licenses}\label{ch:licenses}

    In the following chapter, we detail Optizelle's license as well as the license of all of its dependencies.

\section{Optizelle}\licenselabel{Optizelle}{optizelle}
\begin{flushleft}
    \texttt{\protect\input{@LICENSEPATH@/optizelle.txt}}
\end{flushleft}

\section{JsonCpp}\licenselabel{JsonCpp}{jsoncpp}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/jsoncpp.txt}
\end{flushleft}

\section{BLAS/LAPACK}\licenselabel{BLAS/LAPACK}{blaslapack}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/blas_lapack.txt}
\end{flushleft}

\section{CMake}\licenselabel{CMake}{cmake}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/cmake.txt}
\end{flushleft}

\section{WiX}\licenselabel{WiX}{wix}
\begin{flushleft}
    \texttt{\protect\input{@LICENSEPATH@/wix.txt}}
\end{flushleft}

\section{GCC}\licenselabel{GCC}{gcc}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/gcc.txt}
    \verbatiminput{@LICENSEPATH@/gcc_runtime.txt}
\end{flushleft}

\section{TeX Live}\licenselabel{TeX Live}{texlive}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/texlive.txt}
\end{flushleft}

\section{Python}\licenselabel{Python}{python}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/python.txt}
\end{flushleft}

\section{NumPy}\licenselabel{NumPy}{numpy}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/numpy.txt}
\end{flushleft}

\section{MATLAB}\licenselabel{MATLAB}{matlab}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/matlab.txt}
\end{flushleft}

\section{JSONLab}\licenselabel{JSONLab}{jsonlab}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/jsonlab.txt}
\end{flushleft}

\section{Octave}\licenselabel{Octave}{octave}
\begin{flushleft}
    \verbatiminput{@LICENSEPATH@/octave.txt}
\end{flushleft}

\clearpage
\addcontentsline{toc}{chapter}{Index}
\printindex
\end{document}
